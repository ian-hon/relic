{"convention":"0.0.1","content":[{"Blob":{"name":"Cargo.toml","content":"[package]\nname = \"relic-vcs\"\nversion = \"0.1.0\"\nedition = \"2021\"\nexclude = [\n    \"lorem/\",\n    \"ipsum\",\n    \".relic\",\n    \".relic_ignore\",\n    \"target/\"\n]\nlicense = \"MIT\"\nkeywords = [\"vcs\"]\ncategories = [\"command-line-interface\", \"filesystem\"]\ndescription = \"Git, but in Rust.\"\nhomepage = \"https://github.com/ian-hon/relic\"\nrepository = \"https://github.com/ian-hon/relic\"\nreadme = false\n\n[dependencies]\nsha256 = \"1.5.0\"\n\nstrum = \"0.26.3\"\nstrum_macros = \"0.26.3\"\n\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\nurlencoding = \"2.1.3\"\nunescape = \"0.1.0\"\nchrono = \"0.4.41\"\n\ndotenv = \"0.15.0\"\nclap = \"4.5.38\"\n\nsimilar = \"2.7.0\"\n# diff = \"0.1.13\""}},{"Tree":{"path":"./lorem","name":"lorem","content":[{"Blob":{"name":"earth","content":"can you understand me?"}},{"Tree":{"path":"./lorem/ipsum","name":"ipsum","content":[{"Blob":{"name":"temp","content":"alsfdk"}},{"Tree":{"path":"./lorem/ipsum/dolor","name":"dolor","content":[{"Blob":{"name":"pluto","content":""}},{"Blob":{"name":"venus","content":"al;kjdklfjsalfjsljfklljeowrpyuqiwfoid\nfqlkwoipdngayuowhqjpofqpnigewi\nalksdjflsjkld\nalsjdkfl;jsaklfjlkjiehqojek;dfk;\njklajfdoihqodjkfs"}},{"Blob":{"name":"hm","content":""}}]}},{"Blob":{"name":"saturn","content":""}},{"Blob":{"name":"saturn_new","content":"lasjdklfsjaklfdjsklfjsklf\nakl;js;klfdjs;ldjfklsfd"}}]}},{"Blob":{"name":"mars","content":"sldfjsljdkf"}},{"Blob":{"name":"pluto","content":"lajsdlkfsjdklfjsfsklfdashjdfskdfjs\nlajjsflkjas;dfkjkasjdfklj'ashjdfskdfjs\njas;ldfjlsajdf\n\nalsfjdklasjdl;fjsjdlfslkasjdf\nakljskldfjls;adf"}},{"Blob":{"name":".relic_ignore","content":"-- Added by Relic: Automatically ignore all git content\n.git/\n.gitignore"}},{"Blob":{"name":"earth copy","content":"can you understand me?\nkjadlfjlskdf\nljs;kljflsdjl;kfsd\n\nljadlfjslfjldjls\nskjf;lsjdlfs\n\nlorem ipsum\ndolor sit amet\n\naskldfjlsjdkf\nalksjd;fjsjdlfs"}}]}},{"Tree":{"path":"./src","name":"src","content":[{"Blob":{"name":"lib.rs","content":"pub mod cli;\npub mod commands;\npub mod core;\npub mod error;\npub mod utils;\n"}},{"Tree":{"path":"./src/commands","name":"commands","content":[{"Blob":{"name":"staging.rs","content":"use clap::ArgMatches;\n\nuse crate::core::{content_set::TrackingSet, State};\n\npub fn staging(s: &mut State, _: &ArgMatches) {\n    println!(\n        \"{}\",\n        s.get_changes()\n            .filter_changes(&s.track_set.initialise(&mut s.current))\n            .as_human_readable(&s.upstream)\n    );\n}\n"}},{"Blob":{"name":"pull.rs","content":"use clap::ArgMatches;\n\nuse crate::core::state::State;\n\npub fn pull(_: &mut State, _: &ArgMatches) {}\n"}},{"Blob":{"name":"test.rs","content":"use clap::ArgMatches;\n\nuse crate::core::State;\n\npub fn test(s: &mut State, _: &ArgMatches) {\n    println!(\"{:?}\", s.info);\n}\n"}},{"Blob":{"name":"fetch.rs","content":"use clap::ArgMatches;\n\nuse crate::core::state::State;\n\npub fn fetch(_: &mut State, _: &ArgMatches) {}\n"}},{"Blob":{"name":"cherry.rs","content":"use clap::ArgMatches;\n\nuse crate::core::state::State;\n\npub fn cherry(_: &mut State, _: &ArgMatches) {}\n"}},{"Blob":{"name":"add.rs","content":"use std::{collections::HashSet, fs, path::PathBuf};\n\nuse clap::ArgMatches;\n\nuse crate::core::{paths::RELIC_PATH_TRACKED, state::State};\n\npub fn add(_: &mut State, args: &ArgMatches) {\n    let f = args\n        .get_many::<PathBuf>(\"FILE\")\n        .unwrap()\n        .map(|x| x.clone())\n        .collect::<Vec<PathBuf>>();\n\n    let mut result: HashSet<String> = HashSet::from_iter(\n        fs::read_to_string(format!(\"./{RELIC_PATH_TRACKED}\"))\n            .unwrap()\n            .split(\"\\n\")\n            .filter(|x| !x.is_empty())\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>(),\n    );\n    for p in f {\n        // TODO : path.join for this? or concatenating / works?\n        result.insert(format!(\n            \"{}{}\",\n            p.to_string_lossy().to_string(),\n            if !p.to_string_lossy().to_string().ends_with(\"/\") && p.is_dir() {\n                \"/\"\n            } else {\n                \"\"\n            }\n        ));\n    }\n    let _ = fs::write(\n        format!(\"./{RELIC_PATH_TRACKED}\"),\n        result.drain().collect::<Vec<String>>().join(\"\\n\"),\n    );\n}\n"}},{"Blob":{"name":"push.rs","content":"use clap::ArgMatches;\n\nuse crate::core::state::State;\n\npub fn push(_: &mut State, _: &ArgMatches) {}\n"}},{"Blob":{"name":"rollback.rs","content":"use clap::ArgMatches;\n\nuse crate::core::state::State;\n\npub fn rollback(_: &mut State, _: &ArgMatches) {}\n"}},{"Blob":{"name":"commit.rs","content":"use clap::ArgMatches;\n\nuse crate::{\n    core::{commit::Commit, state::State},\n    utils,\n};\n\npub fn commit(state: &mut State, args: &ArgMatches) {\n    // push into pending stage\n    // update upstream\n\n    // everything after the first line will be generated by Change::serialise_change\n    r#\"= {commit id} {unix timestamp of commit} {message} {description} {author}\n+ D \"lorem/ipsum/dolor\"\n+ F \"lorem/ipsum/dolor/earth.txt\" \"earth.txt\"\n- D \"lorem/sit\"\n=\n| \"lorem/ipsum/dolor/earth.txt\"\n+ 3 asdfsdf\n+ 5 sfsdf\n- 7\n| \"lorem/ipsum/saturn/txt\"\n+ 4 lsdfljs\"#;\n    let message = args.get_one::<String>(\"message\").unwrap().clone();\n    let description = args\n        .get_one::<String>(\"description\")\n        .map_or(\"\".to_string(), String::clone);\n\n    let commit = Commit {\n        id: None,\n        message,\n        description,\n        change: state.get_changes(),\n        timestamp: utils::get_time(),\n        author: \"no_one\".to_string(),\n    };\n\n    state.pending_add(commit);\n    // update upstream\n    (*state).update_upstream(&mut state.track_set.clone());\n}\n"}},{"Blob":{"name":"detach.rs","content":"use std::fs;\n\nuse clap::ArgMatches;\n\nuse crate::core::{paths, State};\n\npub fn detach(_: &mut State, _: &ArgMatches) {\n    let _ = fs::remove_dir_all(paths::RELIC_PATH_PARENT);\n    let _ = fs::remove_file(paths::RELIC_PATH_IGNORE);\n\n    println!(\"Relic repository successfully removed.\");\n}\n"}},{"Blob":{"name":"clone.rs","content":"use clap::ArgMatches;\n\nuse crate::core::State;\n\npub fn clone(_: &mut State, args: &ArgMatches) {\n    if let Some(remote) = args.get_one::<String>(\"URL\") {\n        println!(\"remote : {remote}\");\n\n        // validate if remote is a relic repository\n        // probably need some versioning system\n\n        // let _ = fs::create_dir(paths::RELIC_PATH_PARENT);\n        // let _ = fs::create_dir(paths::RELIC_PATH_HISTORY);\n        // let _ = fs::create_dir(paths::RELIC_PATH_PENDING);\n        // let _ = fs::write(paths::RELIC_PATH_INFO, DEFAULT_INFO);\n        // let _ = fs::write(paths::RELIC_PATH_ROOT, \"\");\n        // let _ = fs::write(paths::RELIC_PATH_TRACKED, \"\");\n        // let _ = fs::write(paths::RELIC_PATH_UPSTREAM, DEFAULT_UPSTREAM);\n\n        // let _ = fs::write(paths::RELIC_PATH_IGNORE, content_set::DEFAULT_IGNORE);\n    } else {\n        println!(\"No remote URL provided.\");\n    }\n}\n"}},{"Blob":{"name":"init.rs","content":"use std::fs;\n\nuse clap::ArgMatches;\n\nuse crate::core::{content_set, objects::data::Upstream, paths, RelicInfo, State};\n\npub fn init(_: &mut State, _: &ArgMatches) {\n    // create\n    // .relic\n    //      history/ (empty)\n    //      pending/ (empty)\n    //      root (empty)\n    //      tracked (empty)\n    //      upstream (empty)\n    // .relic_ignore (use default (const in content_set))\n\n    // if origin is set\n    // update root\n    // update upstream\n\n    let _ = fs::create_dir(paths::RELIC_PATH_PARENT);\n    let _ = fs::create_dir(paths::RELIC_PATH_HISTORY);\n    let _ = fs::create_dir(paths::RELIC_PATH_PENDING);\n    let _ = fs::write(paths::RELIC_PATH_INFO, RelicInfo::default().serialise());\n    let _ = fs::write(paths::RELIC_PATH_ROOT, \"\");\n    let _ = fs::write(paths::RELIC_PATH_TRACKED, \"\");\n    let _ = fs::write(paths::RELIC_PATH_UPSTREAM, Upstream::empty().serialise());\n\n    let _ = fs::write(paths::RELIC_PATH_IGNORE, content_set::DEFAULT_IGNORE);\n\n    println!(\"Empty Relic repository created.\");\n}\n"}},{"Blob":{"name":"pending.rs","content":"use clap::ArgMatches;\n\nuse crate::core::state::State;\n\npub fn pending(state: &mut State, args: &ArgMatches) {\n    let pending = state.pending_get();\n\n    if let Some(commit_number) = args\n        .get_one::<String>(\"COMMIT\")\n        .map_or(None, |x| x.parse::<i32>().map_or(None, |x| Some(x)))\n    {\n        // display selected\n        if (commit_number < 0) || (commit_number >= pending.len() as i32) {\n            println!(\n                \"Invalid selection. Please select commit numbers in the range of (0-{})\",\n                pending.len() - 1\n            );\n            return;\n        }\n\n        // if want the blamed tree here, need to refer to previous upstream\n        println!(\"{}\", pending[commit_number as usize].serialise());\n    } else {\n        // display all\n        for (index, c) in pending.iter().enumerate() {\n            println!(\"{index}. {}\", c.header());\n        }\n    }\n}\n"}},{"Blob":{"name":"qhar.rs","content":"use clap::ArgMatches;\n\nuse crate::core::State;\n\npub fn qhar(_: &mut State, _: &ArgMatches) {\n    println!(\".................................................................................................\\n.................................................................................................\\n.................................................................................................\\n.....-----:......:-:.......:--........:-:.......:------::......:----:....:-:....:---::...:::.....\\n..:-+#%%%%+=:...:+#=:......=#+:......-*#+:......=%%%%%%#*=:..:=*%%%%*-:.-+#=..-+#%%%#+-.:=#*-....\\n.:-%%#+=+#%%+:..-*%+:.....:=%*:.....:+%@#-.....:+%%++++#%%*-.=#%#+=#@#-.-#%=::+%%+=+%%+::+%#-....\\n.-#%=:...:=%%=..-*%+:.....:=%*:.....=#%#%*:....:+%*:...:=%%=-+#+:..-%%=.-*%=:-*#=..:=%#-:+%#-....\\n:+@*:.....:+%#-.-#%+-.....:+%*:....:+%*=#%-....:+%*-....-#%+:::....-%%=:-#%=:.::...:=%#-:+%#-....\\n-#@=:.....:=%%-.-#%+-------+%*:....-##=:+%+:...:+%*:...:=%%=:.....-+%*-.-*%=:.....:=#%+:.=%#-....\\n-#@=......:=%%=.-#@%%######%@*:...:+%+:.-##-:..:+%#====+#%*-.....-*%*-..-*%=.....:=#%+-.:=%#-....\\n-#@=:......=%%=.-#@#+======*@*:..:=##=::-+@*-..:+@%##%%@#=:.....-#%*-:..-*%=....:+%#=:..:=%#-....\\n-*@=:.....:=%%-.:#@+-.....:+%*:..:+@%*++*#@%=..:+%#=--=@#=:....:=%#-....-*#=....-#%+:....=%*-....\\n:+@*-.....-*%#:.:#@+:.....:=%*:..=#%######%@*-.:+%*:..:*%*-:...:-+=:....:==-....:++-.....-==:....\\n.-#%+-:.:-+%%=..:#%+-.....:=%*:.-*%*::::..=#%=::+%*-...-#%+-.....::......:::.....::.......::.....\\n.:-%%%*++#%%=:..-*%+:......+%+-:=%#=:.....-+@*-:+%*-....=%%=:..:=#+-...:-+*=:...:*#=:....=*+-....\\n...:=*#%%%@#=...:+*=:......=#=::+#+-.:.::.:-**-:=*=:.::::=#*-:..=*+-....:+*=....:**=.....=*+-....\\n....:::::-+%%+:..::........::-::---:::::::::-=-:::::--===+++==-::::......::......::.......::.....\\n..........:-=-.............:----==--:::::----===-:-=++*####++++=-:::----:::::::..................\\n..:........................:---===-----------==+=--=***+==+***++=--=+++++=--===-.................\\n.....::::::................:-====-------------===-:-------=+*****+++===++*+***+=:................\\n...:-==++++=--..::---:.....:-=======--======-:-=-......:..::-==++==-:::---====-::................\\n...:=+**#*+++=--==+++=-....-=--============-::-=-.......::::::-::::::::::.::::......:::..........\\n...::--==+++++++++***+-::.:------====+++===-----:......-===++====---====-:........:-===---::::...\\n......::=+**######**+-::...:--========*#+=---::...:::::=+++*####****####*=-:::.:.:=+#***+++===-:.\\n......::-==+++++==-:::...:...:--===---=*+-::.:......::-=********+++++****+++====---=++*+****+++==\\n..........::::::::::::....:..:.::-==---+*=::...::.:::::-=+*####+=---+###****#**++++=-----=+***+++\\n............::--======-------===-------+#+-:::::::::.::::-----=-:::--++*#######*+++++=-:::-=+*###\\n..........:.-=+++******++++=+***+=-----=*#-------:::::::-----------=+++********++****+=:::::--=++\\n....:.:...::-+***##########*+###+=-----=+#+=====----------=======++*################*+--::.:.::::\\n..::::::..::-+*****#+=======-==---=======++====----=--=======+*###****##*+++++++++===-------:::..\\n:-=====--:::-=+**###+---------------==++++====---------=======+*#####*++=-::-::::::::-=++++=+==--\\n-++*#*++==--==++====---:::--::::::--==========--------======---=++##++=--:::::::::::-=+*****##**+\\n:-=+++++*+=+++**=--::::::::--------======--------------=====--=+****+++==--:::::::--=+**+**######\\n.::-=++++++**#**=--::::::----========------------------------=+####*++++++++=-::-=++***###******+\\n.::-=+**+*##*+=--:::::::--:--========-----=======-----:--------==+**+*+++***+=--+#*******########\\n.:::-=======--:::::::::::-----=========++#*******+=--:::::::::::----==++****+++=+#*****++===+++++\\n.:.:::::::::::::::::::::::----======++############*+--::::::::::::::---=********+******+=--::::::\\n....:.::::---=====---::::------====+*#############**+=--::::::::::::::--=*#************=--::::::.\\n.:::---==++++++**++++=--::--------=+#######*+++##******=======--::::::::-=+*#########*+=======--:\\n:--=+++**************++---::::-----+*######*===+*#***#*+++****++-:::::::::--===++++==*******+++++\\n=++*****######********+--:::::::---=*#####*+=--=+**###+*#******+-::::::::.:::::::::-=+#########**\\n+******###************+--:::::::::--=+***+=-------=++==*#####*+=-:::..:..::::..:::::--=+*#######*\\n******##*==++********+=--:::::::::::---==--::::::------===++++=-:::::...:..:.::..:::-==*+********\\n#######*==+*********+--:::::::.::::::::..:::::--=+**+=---::::::::...::........:::--=+###*********\\n##**+==--=+*****###+=--::::...::.:..:.::..:::-++*****#*=--:::::....:...:..:.:::-=++**############\\n=--------=+########*+=--::::::..:.:.:..:::::-=**#**####**+=-::::::::--:..::.::-=*#*******#*++++++\\n::::::::--+#####******+=-:::.:.............::-==+#####*****+-::::-==++=-::.:::-=*####***+=-------\\n.:.:.::::--+**********#*+-:::............::.:::--==++**#****=--=++*****+-:::.::--=++*#*==--::::::\\n.......:::-=+****#*####*+-::::..............::::::--=+******=--+*#*#****=-:::.::::--==---::::....\\n......::::--=+*######*+==-::.........::.:.....:::::-=+******+===****#***=-:::::.::::::::.........\\n......:.::::--=***+==--:::...............::.....:::-=+**##********##***+=-:::....................\\n....:::.:::::--=---:::::.......................:.::-=+#**####****##***+=--::.:...................\\n................::.::..........................:.::--=*##########***++=-:::......................\");\n}\n"}},{"Blob":{"name":"tree.rs","content":"use clap::ArgMatches;\n\nuse crate::{core::State, utils};\n\npub fn tree(s: &mut State, _: &ArgMatches) {\n    println!(\"{}\", utils::generate_tree(&s.current));\n}\n"}},{"Blob":{"name":"mod.rs","content":"pub mod add;\npub mod branch;\npub mod cherry;\npub mod clone;\npub mod commit;\npub mod detach;\npub mod fetch;\npub mod init;\npub mod pending;\npub mod pull;\npub mod push;\npub mod qhar;\npub mod remove;\npub mod rollback;\npub mod staging;\npub mod stash;\npub mod test;\npub mod tree;\n\npub use add::add;\npub use branch::branch;\npub use cherry::cherry;\npub use clone::clone;\npub use commit::commit;\npub use detach::detach;\npub use fetch::fetch;\npub use init::init;\npub use pending::pending;\npub use pull::pull;\npub use push::push;\npub use qhar::qhar;\npub use remove::remove;\npub use rollback::rollback;\npub use staging::staging;\npub use stash::{restore, stash};\npub use test::test;\npub use tree::tree;\n"}},{"Blob":{"name":"branch.rs","content":"use clap::ArgMatches;\n\nuse crate::core::state::State;\n\npub fn branch(_: &mut State, _: &ArgMatches) {}\n"}},{"Blob":{"name":"remove.rs","content":"use std::{collections::HashSet, fs, path::PathBuf};\n\nuse clap::ArgMatches;\n\nuse crate::core::{\n    content_set::{ContentSet, TrackingSet},\n    paths::RELIC_PATH_TRACKED,\n    state::State,\n};\n\npub fn remove(s: &mut State, args: &ArgMatches) {\n    let f = args\n        .get_many::<PathBuf>(\"FILE\")\n        .unwrap()\n        .map(|x| x.clone())\n        .collect::<Vec<PathBuf>>();\n\n    let result: HashSet<String> = HashSet::from_iter(\n        fs::read_to_string(format!(\"./{RELIC_PATH_TRACKED}\"))\n            .unwrap()\n            .split(\"\\n\")\n            .filter(|x| !x.is_empty())\n            .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string())\n            .collect::<Vec<String>>(),\n    );\n\n    // initialise removed_content\n    let mut removed_content = ContentSet {\n        files: HashSet::from_iter(\n            f.iter()\n                .filter(|x| !x.is_dir())\n                .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string()),\n        ),\n        directories: HashSet::from_iter(\n            f.iter()\n                .filter(|x| x.is_dir())\n                .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string()),\n        ),\n    }\n    .initialise(&mut s.current);\n\n    let mut to_subtract: HashSet<String> = HashSet::from_iter(\n        removed_content\n            .directories\n            .drain()\n            .collect::<Vec<String>>()\n            .into_iter()\n            .map(|x| format!(\"{x}/\"))\n            .collect::<Vec<String>>(),\n    );\n    to_subtract = to_subtract\n        .union(&HashSet::from_iter(removed_content.files.drain()))\n        .map(|x| x.to_string())\n        .collect::<HashSet<String>>();\n\n    // set operations\n    // right join\n    // result - removed_content\n\n    let _ = fs::write(\n        format!(\"./{RELIC_PATH_TRACKED}\"),\n        result\n            .difference(&to_subtract)\n            .map(|x| x[2..].to_string())\n            .collect::<Vec<String>>()\n            .join(\"\\n\"),\n    );\n}\n"}},{"Blob":{"name":"stash.rs","content":"use clap::ArgMatches;\n\nuse crate::core::State;\n\npub fn stash(_: &mut State, _: &ArgMatches) {}\n\npub fn restore(_: &mut State, _: &ArgMatches) {}\n"}}]}},{"Blob":{"name":"cli.rs","content":"use std::collections::HashMap;\nuse std::path::PathBuf;\n\nuse clap::{arg, value_parser, ArgMatches, Command};\n\nuse crate::commands as command_module;\nuse crate::core::state::State;\nuse crate::error::RelicError;\n\n// add\n// commit {message}\n// push\n// pull\n// fetch\n// branch {name}\n//      will change to that branch\n//      if branch doesnt exist, create\n//      ask to create stash (if changes present)\n// stash {name|optional}\n//      stashes are bound to a branch\n//      optional to have a name\n// restore\n//      select stash to restore\n// rollback\n//      resets to current head\n// cherry {commit hash}\n\npub type CommandType = fn(&mut State, &ArgMatches);\n\npub struct CommandHandler {\n    commands: HashMap<String, CommandType>,\n    pub handler: Command,\n}\n\npub fn build() -> CommandHandler {\n    let mut command_handler = Command::new(\"relic\")\n        .about(\n            r#\"This is the Relic Version Control System.\n\nThe best way to learn is to stupidly and\nblindly reinvent the wheel.\n\nRelic is a simple hobby project, because\nremaking Git sounded fun and interesting.\n\nMost common features like committing,\npushing and pulling, are implemented.\"#,\n        )\n        .subcommand_required(true)\n        .arg_required_else_help(true);\n\n    type CommandType = fn(&mut State, &ArgMatches);\n    let mut commands: HashMap<String, CommandType> = HashMap::new();\n    for (f, c) in HashMap::<CommandType, clap::Command>::from_iter::<\n        Vec<(CommandType, clap::Command)>,\n    >(vec![\n        (\n            command_module::init,\n            Command::new(\"init\").about(\"Initialises a Relic repository in the current directory.\"),\n        ),\n        (\n            command_module::clone,\n            Command::new(\"clone\").about(\"Clone a remote Relic repository in the current directory.\")\n            .arg_required_else_help(true)\n            .arg(\n                arg!([URL] \"URL of the remote Relic repository\")\n                .required(true)\n            )\n        ),\n        (\n            command_module::detach,\n            Command::new(\"detach\").about(\"Completely removes Relic from the current directory.\")\n        ),\n        (\n            command_module::add,\n            Command::new(\"add\")\n                .about(\"Adds a file(s) to staging\")\n                .arg_required_else_help(true)\n                .arg(\n                    arg!([FILE]... \"File(s) to add (* for all)\")\n                        .required(true)\n                        .value_parser(value_parser!(PathBuf)),\n                ),\n        ),\n        (\n            command_module::remove,\n            Command::new(\"remove\")\n                .about(\"Removes a file(s) to staging\")\n                .arg_required_else_help(true)\n                .arg(\n                    arg!([FILE]... \"File(s) to remove (* for all)\")\n                        .required(true)\n                        .value_parser(value_parser!(PathBuf)),\n                ),\n        ),\n        (\n            command_module::commit,\n            Command::new(\"commit\")\n                .about(\"Commit current changes.\")\n                .arg_required_else_help(true)\n                .arg(arg!(-m --message <MESSAGE> \"Commit message\").required(true))\n                .arg(arg!(-d --description <DESCRIPTION> \"Commit description\")),\n        ),\n        (\n            command_module::push,\n            Command::new(\"push\").about(\"Pushes local changes to remote.\"),\n        ),\n        (\n            command_module::pull,\n            Command::new(\"pull\").about(\"Pull changes from remote to local.\"),\n        ),\n        (\n            command_module::fetch,\n            Command::new(\"fetch\").about(\"Check remote for new changes.\"),\n        ),\n        (\n            command_module::branch,\n            Command::new(\"branch\").about(\"\")\n        ),\n        (\n            command_module::stash,\n            Command::new(\"stash\")\n                // pseudo-commits basically\n                // clear stash after a commit\n                // stash create\n                // stash view\n                // stash restore\n                // stash delete\n                .about(\"\"),\n        ),\n        (\n            command_module::restore,\n            Command::new(\"restore\"), // unimplemented\n        ),\n        (\n            command_module::rollback,\n            Command::new(\"rollback\").about(\"Discard all current changes. Rolls back to most recent commit (or pending commit).\"),\n        ),\n        (\n            command_module::cherry,\n            Command::new(\"cherry\").about(\"Go to specific commit.\"),\n        ),\n        (\n            command_module::tree,\n            Command::new(\"tree\").about(\"Generate content tree of current directory.\"),\n        ),\n        (\n            command_module::staging,\n            Command::new(\"staging\").about(\"View all staging changes.\"),\n        ),\n        (\n            command_module::pending,\n            Command::new(\"pending\").about(\"View all pending commits.\")\n                .arg(arg!([COMMIT]... \"Commit number.\"))\n        ),\n        (\n            command_module::qhar,\n            Command::new(\"qhar\").about(\"??\")\n        ),\n        (\n            command_module::test,\n            Command::new(\"test\").about(\"this is here for debug purposes\")\n        )\n    ]) {\n        commands.insert(c.get_name().to_string(), f);\n        command_handler = command_handler.subcommand(c);\n    }\n\n    CommandHandler {\n        handler: command_handler,\n        commands: commands,\n    }\n}\n\npub fn handle(command_handler: CommandHandler, args: ArgMatches, state: Result<State, RelicError>) {\n    let (command_name, sub_matches) = args.subcommand().unwrap();\n\n    // TODO : shorten and undry this\n    if let Ok(mut s) = state {\n        match command_name {\n            \"clone\" | \"init\" => {\n                // let this run only for\n                // clone, init\n                println!(\"Unable to '{command_name}' an already existing Relic repository.\");\n                return;\n            }\n            _ => match command_handler.commands.get(command_name) {\n                Some(command) => {\n                    command(&mut s, sub_matches);\n                }\n                None => {\n                    unimplemented!(\"Relic Error, command not defined.\");\n                }\n            },\n        }\n    } else {\n        match command_name {\n            \"clone\" | \"init\" => {\n                // let this run only for\n                // clone, init\n                match command_handler.commands.get(command_name) {\n                    Some(command) => {\n                        command(&mut State::empty(), sub_matches);\n                    }\n                    None => {\n                        unimplemented!(\"Relic Error, command not defined.\");\n                    }\n                }\n            }\n            _ => {\n                println!(\"No valid Relic repository found in current directory. Consider executing 'relic init' or 'relic clone'.\");\n                return;\n            }\n        }\n    }\n}\n"}},{"Blob":{"name":"utils.rs","content":"use std::{\n    collections::{HashMap, HashSet},\n    path::PathBuf,\n    time::{Duration, SystemTime, UNIX_EPOCH},\n};\n\nuse chrono::{DateTime, Utc};\n\nuse crate::core::{modifications, Blob, Content, Tree};\n\nimpl Blob {\n    pub fn get_blame_header(\n        &self,\n        modifications: &HashMap<String, bool>,\n        blob_info: &Vec<modifications::Blob>,\n    ) -> String {\n        // returns:\n        // (-) earth\n        // (+) mars\n        // venus [+10, -10]\n\n        let mod_type: Option<bool> = modifications.get(&self.name).copied();\n\n        format!(\n            \"{}{} {}\",\n            match mod_type {\n                Some(m) => {\n                    if m {\n                        \"(+) \"\n                    } else {\n                        \"(-) \"\n                    }\n                }\n                None => \"\",\n            },\n            self.name.clone(),\n            if blob_info.is_empty() {\n                \"\".to_string()\n            } else {\n                format!(\n                    \"[+{}, -{}]\",\n                    blob_info\n                        .iter()\n                        .filter(|b| match b {\n                            modifications::Blob::Create(_, _, _, _) => true,\n                            _ => false,\n                        })\n                        .count(),\n                    blob_info\n                        .iter()\n                        .filter(|b| match b {\n                            modifications::Blob::Delete(_, _, _, _) => true,\n                            _ => false,\n                        })\n                        .count(),\n                )\n            }\n        )\n    }\n}\n\npub fn generate_blame_tree(\n    tree: &Tree,\n    tree_map: &HashMap<String, HashSet<modifications::Tree>>,\n    blob_map: &HashMap<String, HashMap<String, Vec<modifications::Blob>>>,\n) -> String {\n    return generate_blame_subtree(\n        &Content::Tree(tree.clone()),\n        PathBuf::from(\".\"),\n        tree_map,\n        blob_map,\n    );\n}\n\npub fn generate_blame_subtree(\n    c: &Content,\n    path: PathBuf,\n    tree_map: &HashMap<String, HashSet<modifications::Tree>>,\n    blob_map: &HashMap<String, HashMap<String, Vec<modifications::Blob>>>,\n) -> String {\n    let mut result = vec![];\n\n    let modifications =\n        tree_map\n            .get(&path.to_string_lossy().to_string())\n            .map_or(HashMap::new(), |h| {\n                h.into_iter()\n                    .map(|v| match v {\n                        modifications::Tree::CreateTree(_, n)\n                        | modifications::Tree::CreateBlob(_, n) => (n.to_string(), true),\n                        modifications::Tree::DeleteTree(_, n)\n                        | modifications::Tree::DeleteBlob(_, n) => (n.to_string(), false),\n                    })\n                    .collect::<HashMap<String, bool>>()\n            });\n\n    match c {\n        Content::Tree(t) => {\n            let name = t.name.clone();\n            let mut r = vec![name];\n            if t.content.len() >= 1 {\n                let length = t.content.len() - 1;\n                for (index, i) in t.content.iter().enumerate() {\n                    let mut p = path.clone();\n                    if !t.name.is_empty() {\n                        p = path.join(t.name.clone());\n                    }\n                    for (inner_index, line) in generate_blame_subtree(i, p, tree_map, blob_map)\n                        .split(\"\\n\")\n                        .enumerate()\n                    {\n                        r.push(format!(\n                            \" {} {line}\",\n                            if index == length {\n                                if inner_index == 0 {\n                                    \"└\"\n                                } else {\n                                    \"\"\n                                }\n                            } else {\n                                if inner_index == 0 {\n                                    \"├\"\n                                } else {\n                                    \"│\"\n                                }\n                            }\n                        ));\n                    }\n                }\n            }\n            result.push(r.join(\"\\n\"));\n        }\n        Content::Blob(b) => {\n            let blob_info = blob_map\n                .get(&path.to_string_lossy().to_string())\n                .map_or(vec![], |m| m.get(&b.name).unwrap_or(&vec![]).to_vec());\n\n            result.push(b.get_blame_header(&modifications, &blob_info));\n            // result.push(format!(\"{} ({})\", b.name, sha256::digest(&b.content)));\n        }\n    }\n\n    result.join(\"\\n\")\n}\n\npub fn generate_tree(tree: &Tree) -> String {\n    return generate_subtree(&Content::Tree(tree.clone()));\n}\n\nfn generate_subtree(c: &Content) -> String {\n    let mut result = vec![];\n\n    match c {\n        Content::Tree(t) => {\n            let mut r = vec![t.name.clone()];\n            if t.content.len() >= 1 {\n                let length = t.content.len() - 1;\n                for (index, i) in t.content.iter().enumerate() {\n                    for (inner_index, line) in generate_subtree(i).split(\"\\n\").enumerate() {\n                        r.push(format!(\n                            \" {} {line}\",\n                            if index == length {\n                                if inner_index == 0 {\n                                    \"└\"\n                                } else {\n                                    \"\"\n                                }\n                            } else {\n                                if inner_index == 0 {\n                                    \"├\"\n                                } else {\n                                    \"│\"\n                                }\n                            }\n                        ));\n                    }\n                }\n            }\n            result.push(r.join(\"\\n\"));\n        }\n        Content::Blob(b) => {\n            result.push(b.name.clone());\n            // result.push(format!(\"{} ({})\", b.name, sha256::digest(&b.content)));\n        }\n    }\n\n    result.join(\"\\n\")\n}\n\npub fn get_time() -> u64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .expect(\"time went backwards (???)\")\n        .as_millis() as u64\n}\n\npub fn into_human_readable(t: u64) -> String {\n    // accepts unix time, but only in milliseconds format\n    DateTime::<Utc>::from(UNIX_EPOCH + Duration::from_millis(t as u64))\n        .format(\"%Y-%m-%d %H:%M:%S\")\n        .to_string()\n}\n"}},{"Blob":{"name":"error.rs","content":"use serde::{Deserialize, Serialize};\n\n#[derive(Debug, Serialize, Deserialize)]\npub enum RelicError {\n    FileCantOpen,\n    IgnoredFile,\n    ConfigurationIncorrect,\n    RelicInfo(Box<RelicError>),\n}\n"}},{"Tree":{"path":"./src/core","name":"core","content":[{"Blob":{"name":"commit.rs","content":"use crate::{core::modifications::Change, utils};\n\nconst PENDING_TAG: &str = \"LOCAL\";\n\n#[derive(Debug, Clone)]\npub struct Commit {\n    pub id: Option<u32>,\n    pub message: String,\n    pub description: String,\n    pub change: Change,\n    pub timestamp: u64,\n\n    pub author: String,\n}\nimpl Commit {\n    pub fn header(&self) -> String {\n        // \"integrated backwards compatibility\" (2025-5-26 16:30) (affected : change.rs, content.rs, ...)\n\n        let file_names = self.change.get_affected_blobs();\n\n        format!(\n            \"({}) \\\"{}\\\" (affected : {}{})\",\n            utils::into_human_readable(self.timestamp),\n            self.message,\n            file_names\n                .iter()\n                .take(5)\n                .map(|x| x.to_string())\n                .collect::<Vec<String>>()\n                .join(\", \"),\n            if file_names.len() > 5 { \", ...\" } else { \"\" }\n        )\n    }\n\n    pub fn serialise(&self) -> String {\n        format!(\n            \"= {} {} {:?} {:?} {}\\n{}\",\n            self.id\n                .map_or(PENDING_TAG.to_string(), |i| format!(\"{:06x}\", i).clone()),\n            self.timestamp,\n            urlencoding::encode(&self.message).to_string(),\n            urlencoding::encode(&self.description).to_string(),\n            self.author,\n            self.change.serialise_changes()\n        )\n    }\n\n    pub fn deserialise(s: String) -> Option<Commit> {\n        // = LOCAL 1747682692319414000 \"initial%20commit\" \"\" no_one\n\n        let lines = s.split(\"\\n\").collect::<Vec<&str>>();\n        if lines.len() < 2 {\n            // return None;\n        }\n\n        let metadata = lines[0].split(\" \").collect::<Vec<&str>>();\n        if metadata.len() != 6 {\n            // return None;\n        }\n\n        let [_, status, time, message, description, author] = *metadata.as_slice() else {\n            return None;\n        };\n\n        Some(Commit {\n            id: status.parse::<u32>().map_or(None, |t| Some(t)),\n            message: urlencoding::decode(&message[1..message.len() - 1].to_string())\n                .unwrap()\n                .to_string(),\n            description: urlencoding::decode(&description[1..description.len() - 1].to_string())\n                .unwrap()\n                .to_string(),\n            change: Change::deserialise_changes(lines[1..].join(\"\\n\")).unwrap_or(Change::empty()),\n            timestamp: time.parse::<u64>().unwrap_or(0),\n            author: author.to_string(),\n        })\n    }\n}\n"}},{"Tree":{"path":"./src/core/objects","name":"objects","content":[{"Tree":{"path":"./src/core/objects/data","name":"data","content":[{"Blob":{"name":"content.rs","content":"use serde::{Deserialize, Serialize};\n\nuse crate::core::{Blob, Tree};\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub enum Content {\n    Tree(Tree),\n    Blob(Blob),\n}\nimpl Content {\n    pub fn get_name(&self) -> String {\n        match self {\n            Content::Tree(tree) => tree.name.clone(),\n            Content::Blob(blob) => blob.name.clone(),\n        }\n    }\n}\n\n#[derive(Debug)]\npub enum ContentMutRef<'a> {\n    Tree(&'a mut Tree),\n    Blob(&'a mut Blob),\n}\n"}},{"Blob":{"name":"tree.rs","content":"use std::{\n    collections::{HashMap, HashSet},\n    path::PathBuf,\n    sync::{Arc, Mutex},\n};\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::core::{\n    modifications::{self, Change},\n    Blob, Content, ContentMutRef,\n};\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub struct Tree {\n    pub path: PathBuf,\n    pub name: String,\n    pub content: Vec<Content>,\n}\n\nimpl Tree {\n    pub fn new() -> Tree {\n        Tree {\n            path: PathBuf::from(\".\"),\n            name: \"\".to_string(),\n            content: vec![],\n        }\n    }\n\n    // pub fn get_hash(&self) -> String {\n    //     sha256::digest(serde_json::to_string(&self).unwrap())\n    // }\n\n    // pub fn deserialise(s: String) -> Option<Tree> {\n    //     match serde_json::from_str(&s) {\n    //         Ok(d) => Some(d),\n    //         _ => None,\n    //     }\n    // }\n\n    // pub fn deserialise_content(s: String) -> Option<Vec<Content>> {\n    //     // used only for init\n    //     // same as deserialise, but only content, no name or path\n    //     match serde_json::from_str(&s) {\n    //         Ok(d) => Some(d),\n    //         _ => None,\n    //     }\n    // }\n\n    // pub fn serialise(&self) -> String {\n    //     serde_json::to_string_pretty(&self).unwrap()\n    // }\n\n    pub fn apply_changes(&mut self, changes: &Change) {\n        let (c_mod_map, mod_map) = changes.as_map();\n        let c_mod_map = Arc::new(Mutex::new(c_mod_map));\n\n        // two pass\n        // create/delete containers, then create/delete file content\n\n        self.traverse(\n            PathBuf::from(\".\"),\n            &|_, _, current| {\n                if let ContentMutRef::Tree(t) = current {\n                    // somehow denote that the parent does not yet exist,\n                    // possibly recursively create trees where needed\n\n                    // TODO : optimise the match arms\n                    let mut c_mod_map_lock = c_mod_map.lock().unwrap();\n                    if let Some(c_modifications) =\n                        c_mod_map_lock.get(&t.path.to_string_lossy().to_string())\n                    {\n                        let c_clone = c_modifications.clone();\n\n                        // deals with additions\n                        t.content.append(&mut recursive_birth(\n                            &PathBuf::from(t.path.clone()),\n                            &mut c_mod_map_lock,\n                        ));\n\n                        let mut deleted_containers = HashSet::new();\n                        // deals with subtractions\n                        for c_mod in &c_clone {\n                            match c_mod {\n                                modifications::Tree::DeleteTree(_, n) => {\n                                    deleted_containers.insert(n);\n                                }\n                                modifications::Tree::DeleteBlob(_, n) => {\n                                    deleted_containers.insert(n);\n                                }\n                                _ => {}\n                            }\n                        }\n\n                        t.content = t\n                            .content\n                            .iter()\n                            .filter(|x| {\n                                !deleted_containers.contains(match x {\n                                    Content::Blob(b) => &b.name,\n                                    Content::Tree(t) => &t.name,\n                                })\n                            })\n                            .map(|x| x.clone())\n                            .collect::<Vec<Content>>();\n                    }\n                }\n            },\n            &Tree::new(),\n        );\n\n        self.traverse(\n            PathBuf::from(\".\"),\n            &|path, _, current| {\n                if let ContentMutRef::Blob(f) = current {\n                    if let Some(modifications) = mod_map\n                        .get(&path.to_string_lossy().to_string())\n                        .map_or(None, |x| x.get(&f.name))\n                    {\n                        f.apply_changes(modifications);\n                    }\n                }\n            },\n            &self.clone(),\n        );\n\n        pub fn recursive_birth(\n            parent_directory: &PathBuf,\n            c_mod_map: &mut HashMap<String, HashSet<modifications::Tree>>,\n        ) -> Vec<Content> {\n            // pass the new directory's parent directory\n            let mut result = vec![];\n            if let Some(c_modifications) =\n                c_mod_map.get_mut(&parent_directory.to_string_lossy().to_string())\n            {\n                let c_clone = c_modifications.clone();\n                for c in &c_clone {\n                    c_modifications.remove(&c);\n                }\n                for c_mod in c_clone {\n                    match c_mod {\n                        modifications::Tree::CreateTree(_, n) => {\n                            result.push(Content::Tree(Tree {\n                                path: parent_directory.join(n.clone()),\n                                name: n.clone(),\n                                content: recursive_birth(\n                                    &parent_directory.join(n.clone()),\n                                    c_mod_map,\n                                ),\n                            }));\n                        }\n                        modifications::Tree::CreateBlob(_, n) => result.push(Content::Blob(Blob {\n                            name: n.clone(),\n                            content: \"\".to_string(),\n                        })),\n                        _ => {}\n                    }\n                }\n            }\n            result\n        }\n    }\n\n    pub fn unapply_changes(&mut self, changes: &Change) {\n        // TODO : test if 100% reliable\n        let changes = changes.inverse();\n        self.apply_changes(&changes);\n        // TODO : update upstream?\n    }\n\n    pub fn traverse<F>(&mut self, root_path: PathBuf, func: &F, parent: &Tree)\n    where\n        // parent path, parent tree, current content\n        F: Fn(&PathBuf, &Tree, ContentMutRef),\n    {\n        func(&root_path, &parent, ContentMutRef::Tree(self));\n\n        let c = self.clone();\n        for content in &mut self.content {\n            match content {\n                Content::Tree(t) => {\n                    t.traverse(root_path.join(t.name.clone()), func, &c);\n                }\n                Content::Blob(b) => {\n                    func(&root_path, &c, ContentMutRef::Blob(b));\n                }\n            }\n        }\n    }\n}\n"}},{"Blob":{"name":"upstream.rs","content":"// upstream might be stored in differing formats\n// this is here to ensure backwards compatibility with outdated standards and etc\n\nuse std::{fs, path::PathBuf};\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    core::{Content, Tree},\n    error::RelicError,\n};\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\npub struct Upstream {\n    pub convention: String, // used for backwards compatibility\n    pub content: Vec<Content>,\n}\nimpl Upstream {\n    pub fn empty() -> Upstream {\n        Upstream {\n            convention: \"0.0.1\".to_string(),\n            content: vec![],\n        }\n    }\n\n    pub fn tree(self) -> Tree {\n        Tree {\n            path: PathBuf::from(\".\"),\n            name: \"\".to_string(),\n            content: self.content,\n        }\n    }\n\n    pub fn from_tree(tree: &Tree) -> Upstream {\n        Upstream {\n            convention: \"0.0.1\".to_string(),\n            content: tree.content.clone(),\n        }\n    }\n\n    pub fn serialise(&self) -> String {\n        serde_json::to_string(&self).unwrap()\n    }\n\n    pub fn deserialise(path: &str) -> Result<Upstream, RelicError> {\n        match fs::read_to_string(path) {\n            Ok(data) => match serde_json::from_str::<Upstream>(&data) {\n                Ok(u) => Ok(u),\n                // TODO: implement backwards compatibility\n                Err(_) => Err(RelicError::ConfigurationIncorrect),\n            },\n            Err(_) => Err(RelicError::FileCantOpen),\n        }\n    }\n}\n"}},{"Blob":{"name":"blob.rs","content":"use std::{fs, path::PathBuf};\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::{core::modifications, error::RelicError};\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub struct Blob {\n    pub name: String,\n    pub content: String,\n}\n\nimpl Blob {\n    pub fn new() -> Blob {\n        Blob {\n            name: \"\".to_string(),\n            content: \"\".to_string(),\n        }\n    }\n\n    pub fn create(name: String, path: PathBuf) -> Result<Blob, RelicError> {\n        match fs::read_to_string(path) {\n            Ok(content) => Ok(Blob {\n                name: name,\n                content: content,\n            }),\n            Err(_) => Err(RelicError::FileCantOpen),\n        }\n    }\n\n    pub fn apply_changes(&mut self, modifications: &Vec<modifications::Blob>) {\n        // TODO : investigate whether an additional newline is added to eof\n        // BUG : when the file has only one line, diffs start to break\n        //\n        // content : \"\"\n        // Create(,, 0, \"something\")\n        // result : \"something\\nsomething\"\n        //\n        // content : \"something\\nsomething\"\n        // Delete(,, 0)\n        // result : \"\"\n\n        // CHANGES ARE BEING APPLIED TO THE WRONG FILE\n        // APPLY CHANGES TO UPSTREAM, NOT CURRENT\n\n        // TODO : revise modification order\n\n        // deletions first then creations?\n        //      sorted largest to smallest\n        // creations sorted smallest to largest?\n        let mut lines = self\n            .content\n            .split(\"\\n\")\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>();\n\n        let mut modifications = modifications.clone();\n        modifications.sort_by_key(|m| match m {\n            modifications::Blob::Create(_, _, l, _) => *l as i128,\n            modifications::Blob::Delete(_, _, l, _) => -(*l as i128),\n        });\n\n        for m in &modifications {\n            match m {\n                modifications::Blob::Create(_, _, line, content) => {\n                    // insert at that line\n                    lines.insert(*line, content.clone());\n                }\n                modifications::Blob::Delete(_, _, line, _) => {\n                    // delete that line\n                    lines.remove(*line);\n                }\n            }\n        }\n\n        self.content = lines.join(\"\\n\");\n    }\n}\n"}},{"Blob":{"name":"mod.rs","content":"pub mod blob;\npub mod content;\npub mod content_set;\npub mod tree;\npub mod upstream;\n\npub use blob::Blob;\npub use tree::Tree;\n\npub use content::{Content, ContentMutRef};\npub use upstream::Upstream;\n"}},{"Blob":{"name":"content_set.rs","content":"use std::{\n    collections::HashSet,\n    path::PathBuf,\n    sync::{Arc, Mutex},\n};\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::core::{ContentMutRef, Tree};\n\npub const DEFAULT_IGNORE: &str = r#\"-- Added by Relic: Automatically ignore all git content\n.git/\n.gitignore\"#;\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\npub struct ContentSet {\n    pub directories: HashSet<String>,\n    pub files: HashSet<String>,\n}\nimpl ContentSet {\n    pub fn empty() -> ContentSet {\n        ContentSet {\n            directories: HashSet::new(),\n            files: HashSet::new(),\n        }\n    }\n}\n\npub trait IgnoreSet {\n    fn create(content: String) -> Self;\n}\nimpl IgnoreSet for ContentSet {\n    fn create(content: String) -> ContentSet {\n        let mut result = ContentSet {\n            directories: HashSet::new(),\n            files: HashSet::new(),\n        };\n\n        // always ignore the .relic directory\n        result.directories.insert(\".relic\".to_string());\n\n        for line in content.split(\"\\n\") {\n            if line.is_empty() {\n                continue;\n            }\n\n            // skip comments\n            if line.starts_with(\"-- \") {\n                continue;\n            }\n\n            // doesnt take into account cases like\n            // some_directory// <- double slashes\n            if line.ends_with(\"/\") {\n                let i = line[0..line.len() - 1].to_string();\n                if i.is_empty() {\n                    continue;\n                }\n\n                result.directories.insert(i);\n            } else {\n                result.files.insert(line.to_string());\n            }\n        }\n\n        result\n    }\n}\n\npub trait TrackingSet {\n    fn deserialise(content: String) -> Self;\n    fn initialise(&self, d: &mut Tree) -> Self;\n}\nimpl TrackingSet for ContentSet {\n    fn deserialise(content: String) -> Self {\n        let mut result = ContentSet::empty();\n\n        for d in content\n            .split(\"\\n\")\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>()\n        {\n            if d.ends_with(\"/\") {\n                // dir\n                result.directories.insert(d[..d.len() - 1].to_string());\n            } else {\n                // file\n                result.files.insert(d);\n            }\n        }\n\n        result\n    }\n\n    fn initialise(&self, d: &mut Tree) -> ContentSet {\n        let tracked_mutex = Arc::new(Mutex::new(self.clone()));\n        d.traverse(\n            PathBuf::from(\".\"),\n            &|path, _, current| {\n                // println!(\"traversing at : {path:?}\");\n\n                let mut tracked_unlock = tracked_mutex.lock().unwrap();\n\n                match current {\n                    ContentMutRef::Tree(t) => {\n                        // if parent in set\n                        // add to content set\n                        if tracked_unlock\n                            .directories\n                            .contains(&t.path.parent().unwrap().to_string_lossy().to_string())\n                        {\n                            tracked_unlock\n                                .directories\n                                .insert(t.path.to_string_lossy().to_string());\n                        }\n                    }\n                    ContentMutRef::Blob(b) => {\n                        if tracked_unlock\n                            .directories\n                            .contains(&path.to_string_lossy().to_string())\n                        {\n                            tracked_unlock\n                                .files\n                                .insert(path.join(&b.name).to_string_lossy().to_string());\n                        }\n                    }\n                }\n            },\n            &d.clone(),\n        );\n\n        // dont ask me\n        let result = tracked_mutex.lock().unwrap().clone();\n        result\n    }\n}\n"}}]}},{"Blob":{"name":"mod.rs","content":"pub mod data;\npub mod modifications;\n\npub use data::{content_set, Blob, Content, ContentMutRef, Tree};\n"}},{"Tree":{"path":"./src/core/objects/modifications","name":"modifications","content":[{"Blob":{"name":"container.rs","content":"use serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq, PartialOrd, Ord)]\npub enum Tree {\n    // denote that parent doesnt exist?\n\n    // creation/deletion of files & folders\n    CreateTree(\n        String, // parent directory\n        String, // name\n    ),\n    DeleteTree(\n        String, // parent directory\n        String, // name\n    ),\n\n    CreateBlob(\n        String, // parent directory\n        String, // name\n    ),\n    DeleteBlob(\n        String, // parent directory\n        String, // name\n    ),\n}\nimpl Tree {\n    pub fn extract_data(&self) -> (String, String) {\n        match self {\n            Tree::CreateTree(path, name)\n            | Tree::DeleteTree(path, name)\n            | Tree::CreateBlob(path, name)\n            | Tree::DeleteBlob(path, name) => (path.clone(), name.clone()),\n        }\n    }\n\n    pub fn serialise(&self) -> String {\n        format!(\n            \"{} {}\",\n            match self {\n                Tree::CreateTree(_, _) => {\n                    \"+ D\"\n                }\n                Tree::DeleteTree(_, _) => {\n                    \"- D\"\n                }\n                Tree::CreateBlob(_, _) => {\n                    \"+ F\"\n                }\n                Tree::DeleteBlob(_, _) => {\n                    \"- F\"\n                }\n            },\n            match self {\n                Tree::CreateTree(p, n)\n                | Tree::DeleteTree(p, n)\n                | Tree::CreateBlob(p, n)\n                | Tree::DeleteBlob(p, n) => {\n                    format!(\n                        \"{} {}\",\n                        urlencoding::encode(&p).to_string(),\n                        urlencoding::encode(&n).to_string()\n                    )\n                }\n            }\n        )\n    }\n}\n"}},{"Tree":{"path":"./src/core/objects/modifications/change","name":"change","content":[{"Blob":{"name":"mod.rs","content":"mod constructor;\nmod filter;\nmod inverse;\nmod serialisation;\n\nuse std::{\n    collections::{HashMap, HashSet},\n    thread::current,\n};\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    core::{content_set::ContentSet, modifications, State, Tree},\n    utils,\n};\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub struct Change {\n    pub trees: Vec<modifications::Tree>,\n    pub blobs: Vec<modifications::Blob>,\n}\nimpl Change {\n    pub fn empty() -> Change {\n        Change {\n            trees: vec![],\n            blobs: vec![],\n        }\n    }\n\n    pub fn get_affected_blobs(&self) -> Vec<String> {\n        let mut blobs = vec![];\n        for (_, parent) in self.as_map().1 {\n            blobs.append(&mut parent.iter().map(|f| f.0.to_string()).collect())\n        }\n        blobs\n    }\n\n    pub fn as_human_readable(&self, current_upstream: &Tree) -> String {\n        // HashMap<String, HashSet<modifications::Tree>>,\n        // HashMap<String, HashMap<String, Vec<modifications::Blob>>>,\n\n        let mut changes = self.clone();\n        changes.trees = changes\n            .trees\n            .clone()\n            .into_iter()\n            .filter(|t| match t {\n                modifications::Tree::DeleteBlob(_, _) | modifications::Tree::DeleteTree(_, _) => {\n                    false\n                }\n                _ => true,\n            })\n            .collect::<Vec<modifications::Tree>>();\n\n        let (tree_map, blob_map) = self.as_map();\n\n        let mut current_upstream = current_upstream.clone();\n        current_upstream.apply_changes(&changes);\n\n        /*\n            {full change}\n\n            repo_name\n             ├ (+) saturn\n             ├ (-) jupiter\n             └ huh/mod.rs [+11, -52]\n\n            x files affected, x additions, x deletions\n        */\n\n        let affected_files = blob_map\n            .iter()\n            .map(|(_, v)| v.keys().count())\n            .sum::<usize>();\n\n        let addition = blob_map\n            .iter()\n            .map(|(_, v)| {\n                v.iter()\n                    .map(|(_, b)| {\n                        b.iter()\n                            .filter(|i| match i {\n                                modifications::Blob::Create(_, _, _, _) => true,\n                                _ => false,\n                            })\n                            .count()\n                    })\n                    .sum::<usize>()\n            })\n            .sum::<usize>();\n\n        let deletion = blob_map\n            .iter()\n            .map(|(_, v)| {\n                v.iter()\n                    .map(|(_, b)| {\n                        b.iter()\n                            .filter(|i| match i {\n                                modifications::Blob::Delete(_, _, _, _) => true,\n                                _ => false,\n                            })\n                            .count()\n                    })\n                    .sum::<usize>()\n            })\n            .sum::<usize>();\n\n        format!(\n            \"{}\\n\\n{}\\n\\n{affected_files} files affected, {} additions, {} deletions\",\n            self.serialise_changes(),\n            utils::generate_blame_tree(&current_upstream, &tree_map, &blob_map),\n            addition,\n            deletion\n        )\n    }\n\n    pub fn as_map(\n        &self,\n    ) -> (\n        HashMap<String, HashSet<modifications::Tree>>,\n        HashMap<String, HashMap<String, Vec<modifications::Blob>>>,\n    ) {\n        // tree_map: map<parent_directory, Vec<changes>>\n        // blob_map: map<parent_directory, map<file_name, Vec<changes>>>\n\n        let mut tree_map = HashMap::new();\n        for tree_modification in &self.trees {\n            let path = match tree_modification {\n                modifications::Tree::CreateTree(path, _)\n                | modifications::Tree::DeleteTree(path, _)\n                | modifications::Tree::CreateBlob(path, _)\n                | modifications::Tree::DeleteBlob(path, _) => path.clone(),\n            };\n\n            assert_eq!(path, tree_modification.extract_data().0);\n\n            tree_map\n                .entry(path)\n                .or_insert(HashSet::new())\n                .insert(tree_modification.clone());\n        }\n\n        let mut blob_map = HashMap::new();\n        for blob_modification in &self.blobs {\n            let (parent_directory, file_name) = match blob_modification {\n                modifications::Blob::Create(path, name, _, _) => (path.clone(), name.clone()),\n                modifications::Blob::Delete(path, name, _, _) => (path.clone(), name.clone()),\n            };\n\n            assert_eq!(\n                (parent_directory.clone(), file_name.clone()),\n                blob_modification.extract_path()\n            );\n            blob_map\n                .entry(parent_directory)\n                .or_insert(HashMap::new())\n                .entry(file_name)\n                .or_insert(vec![])\n                .push(blob_modification.clone());\n        }\n\n        (tree_map, blob_map)\n    }\n}\n"}},{"Blob":{"name":"constructor.rs","content":"use std::{\n    collections::{HashMap, HashSet},\n    path::Path,\n};\n\nuse similar::{ChangeTag, TextDiff};\n\nuse crate::core::{modifications, Blob, Content, Tree};\n\nuse super::Change;\n\nimpl Change {\n    pub fn get_change(\n        path: String,\n        upstream_blob: &Blob,\n        current_blob: &Blob,\n    ) -> Vec<modifications::Blob> {\n        // https://blog.jcoglan.com/2017/02/15/the-myers-diff-algorithm-part-2/\n        // for our change algorithm, we will be using myers diff algorithm\n        // basically a shortest distance problem, with downwards, rightwards and diagonal directions as movement choices\n        // (note that diagonal movements do not contribute towards the distance)\n\n        // similar does not handle newlines at eof well at all\n        // this is the workaround for it\n        let upstream = format!(\"{}\\n\", upstream_blob.content.clone());\n        let current = format!(\"{}\\n\", current_blob.content.clone());\n\n        // TODO : compare hashes instead of blobs\n        if upstream == current {\n            return vec![];\n        }\n\n        let mut result = vec![];\n        let diff = TextDiff::from_lines(&upstream, &current);\n\n        for change in diff.iter_all_changes().filter_map(|c| match c.tag() {\n            ChangeTag::Equal => None,\n            _ => Some(c),\n        }) {\n            result.push(match change.tag() {\n                ChangeTag::Delete => modifications::Blob::Delete(\n                    path.clone(),\n                    current_blob.name.clone(),\n                    change.old_index().unwrap(),\n                    change.to_string().strip_suffix(\"\\n\").unwrap().to_string(),\n                ),\n                ChangeTag::Insert => modifications::Blob::Create(\n                    path.clone(),\n                    current_blob.name.clone(),\n                    change.new_index().unwrap(),\n                    change.to_string().strip_suffix(\"\\n\").unwrap().to_string(),\n                ),\n                _ => panic!(\"Unmatched change type: {}\", change),\n            })\n        }\n\n        result\n    }\n\n    pub fn get_change_all(upstream: &Tree, current: &Tree, path: &Path) -> Change {\n        // assume that both current and previous have the same tree names\n        // has to be bfs\n\n        // initialise current state set\n        let mut current_set = HashSet::new();\n        let mut current_map = HashMap::new();\n        for c in &current.content {\n            match c {\n                Content::Tree(t) => {\n                    current_set.insert((t.name.clone(), false));\n                    current_map.insert((t.name.clone(), false), c);\n                }\n                Content::Blob(b) => {\n                    current_set.insert((b.name.clone(), true));\n                    current_map.insert((b.name.clone(), true), c);\n                }\n            }\n        }\n        //\n\n        // initialise upstream state set\n        let mut upstream_set = HashSet::new();\n        let mut upstream_map = HashMap::new();\n        for c in &upstream.content {\n            match c {\n                Content::Tree(t) => {\n                    upstream_set.insert((t.name.clone(), false));\n                    upstream_map.insert((t.name.clone(), false), c);\n                }\n                Content::Blob(b) => {\n                    upstream_set.insert((b.name.clone(), true));\n                    upstream_map.insert((b.name.clone(), true), c);\n                }\n            }\n        }\n        //\n\n        // use set differences to determine blob and tree creation or deletion\n        let deleted = upstream_set\n            .difference(&current_set)\n            .map(|(n, t)| (n.to_string(), *t))\n            .collect::<Vec<(String, bool)>>();\n        let created = current_set\n            .difference(&upstream_set)\n            .map(|(n, t)| (n.to_string(), *t))\n            .collect::<Vec<(String, bool)>>();\n        //\n\n        // for all deleted blobs, log them\n        // for all deleted trees, log them and do the same for all children\n        let mut container_modifications = vec![];\n        let mut modifications = vec![];\n        for (name, is_blob) in deleted {\n            if is_blob {\n                container_modifications.push(modifications::Tree::DeleteBlob(\n                    path.to_string_lossy().to_string(),\n                    name,\n                ));\n            } else {\n                container_modifications.push(modifications::Tree::DeleteTree(\n                    path.to_string_lossy().to_string(),\n                    name.clone(),\n                ));\n                // traverse all children, add them to result as well\n                let mut changes = Change::get_change_all(\n                    match upstream_map.get(&(name.clone(), false)).unwrap() {\n                        Content::Tree(deleted_tree) => deleted_tree,\n                        _ => panic!(),\n                    },\n                    &Tree::new(),\n                    &path.join(name.clone()),\n                );\n                container_modifications.append(&mut changes.trees);\n                modifications.append(&mut changes.blobs);\n            }\n        }\n        //\n\n        // for all created blobs, log them\n        // for all created trees, log them and do the same for all children\n        for (name, is_blob) in created {\n            if is_blob {\n                container_modifications.push(modifications::Tree::CreateBlob(\n                    path.to_string_lossy().to_string(),\n                    name.clone(),\n                ));\n                modifications.append(&mut Change::get_change(\n                    path.to_string_lossy().to_string(),\n                    &Blob::new(),\n                    match current_map.get(&(name, true)).unwrap() {\n                        Content::Blob(b) => b,\n                        _ => panic!(),\n                    },\n                ))\n            } else {\n                container_modifications.push(modifications::Tree::CreateTree(\n                    path.to_string_lossy().to_string(),\n                    name.clone(),\n                ));\n\n                let mut changes = Change::get_change_all(\n                    &Tree::new(),\n                    match current_map.get(&(name.clone(), false)).unwrap() {\n                        Content::Tree(t) => t,\n                        _ => panic!(),\n                    },\n                    &path.join(name.clone()),\n                );\n                container_modifications.append(&mut changes.trees);\n                modifications.append(&mut changes.blobs);\n            }\n        }\n\n        for content in &current.content {\n            match content {\n                Content::Tree(tree) => {\n                    // get the matching upstream tree\n                    // if it doesnt exist, that means the content is new and can be ignored\n                    // we ignore it because we have already logged it in the section above\n                    let p = path.join(tree.name.clone());\n                    let upstream_tree = match upstream_map.get(&(tree.name.clone(), false)) {\n                        Some(u) => match u {\n                            Content::Tree(u_t) => u_t,\n                            _ => panic!(),\n                        },\n                        _ => {\n                            continue;\n                        }\n                    };\n                    //\n\n                    let mut changes = Change::get_change_all(upstream_tree, tree, &p);\n                    container_modifications.append(&mut changes.trees);\n                    modifications.append(&mut changes.blobs);\n                }\n                Content::Blob(b) => {\n                    let upstream_blob = match upstream_map.get(&(b.name.clone(), true)) {\n                        Some(c) => match c {\n                            Content::Blob(b) => b,\n                            _ => panic!(),\n                        },\n                        None => {\n                            continue;\n                        }\n                    };\n\n                    modifications.append(&mut Change::get_change(\n                        path.to_string_lossy().to_string(),\n                        &upstream_blob,\n                        &b,\n                    ));\n                }\n            }\n        }\n\n        Change {\n            trees: container_modifications,\n            blobs: modifications,\n        }\n    }\n}\n"}},{"Blob":{"name":"filter.rs","content":"use std::path::PathBuf;\n\nuse crate::core::{content_set::ContentSet, modifications};\n\nuse super::Change;\n\nimpl Change {\n    pub fn filter_changes(&self, filter: &ContentSet) -> Change {\n        Change {\n            trees: self\n                .trees\n                .clone()\n                .into_iter()\n                .filter(|c_mod| match c_mod {\n                    modifications::Tree::CreateBlob(p, n)\n                    | modifications::Tree::DeleteBlob(p, n) => filter\n                        .files\n                        .contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),\n                    modifications::Tree::CreateTree(p, n)\n                    | modifications::Tree::DeleteTree(p, n) => filter\n                        .directories\n                        .contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),\n                })\n                .collect(),\n            blobs: self\n                .blobs\n                .clone()\n                .into_iter()\n                .filter(|m| {\n                    // if only can map a tuple\n                    filter.files.contains(&match m {\n                        modifications::Blob::Create(p, n, _, _)\n                        | modifications::Blob::Delete(p, n, _, _) => {\n                            PathBuf::from(p).join(n).to_string_lossy().to_string()\n                        }\n                    })\n                })\n                .collect(),\n        }\n    }\n}\n"}},{"Blob":{"name":"inverse.rs","content":"use crate::core::modifications;\n\nuse super::Change;\n\nimpl Change {\n    pub fn inverse(&self) -> Change {\n        // TODO: test\n\n        // returns inverse of the change\n        // all additions are deletions and vice versa\n\n        // the order does not follow the optimised/intuitive format\n        // additions will appear before deletions if inversed\n        // but relic will always apply changes in the correct order regardless\n\n        Change {\n            trees: self\n                .trees\n                .iter()\n                .map(|c| match c {\n                    modifications::Tree::CreateBlob(p, n) => {\n                        modifications::Tree::DeleteBlob(p.to_string(), n.to_string())\n                    }\n                    modifications::Tree::CreateTree(p, n) => {\n                        modifications::Tree::DeleteTree(p.to_string(), n.to_string())\n                    }\n                    modifications::Tree::DeleteBlob(p, n) => {\n                        modifications::Tree::CreateBlob(p.to_string(), n.to_string())\n                    }\n                    modifications::Tree::DeleteTree(p, n) => {\n                        modifications::Tree::CreateTree(p.to_string(), n.to_string())\n                    }\n                })\n                .collect::<Vec<modifications::Tree>>(),\n            blobs: self\n                .blobs\n                .iter()\n                .map(|m| match m {\n                    modifications::Blob::Create(p, f, l, t) => {\n                        modifications::Blob::Delete(p.to_string(), f.to_string(), *l, t.to_string())\n                    }\n                    modifications::Blob::Delete(p, f, l, t) => {\n                        modifications::Blob::Create(p.to_string(), f.to_string(), *l, t.to_string())\n                    }\n                })\n                .collect::<Vec<modifications::Blob>>(),\n        }\n    }\n}\n"}},{"Blob":{"name":"serialisation.rs","content":"use std::collections::HashMap;\n\nuse crate::core::modifications;\n\nuse super::Change;\n\nimpl Change {\n    pub fn serialise_changes(&self) -> String {\n        // + D . src\n        // + F .%2Fsrc utils.rs\n        // + F .%2Fsrc branch.rs\n        // =\n        // | .%2Fsrc content.rs\n        // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\"\n        // + 1 \"\"\n\n        // final result string\n        let mut result: Vec<String> = vec![];\n\n        for tree in &self.trees {\n            result.push(tree.serialise());\n        }\n\n        result.push(\"=\".to_string()); // container and blob section separator\n\n        let mut blob_sections = HashMap::new();\n        for blob in &self.blobs {\n            blob_sections\n                .entry(blob.extract_path())\n                .or_insert(vec![])\n                .push(blob.clone());\n        }\n\n        let mut keys = blob_sections\n            .iter()\n            .map(|x| x.0.clone())\n            .collect::<Vec<(String, String)>>();\n\n        keys.sort();\n\n        for (path, name) in keys {\n            let modifications = blob_sections.get(&(path.clone(), name.clone())).unwrap();\n            result.push(format!(\n                \"| {} {}\",\n                urlencoding::encode(&path).to_string(),\n                urlencoding::encode(&name).to_string()\n            ));\n            for blob in modifications {\n                result.push(blob.extract_change());\n            }\n        }\n\n        result.join(\"\\n\")\n    }\n\n    pub fn deserialise_changes(s: String) -> Option<Change> {\n        // + D . src\n        // + F .%2Fsrc utils.rs\n        // + F .%2Fsrc branch.rs\n        // =\n        // | .%2Fsrc content.rs\n        // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\"\n        // + 1 \"\"\n\n        let lines = s\n            .split(\"\\n\")\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>();\n\n        let mut result = Change::empty();\n        let mut tree_section = true;\n\n        let mut previous_blob = None;\n        for l in lines {\n            if tree_section && (l == \"=\") {\n                tree_section = false;\n                continue;\n            }\n            let content = l.split(\" \").collect::<Vec<&str>>();\n\n            if tree_section {\n                let [species, container, parent, name] = *content.as_slice() else {\n                    return None;\n                };\n\n                result.trees.push(match (species, container) {\n                    (\"+\", \"D\") => modifications::Tree::CreateTree(\n                        urlencoding::decode(parent).unwrap().to_string(),\n                        urlencoding::decode(name).unwrap().to_string(),\n                    ),\n                    (\"-\", \"D\") => modifications::Tree::DeleteTree(\n                        urlencoding::decode(parent).unwrap().to_string(),\n                        urlencoding::decode(name).unwrap().to_string(),\n                    ),\n                    (\"+\", \"F\") => modifications::Tree::CreateBlob(\n                        urlencoding::decode(parent).unwrap().to_string(),\n                        urlencoding::decode(name).unwrap().to_string(),\n                    ),\n                    (\"-\", \"F\") => modifications::Tree::DeleteBlob(\n                        urlencoding::decode(parent).unwrap().to_string(),\n                        urlencoding::decode(name).unwrap().to_string(),\n                    ),\n                    _ => {\n                        println!(\"invalid tree\");\n                        return None;\n                    }\n                });\n            } else {\n                if content[0] == \"|\" {\n                    // | .%2Fsrc content.rs\n                    let [_, parent, name] = *content.as_slice() else {\n                        println!(\"invalid blob header\");\n                        return None;\n                    };\n\n                    previous_blob = Some((parent.to_string(), name.to_string()));\n                } else {\n                    // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\"\n                    if content.len() < 2 {\n                        println!(\"invalid change line\");\n                        return None;\n                    }\n\n                    let species = content[0];\n                    let line = match content[1].parse::<usize>() {\n                        Ok(i) => i,\n                        _ => {\n                            println!(\"invalid line index\");\n                            return None;\n                        }\n                    };\n\n                    match &previous_blob {\n                        Some((p, n)) => {\n                            let decoded_path = urlencoding::decode(p).unwrap().to_string();\n                            let decoded_name = urlencoding::decode(n).unwrap().to_string();\n                            let s = unescape::unescape(&content[2..].join(\" \")).unwrap();\n                            let content_text = s[1..s.len() - 1].to_string();\n\n                            match species {\n                                \"+\" => {\n                                    result.blobs.push(modifications::Blob::Create(\n                                        decoded_path,\n                                        decoded_name,\n                                        line,\n                                        content_text,\n                                    ));\n                                }\n                                \"-\" => {\n                                    result.blobs.push(modifications::Blob::Delete(\n                                        decoded_path,\n                                        decoded_name,\n                                        line,\n                                        content_text,\n                                    ));\n                                }\n                                _ => {\n                                    return None;\n                                }\n                            }\n                        }\n                        None => {\n                            return None;\n                        }\n                    }\n                }\n            }\n        }\n\n        Some(result)\n    }\n}\n"}}]}},{"Blob":{"name":"blob.rs","content":"use serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq, PartialOrd, Ord)]\npub enum Blob {\n    // creation/deletion of lines in files\n    Create(\n        String, // parent directory\n        String, // file name\n        usize,  // line\n        String, // text\n    ),\n    Delete(\n        String, // parent directory\n        String, // file name\n        usize,  // line\n        String, // text\n    ),\n}\n\nimpl Blob {\n    pub fn extract_path(&self) -> (String, String) {\n        match self {\n            Blob::Create(path, name, _, _) | Blob::Delete(path, name, _, _) => {\n                (path.clone(), name.clone())\n            }\n        }\n    }\n\n    pub fn extract_change(&self) -> String {\n        format!(\n            \"{} {}\",\n            match self {\n                Blob::Create(_, _, _, _) => \"+\",\n                Blob::Delete(_, _, _, _) => \"-\",\n            },\n            match self {\n                Blob::Create(_, _, line, content) | Blob::Delete(_, _, line, content) => {\n                    format!(\"{line} {content:?}\")\n                }\n            }\n        )\n    }\n}\n"}},{"Blob":{"name":"mod.rs","content":"pub mod change;\npub mod container;\npub mod blob;\n\npub use change::Change;\npub use container::Tree;\npub use blob::Blob;\n"}}]}}]}},{"Blob":{"name":"relic.rs","content":"// use crate::state::State;\n\n// #[derive(Debug)]\n// pub struct Relic {\n//     // holds\n//     //      history.changes\n//     //      now.changes\n//     //      root\n//     //      upstream\n//     pub upstream: State,\n// }\n// impl Relic {\n//     pub fn empty() -> Relic {\n//         Relic {\n//             upstream: State::empty(),\n//         }\n//     }\n// }\n"}},{"Blob":{"name":"state.rs","content":"use serde::{Deserialize, Serialize};\nuse std::{\n    collections::HashSet,\n    fs,\n    path::{Path, PathBuf},\n};\n\nuse crate::{\n    core::{\n        commit::Commit,\n        content_set::{ContentSet, IgnoreSet, TrackingSet},\n        modifications::Change,\n        objects::data::upstream::Upstream,\n        paths::{RELIC_PATH_IGNORE, RELIC_PATH_PENDING, RELIC_PATH_TRACKED, RELIC_PATH_UPSTREAM},\n        Blob, Content, RelicInfo, Tree,\n    },\n    error::RelicError,\n};\n\npub const DEFAULT_BRANCH: &str = \"main\";\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct State {\n    pub info: RelicInfo,\n    // current & upstream uses a Tree with unset path & name values\n    pub current: Tree,\n    pub upstream: Tree,\n    pub path: PathBuf,\n    pub track_set: ContentSet,\n    pub ignore_set: ContentSet,\n}\n\nimpl State {\n    pub fn empty() -> State {\n        // needs to store current upstream commit\n        // local commits assigned an id?\n        State {\n            info: RelicInfo::empty(),\n            current: Tree::new(),\n            upstream: Tree::new(),\n            path: PathBuf::from(\".\"),\n            track_set: ContentSet::empty(),\n            ignore_set: ContentSet::empty(),\n        }\n    }\n\n    pub fn create(path: PathBuf) -> Result<State, RelicError> {\n        let info = match RelicInfo::initialise() {\n            Ok(r) => r,\n            Err(e) => return Err(e),\n        };\n\n        let ignore_set =\n            IgnoreSet::create(fs::read_to_string(RELIC_PATH_IGNORE).unwrap_or(\"\".to_string()));\n\n        let current =\n            match State::content_at(&path.to_string_lossy().to_string(), &path, &ignore_set)? {\n                Content::Tree(t) => t,\n                _ => return Err(RelicError::ConfigurationIncorrect),\n            };\n\n        let upstream = match Upstream::deserialise(RELIC_PATH_UPSTREAM) {\n            Ok(u) => u,\n            Err(e) => return Err(e),\n        }\n        .tree();\n\n        let mut track_set: ContentSet = match fs::read_to_string(RELIC_PATH_TRACKED) {\n            Ok(data) => TrackingSet::deserialise(data),\n            Err(_) => return Err(RelicError::ConfigurationIncorrect),\n        };\n\n        track_set.directories = HashSet::from_iter(\n            track_set\n                .directories\n                .difference(&ignore_set.directories)\n                .map(|x| {\n                    PathBuf::from(\".\")\n                        .join(PathBuf::from(x))\n                        .to_string_lossy()\n                        .to_string()\n                }),\n        );\n        track_set.files =\n            HashSet::from_iter(track_set.files.difference(&ignore_set.files).map(|x| {\n                PathBuf::from(\".\")\n                    .join(PathBuf::from(x))\n                    .to_string_lossy()\n                    .to_string()\n            }));\n\n        Ok(State {\n            info,\n            current,\n            upstream,\n            path,\n            track_set,\n            ignore_set,\n        })\n    }\n\n    pub fn content_at(\n        file_name: &String,\n        root_path: &PathBuf,\n        ignore_set: &ContentSet,\n    ) -> Result<Content, RelicError> {\n        // get all files at path\n        let paths = match fs::read_dir(root_path) {\n            // let paths = match fs::read_dir(format!(\"./{}\", root_path.clone())) {\n            Ok(r) => r,\n            Err(e) => {\n                println!(\"state.rs (content_at) get all dirs : {root_path:?} : {e:?}\");\n                return Err(RelicError::FileCantOpen);\n            }\n        };\n\n        let mut tree_contents = vec![];\n\n        // iterate through them all\n        for path in paths {\n            match path {\n                Ok(p) => {\n                    let file_type = p.file_type().unwrap();\n                    let file_name = p.file_name().into_string().unwrap();\n                    let file_path = p.path();\n\n                    // if file_name.starts_with(\".\") {\n                    //     continue;\n                    // }\n\n                    if file_type.is_dir() {\n                        if ignore_set.directories.contains(&file_name) {\n                            continue;\n                        }\n\n                        match State::content_at(&file_name, &file_path, ignore_set) {\n                            Ok(c) => {\n                                tree_contents.push(c);\n                            }\n                            Err(e) => {\n                                println!(\"state.rs (content_at) subtraverse : {e:?}\");\n                            }\n                        }\n                    } else if file_type.is_file() {\n                        if ignore_set.files.contains(&file_name) {\n                            continue;\n                        }\n\n                        match Blob::create(file_name, file_path) {\n                            Ok(b) => {\n                                tree_contents.push(Content::Blob(b));\n                            }\n                            _ => {}\n                        }\n                    } else if file_type.is_symlink() {\n                        // TODO : decide what to do here\n                        if ignore_set.files.contains(&file_name) {\n                            continue;\n                        }\n                    }\n                }\n                Err(e) => {\n                    println!(\"state.rs (content_at) read_dir : {e:?}\");\n                }\n            }\n        }\n\n        // println!(\"CREATION : {root_path:?}\");\n        Ok(Content::Tree(Tree {\n            path: root_path.clone(),\n            name: file_name.clone(),\n            content: tree_contents,\n        }))\n    }\n\n    // #region changes\n    pub fn get_changes(&self) -> Change {\n        Change::get_change_all(&self.upstream, &self.current, Path::new(&self.path))\n    }\n    // #endregion\n\n    // #region upstream\n    pub fn update_upstream(&mut self, tracked_content: &ContentSet) {\n        // fully fill tracked_content\n        // eg : \"lorem/\" -> [\"lorem/ipsum\", \"lorem/dolor\", \"lorem/sit\"]\n        // traverse directories and fetch all children\n\n        let tracked_content = tracked_content.clone().initialise(&mut self.current);\n\n        // get changes\n        // filter to only changes in the tracked_content content set\n        let changes = self.get_changes().filter_changes(&tracked_content);\n\n        // apply changes to current\n        self.upstream.apply_changes(&changes);\n        let _ = fs::write(\n            RELIC_PATH_UPSTREAM,\n            Upstream::from_tree(&self.upstream).serialise(),\n        );\n    }\n    // #endregion\n\n    // #region pending\n    pub fn pending_add(&self, commit: Commit) {\n        // TODO : use numbering for blob name\n        // who knows if two commits are created in the same nanosecond\n        let _ = fs::write(\n            format!(\"{RELIC_PATH_PENDING}/{}.diff\", commit.timestamp),\n            commit.serialise(),\n        );\n    }\n\n    pub fn pending_get(&self) -> Vec<Commit> {\n        let directories = if let Ok(d) = fs::read_dir(RELIC_PATH_PENDING) {\n            d\n        } else {\n            return vec![];\n        };\n\n        let mut result = vec![];\n\n        for d in directories {\n            let d = if let Ok(d) = d { d } else { continue };\n            let p = if let Ok(p) = fs::read_to_string(d.path()) {\n                p\n            } else {\n                continue;\n            };\n\n            if let Some(c) = Commit::deserialise(p) {\n                result.push(c);\n            }\n        }\n\n        result.sort_by_key(|c| c.timestamp);\n\n        result\n    }\n    // #endregion\n}\n"}},{"Blob":{"name":"relic_info.rs","content":"use std::fs;\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    core::{paths::RELIC_PATH_INFO, state},\n    error::RelicError,\n};\n\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct RelicInfo {\n    pub remote: String,\n    pub branch: String,\n}\nimpl RelicInfo {\n    pub fn empty() -> RelicInfo {\n        RelicInfo {\n            remote: \"\".to_string(),\n            branch: \"\".to_string(),\n        }\n    }\n\n    pub fn default() -> RelicInfo {\n        RelicInfo {\n            remote: \"\".to_string(),\n            branch: state::DEFAULT_BRANCH.to_string(),\n        }\n    }\n\n    pub fn initialise() -> Result<RelicInfo, RelicError> {\n        if let Ok(t) = fs::read_to_string(format!(\"./{RELIC_PATH_INFO}\")) {\n            if let Ok(d) = serde_json::from_str::<RelicInfo>(&t) {\n                return Ok(d);\n            }\n            return Err(RelicError::RelicInfo(Box::new(\n                RelicError::ConfigurationIncorrect,\n            )));\n        }\n        Err(RelicError::RelicInfo(Box::new(RelicError::FileCantOpen)))\n    }\n\n    pub fn serialise(&self) -> String {\n        serde_json::to_string(self).unwrap()\n    }\n}\n"}},{"Blob":{"name":"mod.rs","content":"pub mod paths;\n\npub mod objects;\n\npub mod relic;\npub mod relic_info;\npub mod state;\n\npub mod commit;\n\npub use objects::{content_set, modifications, Content, ContentMutRef, Tree, Blob};\npub use relic_info::RelicInfo;\npub use state::State;\n"}},{"Blob":{"name":"paths.rs","content":"pub const RELIC_PATH_PARENT: &str = \".relic\";\npub const RELIC_PATH_HISTORY: &str = \".relic/history\";\npub const RELIC_PATH_PENDING: &str = \".relic/pending\";\n\npub const RELIC_PATH_ROOT: &str = \".relic/root\";\npub const RELIC_PATH_INFO: &str = \".relic/info.json\";\npub const RELIC_PATH_TRACKED: &str = \".relic/tracked\";\npub const RELIC_PATH_UPSTREAM: &str = \".relic/upstream\";\n\npub const RELIC_PATH_IGNORE: &str = \".relic_ignore\";\n"}}]}},{"Blob":{"name":"main.rs","content":"use std::path::PathBuf;\n\nmod core;\n\nmod error;\nmod utils;\n\nmod cli;\nmod commands;\n\nuse crate::core::state::State;\n\nfn main() {\n    let command_handler = cli::build();\n    let state = State::create(PathBuf::from(\".\"));\n    let args = command_handler.handler.clone().get_matches();\n\n    cli::handle(command_handler, args, state);\n}\n"}}]}},{"Blob":{"name":"ipsum","content":",\\n};\\n\\n#[derive(Debug, Clone)]\\npub struct Commit {\\n    pub id: Option<u32>,\\n    pub message: String,\\n    pub description: String,\\n    pub change: Change,\\n    pub timestamp: u64,\\n\\n    pub author: String,\\n}\\nimpl Commit {\\n    pub fn header(&self) -> String {\\n        // \\\"integrated backwards compatibility\\\" (2025-5-26 16:30) (affected : change.rs, content.rs, ...)\\n\\n        let mut file_names = vec![];\\n        for (_, parent) in self.change.as_map().1 {\\n            for (f, _) in parent {\\n                file_names.push(f);\\n            }\\n        }\\n\\n        format!(\\n            \\\"({}) \\\\\\\"{}\\\\\\\" (affected : {}{})\\\",\\n            utils::into_human_readable(self.timestamp),\\n            self.message,\\n            file_names\\n                .iter()\\n                .take(5)\\n                .map(|x| x.to_string())\\n                .collect::<Vec<String>>()\\n                .join(\\\", \\\"),\\n            if file_names.len() > 5 { \\\", ...\\\" } else { \\\"\\\" }\\n        )\\n    }\\n\\n    pub fn serialise(&self) -> String {\\n        format!(\\n            \\\"= {} {} {:?} {:?} {}\\\\n{}\\\",\\n            self.id\\n                .map_or(\\\"LOCAL\\\".to_string(), |i| format!(\\\"{:06x}\\\", i).clone()),\\n            self.timestamp,\\n            urlencoding::encode(&self.message).to_string(),\\n            urlencoding::encode(&self.description).to_string(),\\n            self.author,\\n            self.change.serialise_changes()\\n        )\\n    }\\n\\n    pub fn deserialise(s: String) -> Option<Commit> {\\n        // = LOCAL 1747682692319414000 \\\"initial%20commit\\\" \\\"\\\" no_one\\n\\n        let lines = s.split(\\\"\\\\n\\\").collect::<Vec<&str>>();\\n        if lines.len() < 2 {\\n            // return None;\\n        }\\n\\n        let metadata = lines[0].split(\\\" \\\").collect::<Vec<&str>>();\\n        if metadata.len() != 6 {\\n            // return None;\\n        }\\n\\n        let [_, status, time, message, description, author] = *metadata.as_slice() else {\\n            return None;\\n        };\\n\\n        Some(Commit {\\n            id: status.parse::<u32>().map_or(None, |t| Some(t)),\\n            message: urlencoding::decode(&message[1..message.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            description: urlencoding::decode(&description[1..description.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            change: Change::deserialise_changes(lines[1..].join(\\\"\\\\n\\\")).unwrap_or(Change::empty()),\\n            timestamp: time.parse::<u64>().unwrap_or(0),\\n            author: author.to_string(),\\n        })\\n    }\\n}\\n\\npub fn add(_: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let mut result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n    for p in f {\\n        // TODO : path.join for this? or concatenating / works?\\n        result.insert(format!(\\n            \\\"{}{}\\\",\\n            p.to_string_lossy().to_string(),\\n            if !p.to_string_lossy().to_string().ends_with(\\\"/\\\") && p.is_dir() {\\n                \\\"/\\\"\\n            } else {\\n                \\\"\\\"\\n            }\\n        ));\\n    }\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result.drain().collect::<Vec<String>>().join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn remove(s: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n\\n    // initialise removed_content\\n    let mut removed_content = ContentSet {\\n        files: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| !x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n        directories: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n    }\\n    .initialise(&mut s.current);\\n\\n    let mut to_subtract: HashSet<String> = HashSet::from_iter(\\n        removed_content\\n            .directories\\n            .drain()\\n            .collect::<Vec<String>>()\\n            .into_iter()\\n            .map(|x| format!(\\\"{x}/\\\"))\\n            .collect::<Vec<String>>(),\\n    );\\n    to_subtract = to_subtract\\n        .union(&HashSet::from_iter(removed_content.files.drain()))\\n        .map(|x| x.to_string())\\n        .collect::<HashSet<String>>();\\n\\n    // set operations\\n    // right join\\n    // result - removed_content\\n\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result\\n            .difference(&to_subtract)\\n            .map(|x| x[2..].to_string())\\n            .collect::<Vec<String>>()\\n            .join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn commit(state: &mut State, args: &ArgMatches) {\\n    // push into pending stage\\n    // update upstream\\n\\n    // everything after the first line will be generated by Change::serialise_change\\n    r#\\\"= {commit id} {unix timestamp of commit} {message} {description} {author}\\n+ D \\\"lorem/ipsum/dolor\\\"\\n+ F \\\"lorem/ipsum/dolor/earth.txt\\\" \\\"earth.txt\\\"\\n- D \\\"lorem/sit\\\"\\n=\\n| \\\"lorem/ipsum/dolor/earth.txt\\\"\\n+ 3 asdfsdf\\n+ 5 sfsdf\\n- 7\\n| \\\"lorem/ipsum/saturn/txt\\\"\\n+ 4 lsdfljs\\\"#;\\n    let message = args.get_one::<String>(\\\"message\\\").unwrap().clone();\\n    let description = args\\n        .get_one::<String>(\\\"description\\\")\\n        .map_or(\\\"\\\".to_string(), String::clone);\\n\\n    let commit = Commit {\\n        id: None,\\n        message,\\n        description,\\n        change: state.get_changes(),\\n        timestamp: utils::get_time(),\\n        author: \\\"no_one\\\".to_string(),\\n    };\\n\\n    state.pending_add(commit);\\n    // update upstream\\n    (*state).update_upstream(&mut state.track_set.clone());\\n}\\n\\npub fn push(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pull(_: &mut State, _: &ArgMatches) {}\\n\\npub fn fetch(_: &mut State, _: &ArgMatches) {}\\n\\npub fn cherry(_: &mut State, _: &ArgMatches) {}\\n\\npub fn rollback(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pending(state: &mut State, args: &ArgMatches) {\\n    let pending = state.pending_get();\\n\\n    if let Some(commit_number) = args\\n        .get_one::<String>(\\\"COMMIT\\\")\\n        .map_or(None, |x| x.parse::<i32>().map_or(None, |x| Some(x)))\\n    {\\n        // display selected\\n        if (commit_number < 0) || (commit_number >= pending.len() as i32) {\\n            println!(\\n                \\\"Invalid selection. Please select commit numbers in the range of (0-{})\\\",\\n                pending.len() - 1\\n            );\\n            return;\\n        }\\n\\n        let copy = state.current.clone();\\n        let changes = pending[commit_number as usize].clone();\\n        println!(\\\"before : {}\\\", copy.get_hash());\\n\\n        let mut inversed = copy.clone();\\n        inversed.unapply_changes(changes.change.clone());\\n        println!(\\\"inverse : {}\\\", inversed.get_hash());\\n\\n        let mut after = inversed.clone();\\n        after.apply_changes(changes.change.clone());\\n        println!(\\\"after : {}\\\", after.get_hash());\\n\\n        let mut a = after\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n        let mut b = copy\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n\\n        a.sort();\\n        b.sort();\\n\\n        // println!(\\\"{}\\\", utils::generate_tree(&copy));\\n        // println!(\\\"{}\\\", utils::generate_tree(&after));\\n        // println!(\\\"{}\\\", utils::generate_tree(&inversed));\\n\\n        for i in 0..a.len() {\\n            let c = a[i].clone();\\n            let d = b[i].clone();\\n            if c != d {\\n                println!(\\\"{c}\\\\n{d}\\\\n\\\\n\\\\n\\\\n\\\\n\\\");\\n            }\\n        }\\n    } else {\\n        // display all\\n        for (index, c) in pending.iter().enumerate() {\\n            println!(\\\"{index}. {}\\\", c.header());\\n        }\\n    }\\n}\\n\"\n,\\n};\\n\\n#[derive(Debug, Clone)]\\npub struct Commit {\\n    pub id: Option<u32>,\\n    pub message: String,\\n    pub description: String,\\n    pub change: Change,\\n    pub timestamp: u64,\\n\\n    pub author: String,\\n}\\nimpl Commit {\\n    pub fn header(&self) -> String {\\n        // \\\"integrated backwards compatibility\\\" (2025-5-26 16:30) (affected : change.rs, content.rs, ...)\\n\\n        let mut file_names = vec![];\\n        for (_, parent) in self.change.as_map().1 {\\n            for (f, _) in parent {\\n                file_names.push(f);\\n            }\\n        }\\n\\n        format!(\\n            \\\"({}) \\\\\\\"{}\\\\\\\" (affected : {}{})\\\",\\n            utils::into_human_readable(self.timestamp),\\n            self.message,\\n            file_names\\n                .iter()\\n                .take(5)\\n                .map(|x| x.to_string())\\n                .collect::<Vec<String>>()\\n                .join(\\\", \\\"),\\n            if file_names.len() > 5 { \\\", ...\\\" } else { \\\"\\\" }\\n        )\\n    }\\n\\n    pub fn serialise(&self) -> String {\\n        format!(\\n            \\\"= {} {} {:?} {:?} {}\\\\n{}\\\",\\n            self.id\\n                .map_or(\\\"LOCAL\\\".to_string(), |i| format!(\\\"{:06x}\\\", i).clone()),\\n            self.timestamp,\\n            urlencoding::encode(&self.message).to_string(),\\n            urlencoding::encode(&self.description).to_string(),\\n            self.author,\\n            self.change.serialise_changes()\\n        )\\n    }\\n\\n    pub fn deserialise(s: String) -> Option<Commit> {\\n        // = LOCAL 1747682692319414000 \\\"initial%20commit\\\" \\\"\\\" no_one\\n\\n        let lines = s.split(\\\"\\\\n\\\").collect::<Vec<&str>>();\\n        if lines.len() < 2 {\\n            // return None;\\n        }\\n\\n        let metadata = lines[0].split(\\\" \\\").collect::<Vec<&str>>();\\n        if metadata.len() != 6 {\\n            // return None;\\n        }\\n\\n        let [_, status, time, message, description, author] = *metadata.as_slice() else {\\n            return None;\\n        };\\n\\n        Some(Commit {\\n            id: status.parse::<u32>().map_or(None, |t| Some(t)),\\n            message: urlencoding::decode(&message[1..message.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            description: urlencoding::decode(&description[1..description.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            change: Change::deserialise_changes(lines[1..].join(\\\"\\\\n\\\")).unwrap_or(Change::empty()),\\n            timestamp: time.parse::<u64>().unwrap_or(0),\\n            author: author.to_string(),\\n        })\\n    }\\n}\\n\\npub fn add(_: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let mut result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n    for p in f {\\n        // TODO : path.join for this? or concatenating / works?\\n        result.insert(format!(\\n            \\\"{}{}\\\",\\n            p.to_string_lossy().to_string(),\\n            if !p.to_string_lossy().to_string().ends_with(\\\"/\\\") && p.is_dir() {\\n                \\\"/\\\"\\n            } else {\\n                \\\"\\\"\\n            }\\n        ));\\n    }\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result.drain().collect::<Vec<String>>().join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn remove(s: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n\\n    // initialise removed_content\\n    let mut removed_content = ContentSet {\\n        files: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| !x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n        directories: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n    }\\n    .initialise(&mut s.current);\\n\\n    let mut to_subtract: HashSet<String> = HashSet::from_iter(\\n        removed_content\\n            .directories\\n            .drain()\\n            .collect::<Vec<String>>()\\n            .into_iter()\\n            .map(|x| format!(\\\"{x}/\\\"))\\n            .collect::<Vec<String>>(),\\n    );\\n    to_subtract = to_subtract\\n        .union(&HashSet::from_iter(removed_content.files.drain()))\\n        .map(|x| x.to_string())\\n        .collect::<HashSet<String>>();\\n\\n    // set operations\\n    // right join\\n    // result - removed_content\\n\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result\\n            .difference(&to_subtract)\\n            .map(|x| x[2..].to_string())\\n            .collect::<Vec<String>>()\\n            .join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn commit(state: &mut State, args: &ArgMatches) {\\n    // push into pending stage\\n    // update upstream\\n\\n    // everything after the first line will be generated by Change::serialise_change\\n    r#\\\"= {commit id} {unix timestamp of commit} {message} {description} {author}\\n+ D \\\"lorem/ipsum/dolor\\\"\\n+ F \\\"lorem/ipsum/dolor/earth.txt\\\" \\\"earth.txt\\\"\\n- D \\\"lorem/sit\\\"\\n=\\n| \\\"lorem/ipsum/dolor/earth.txt\\\"\\n+ 3 asdfsdf\\n+ 5 sfsdf\\n- 7\\n| \\\"lorem/ipsum/saturn/txt\\\"\\n+ 4 lsdfljs\\\"#;\\n    let message = args.get_one::<String>(\\\"message\\\").unwrap().clone();\\n    let description = args\\n        .get_one::<String>(\\\"description\\\")\\n        .map_or(\\\"\\\".to_string(), String::clone);\\n\\n    let commit = Commit {\\n        id: None,\\n        message,\\n        description,\\n        change: state.get_changes(),\\n        timestamp: utils::get_time(),\\n        author: \\\"no_one\\\".to_string(),\\n    };\\n\\n    state.pending_add(commit);\\n    // update upstream\\n    (*state).update_upstream(&mut state.track_set.clone());\\n}\\n\\npub fn push(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pull(_: &mut State, _: &ArgMatches) {}\\n\\npub fn fetch(_: &mut State, _: &ArgMatches) {}\\n\\npub fn cherry(_: &mut State, _: &ArgMatches) {}\\n\\npub fn rollback(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pending(state: &mut State, args: &ArgMatches) {\\n    let pending = state.pending_get();\\n\\n    if let Some(commit_number) = args\\n        .get_one::<String>(\\\"COMMIT\\\")\\n        .map_or(None, |x| x.parse::<i32>().map_or(None, |x| Some(x)))\\n    {\\n        // display selected\\n        if (commit_number < 0) || (commit_number >= pending.len() as i32) {\\n            println!(\\n                \\\"Invalid selection. Please select commit numbers in the range of (0-{})\\\",\\n                pending.len() - 1\\n            );\\n            return;\\n        }\\n\\n        let copy = state.current.clone();\\n        let changes = pending[commit_number as usize].clone();\\n        println!(\\\"before : {}\\\", copy.get_hash());\\n\\n        let mut after = copy.clone();\\n        after.apply_changes(changes.change.clone());\\n        println!(\\\"after : {}\\\", after.get_hash());\\n\\n        let mut inversed = after.clone();\\n        inversed.unapply_changes(changes.change.clone());\\n        println!(\\\"inverse : {}\\\", inversed.get_hash());\\n\\n        let mut a = inversed\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n        let mut b = copy\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n\\n        a.sort();\\n        b.sort();\\n\\n        // println!(\\\"{}\\\", utils::generate_tree(&copy));\\n        // println!(\\\"{}\\\", utils::generate_tree(&after));\\n        // println!(\\\"{}\\\", utils::generate_tree(&inversed));\\n\\n        for i in 0..a.len() {\\n            let c = a[i].clone();\\n            let d = b[i].clone();\\n            if c != d {\\n                println!(\\\"{c}\\\\n{d}\\\\n\\\\n\\\\n\\\\n\\\\n\\\");\\n            }\\n        }\\n        // display all\\n        for (index, c) in pending.iter().enumerate() {\\n            println!(\\\"{index}. {}\\\", c.header());\\n        }\\n    }\\n}\\n\"\n"}}]}