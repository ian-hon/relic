{
  "path": ".",
  "name": ".",
  "content": [
    {
      "Directory": {
        "path": "./src",
        "name": "src",
        "content": [
          {
            "File": {
              "name": "branch.rs",
              "content": "use clap::ArgMatches;\n\nuse crate::state::State;\n\npub fn branch(_: &mut State, _: &ArgMatches) {}\n"
            }
          },
          {
            "File": {
              "name": "main.rs",
              "content": "use std::collections::HashMap;\nuse std::path::PathBuf;\n\nmod paths;\n\nmod content_set;\nmod error;\nmod state;\nmod utils;\n\nmod branch;\nmod commit;\nmod relic;\nmod relic_info;\nmod stash;\n\nmod change;\nmod content;\n\nuse clap::{arg, value_parser, ArgMatches, Command};\nuse commit::{pending, remove};\nuse content_set::TrackingSet;\nuse state::init;\nuse utils::generate_tree;\n\nuse crate::branch::branch;\nuse crate::commit::{add, cherry, commit, fetch, pull, push, rollback};\nuse crate::stash::{restore, stash};\nuse crate::state::State;\n\n// add\n// commit {message}\n// push\n// pull\n// fetch\n// branch {name}\n//      will change to that branch\n//      if branch doesnt exist, create\n//      ask to create stash (if changes present)\n// stash {name|optional}\n//      stashes are bound to a branch\n//      optional to have a name\n// restore\n//      select stash to restore\n// rollback\n//      resets to current head\n// cherry {commit hash}\n\nfn main() {\n    let mut command_handler = Command::new(\"relic\")\n        .about(\n            r#\"This is the Relic Version Control System.\n\nThe best way to learn is to stupidly and\nblindly reinvent the wheel.\n\nRelic is a simple hobby project, because\nremaking Git sounded fun and interesting.\n\nMost common features like committing,\npushing and pulling, are implemented.\"#,\n        )\n        .subcommand_required(true)\n        .arg_required_else_help(true);\n\n    type CommandType = fn(&mut State, &ArgMatches);\n    let mut commands: HashMap<String, CommandType> = HashMap::new();\n    for (f, c) in HashMap::<CommandType, clap::Command>::from_iter::<\n        Vec<(CommandType, clap::Command)>,\n    >(vec![\n        (\n            init,\n            Command::new(\"init\").about(\"Initialises a Relic repository in the current directory.\"),\n        ),\n        (\n            state::clone,\n            Command::new(\"clone\").about(\"Clone a remote Relic repository in the current directory.\")\n        ),\n        (\n            state::detach,\n            Command::new(\"detach\").about(\"Completely removes Relic from the current directory.\")\n        ),\n        (\n            add,\n            Command::new(\"add\")\n                .about(\"Adds a file(s) to staging\")\n                .arg_required_else_help(true)\n                .arg(\n                    arg!([FILE]... \"File(s) to add (* for all)\")\n                        .required(true)\n                        .value_parser(value_parser!(PathBuf)),\n                ),\n        ),\n        (\n            remove,\n            Command::new(\"remove\")\n                .about(\"Removes a file(s) to staging\")\n                .arg_required_else_help(true)\n                .arg(\n                    arg!([FILE]... \"File(s) to remove (* for all)\")\n                        .required(true)\n                        .value_parser(value_parser!(PathBuf)),\n                ),\n        ),\n        (\n            commit,\n            Command::new(\"commit\")\n                .about(\"Commit current changes.\")\n                .arg_required_else_help(true)\n                .arg(arg!(-m --message <MESSAGE> \"Commit message\").required(true))\n                .arg(arg!(-d --description <DESCRIPTION> \"Commit description\")),\n        ),\n        (\n            push,\n            Command::new(\"push\").about(\"Pushes local changes to remote.\"),\n        ),\n        (\n            pull,\n            Command::new(\"pull\").about(\"Pull changes from remote to local.\"),\n        ),\n        (\n            fetch,\n            Command::new(\"fetch\").about(\"Check remote for new changes.\"),\n        ),\n        (branch, Command::new(\"branch\").about(\"\")),\n        (\n            stash,\n            Command::new(\"stash\")\n                // pseudo-commits basically\n                // clear stash after a commit\n                // stash create\n                // stash view\n                // stash restore\n                // stash delete\n                .about(\"\"),\n        ),\n        (\n            restore,\n            Command::new(\"restore\"), // unimplemented\n        ),\n        (\n            rollback,\n            Command::new(\"rollback\").about(\"Discard all current changes. Rolls back to most recent commit (or pending commit).\"),\n        ),\n        (\n            cherry,\n            Command::new(\"cherry\").about(\"Go to specific commit.\"),\n        ),\n        (\n            |s, _| {\n                println!(\"{}\", generate_tree(&s.current));\n            },\n            Command::new(\"tree\").about(\"Generate content tree of current directory.\"),\n        ),\n        (\n            |s, _| {\n                println!(\n                    \"{}\",\n                    s.get_changes()\n                        .filter_changes(&s.track_set.initialise(&mut s.current))\n                        .serialise_changes()\n                );\n            },\n            Command::new(\"staging\").about(\"View all staging changes.\"),\n        ),\n        (\n            pending,\n            Command::new(\"pending\").about(\"View all pending commits.\")\n                .arg(arg!([COMMIT]... \"Commit number.\"))\n        ),\n        (\n            |_, _| {\n                println!(\".................................................................................................\\n.................................................................................................\\n.................................................................................................\\n.....-----:......:-:.......:--........:-:.......:------::......:----:....:-:....:---::...:::.....\\n..:-+#%%%%+=:...:+#=:......=#+:......-*#+:......=%%%%%%#*=:..:=*%%%%*-:.-+#=..-+#%%%#+-.:=#*-....\\n.:-%%#+=+#%%+:..-*%+:.....:=%*:.....:+%@#-.....:+%%++++#%%*-.=#%#+=#@#-.-#%=::+%%+=+%%+::+%#-....\\n.-#%=:...:=%%=..-*%+:.....:=%*:.....=#%#%*:....:+%*:...:=%%=-+#+:..-%%=.-*%=:-*#=..:=%#-:+%#-....\\n:+@*:.....:+%#-.-#%+-.....:+%*:....:+%*=#%-....:+%*-....-#%+:::....-%%=:-#%=:.::...:=%#-:+%#-....\\n-#@=:.....:=%%-.-#%+-------+%*:....-##=:+%+:...:+%*:...:=%%=:.....-+%*-.-*%=:.....:=#%+:.=%#-....\\n-#@=......:=%%=.-#@%%######%@*:...:+%+:.-##-:..:+%#====+#%*-.....-*%*-..-*%=.....:=#%+-.:=%#-....\\n-#@=:......=%%=.-#@#+======*@*:..:=##=::-+@*-..:+@%##%%@#=:.....-#%*-:..-*%=....:+%#=:..:=%#-....\\n-*@=:.....:=%%-.:#@+-.....:+%*:..:+@%*++*#@%=..:+%#=--=@#=:....:=%#-....-*#=....-#%+:....=%*-....\\n:+@*-.....-*%#:.:#@+:.....:=%*:..=#%######%@*-.:+%*:..:*%*-:...:-+=:....:==-....:++-.....-==:....\\n.-#%+-:.:-+%%=..:#%+-.....:=%*:.-*%*::::..=#%=::+%*-...-#%+-.....::......:::.....::.......::.....\\n.:-%%%*++#%%=:..-*%+:......+%+-:=%#=:.....-+@*-:+%*-....=%%=:..:=#+-...:-+*=:...:*#=:....=*+-....\\n...:=*#%%%@#=...:+*=:......=#=::+#+-.:.::.:-**-:=*=:.::::=#*-:..=*+-....:+*=....:**=.....=*+-....\\n....:::::-+%%+:..::........::-::---:::::::::-=-:::::--===+++==-::::......::......::.......::.....\\n..........:-=-.............:----==--:::::----===-:-=++*####++++=-:::----:::::::..................\\n..:........................:---===-----------==+=--=***+==+***++=--=+++++=--===-.................\\n.....::::::................:-====-------------===-:-------=+*****+++===++*+***+=:................\\n...:-==++++=--..::---:.....:-=======--======-:-=-......:..::-==++==-:::---====-::................\\n...:=+**#*+++=--==+++=-....-=--============-::-=-.......::::::-::::::::::.::::......:::..........\\n...::--==+++++++++***+-::.:------====+++===-----:......-===++====---====-:........:-===---::::...\\n......::=+**######**+-::...:--========*#+=---::...:::::=+++*####****####*=-:::.:.:=+#***+++===-:.\\n......::-==+++++==-:::...:...:--===---=*+-::.:......::-=********+++++****+++====---=++*+****+++==\\n..........::::::::::::....:..:.::-==---+*=::...::.:::::-=+*####+=---+###****#**++++=-----=+***+++\\n............::--======-------===-------+#+-:::::::::.::::-----=-:::--++*#######*+++++=-:::-=+*###\\n..........:.-=+++******++++=+***+=-----=*#-------:::::::-----------=+++********++****+=:::::--=++\\n....:.:...::-+***##########*+###+=-----=+#+=====----------=======++*################*+--::.:.::::\\n..::::::..::-+*****#+=======-==---=======++====----=--=======+*###****##*+++++++++===-------:::..\\n:-=====--:::-=+**###+---------------==++++====---------=======+*#####*++=-::-::::::::-=++++=+==--\\n-++*#*++==--==++====---:::--::::::--==========--------======---=++##++=--:::::::::::-=+*****##**+\\n:-=+++++*+=+++**=--::::::::--------======--------------=====--=+****+++==--:::::::--=+**+**######\\n.::-=++++++**#**=--::::::----========------------------------=+####*++++++++=-::-=++***###******+\\n.::-=+**+*##*+=--:::::::--:--========-----=======-----:--------==+**+*+++***+=--+#*******########\\n.:::-=======--:::::::::::-----=========++#*******+=--:::::::::::----==++****+++=+#*****++===+++++\\n.:.:::::::::::::::::::::::----======++############*+--::::::::::::::---=********+******+=--::::::\\n....:.::::---=====---::::------====+*#############**+=--::::::::::::::--=*#************=--::::::.\\n.:::---==++++++**++++=--::--------=+#######*+++##******=======--::::::::-=+*#########*+=======--:\\n:--=+++**************++---::::-----+*######*===+*#***#*+++****++-:::::::::--===++++==*******+++++\\n=++*****######********+--:::::::---=*#####*+=--=+**###+*#******+-::::::::.:::::::::-=+#########**\\n+******###************+--:::::::::--=+***+=-------=++==*#####*+=-:::..:..::::..:::::--=+*#######*\\n******##*==++********+=--:::::::::::---==--::::::------===++++=-:::::...:..:.::..:::-==*+********\\n#######*==+*********+--:::::::.::::::::..:::::--=+**+=---::::::::...::........:::--=+###*********\\n##**+==--=+*****###+=--::::...::.:..:.::..:::-++*****#*=--:::::....:...:..:.:::-=++**############\\n=--------=+########*+=--::::::..:.:.:..:::::-=**#**####**+=-::::::::--:..::.::-=*#*******#*++++++\\n::::::::--+#####******+=-:::.:.............::-==+#####*****+-::::-==++=-::.:::-=*####***+=-------\\n.:.:.::::--+**********#*+-:::............::.:::--==++**#****=--=++*****+-:::.::--=++*#*==--::::::\\n.......:::-=+****#*####*+-::::..............::::::--=+******=--+*#*#****=-:::.::::--==---::::....\\n......::::--=+*######*+==-::.........::.:.....:::::-=+******+===****#***=-:::::.::::::::.........\\n......:.::::--=***+==--:::...............::.....:::-=+**##********##***+=-:::....................\\n....:::.:::::--=---:::::.......................:.::-=+#**####****##***+=--::.:...................\\n................::.::..........................:.::--=*##########***++=-:::......................\");\n            },\n            Command::new(\"qhar\").about(\"??\")\n        ),\n        (\n            |s, _| {\n                println!(\"{:?}\", s.info);\n            },\n            Command::new(\"test\").about(\"this is here for debug purposes\")\n        )\n    ]) {\n        commands.insert(c.get_name().to_string(), f);\n        command_handler = command_handler.subcommand(c);\n    }\n\n    let s = State::create(PathBuf::from(\".\"));\n\n    let c = command_handler.get_matches();\n    let (command_name, sub_matches) = c.subcommand().unwrap();\n\n    // TODO : shorten and undry this\n    if let Ok(mut s) = s {\n        match command_name {\n            \"clone\" | \"init\" => {\n                // let this run only for\n                // clone, init\n                println!(\"Unable to '{command_name}' an already existing Relic repository.\");\n                return;\n            }\n            _ => match commands.get(command_name) {\n                Some(command) => {\n                    command(&mut s, sub_matches);\n                }\n                None => {\n                    unimplemented!(\"Relic Error, command not defined.\");\n                }\n            },\n        }\n    } else {\n        match command_name {\n            \"clone\" | \"init\" => {\n                // let this run only for\n                // clone, init\n                match commands.get(command_name) {\n                    Some(command) => {\n                        command(&mut State::empty(), sub_matches);\n                    }\n                    None => {\n                        unimplemented!(\"Relic Error, command not defined.\");\n                    }\n                }\n            }\n            _ => {\n                println!(\"No valid Relic repository found in current directory. Consider executing 'relic init' or 'relic clone'.\");\n                return;\n            }\n        }\n    }\n}\n"
            }
          },
          {
            "File": {
              "name": "commit.rs",
              "content": "use std::{collections::HashSet, fs, path::PathBuf};\n\nuse clap::ArgMatches;\n\nuse crate::{\n    change::Change,\n    content_set::{ContentSet, TrackingSet},\n    paths::RELIC_PATH_TRACKED,\n    state::State,\n    utils,\n};\n\nconst PENDING_TAG: &str = \"LOCAL\";\n\n#[derive(Debug, Clone)]\npub struct Commit {\n    pub id: Option<u32>,\n    pub message: String,\n    pub description: String,\n    pub change: Change,\n    pub timestamp: u64,\n\n    pub author: String,\n}\nimpl Commit {\n    pub fn hash(&self) -> String {\n        sha256::digest(self.serialise())\n    }\n\n    pub fn header(&self) -> String {\n        // \"integrated backwards compatibility\" (2025-5-26 16:30) (affected : change.rs, content.rs, ...)\n\n        let mut file_names = vec![];\n        for (_, parent) in self.change.as_map().1 {\n            for (f, _) in parent {\n                file_names.push(f);\n            }\n        }\n\n        format!(\n            \"({}) \\\"{}\\\" (affected : {}{})\",\n            utils::into_human_readable(self.timestamp),\n            self.message,\n            file_names\n                .iter()\n                .take(5)\n                .map(|x| x.to_string())\n                .collect::<Vec<String>>()\n                .join(\", \"),\n            if file_names.len() > 5 { \", ...\" } else { \"\" }\n        )\n    }\n\n    pub fn serialise(&self) -> String {\n        format!(\n            \"= {} {} {:?} {:?} {}\\n{}\",\n            self.id\n                .map_or(PENDING_TAG.to_string(), |i| format!(\"{:06x}\", i).clone()),\n            self.timestamp,\n            urlencoding::encode(&self.message).to_string(),\n            urlencoding::encode(&self.description).to_string(),\n            self.author,\n            self.change.serialise_changes()\n        )\n    }\n\n    pub fn deserialise(s: String) -> Option<Commit> {\n        // = LOCAL 1747682692319414000 \"initial%20commit\" \"\" no_one\n\n        let lines = s.split(\"\\n\").collect::<Vec<&str>>();\n        if lines.len() < 2 {\n            // return None;\n        }\n\n        let metadata = lines[0].split(\" \").collect::<Vec<&str>>();\n        if metadata.len() != 6 {\n            // return None;\n        }\n\n        let [_, status, time, message, description, author] = *metadata.as_slice() else {\n            return None;\n        };\n\n        Some(Commit {\n            id: status.parse::<u32>().map_or(None, |t| Some(t)),\n            message: urlencoding::decode(&message[1..message.len() - 1].to_string())\n                .unwrap()\n                .to_string(),\n            description: urlencoding::decode(&description[1..description.len() - 1].to_string())\n                .unwrap()\n                .to_string(),\n            change: Change::deserialise_changes(lines[1..].join(\"\\n\")).unwrap_or(Change::empty()),\n            timestamp: time.parse::<u64>().unwrap_or(0),\n            author: author.to_string(),\n        })\n    }\n}\n\npub fn add(_: &mut State, args: &ArgMatches) {\n    let f = args\n        .get_many::<PathBuf>(\"FILE\")\n        .unwrap()\n        .map(|x| x.clone())\n        .collect::<Vec<PathBuf>>();\n\n    let mut result: HashSet<String> = HashSet::from_iter(\n        fs::read_to_string(format!(\"./{RELIC_PATH_TRACKED}\"))\n            .unwrap()\n            .split(\"\\n\")\n            .filter(|x| !x.is_empty())\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>(),\n    );\n    for p in f {\n        // TODO : path.join for this? or concatenating / works?\n        result.insert(format!(\n            \"{}{}\",\n            p.to_string_lossy().to_string(),\n            if !p.to_string_lossy().to_string().ends_with(\"/\") && p.is_dir() {\n                \"/\"\n            } else {\n                \"\"\n            }\n        ));\n    }\n    let _ = fs::write(\n        format!(\"./{RELIC_PATH_TRACKED}\"),\n        result.drain().collect::<Vec<String>>().join(\"\\n\"),\n    );\n}\n\npub fn remove(s: &mut State, args: &ArgMatches) {\n    let f = args\n        .get_many::<PathBuf>(\"FILE\")\n        .unwrap()\n        .map(|x| x.clone())\n        .collect::<Vec<PathBuf>>();\n\n    let result: HashSet<String> = HashSet::from_iter(\n        fs::read_to_string(format!(\"./{RELIC_PATH_TRACKED}\"))\n            .unwrap()\n            .split(\"\\n\")\n            .filter(|x| !x.is_empty())\n            .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string())\n            .collect::<Vec<String>>(),\n    );\n\n    // initialise removed_content\n    let mut removed_content = ContentSet {\n        files: HashSet::from_iter(\n            f.iter()\n                .filter(|x| !x.is_dir())\n                .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string()),\n        ),\n        directories: HashSet::from_iter(\n            f.iter()\n                .filter(|x| x.is_dir())\n                .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string()),\n        ),\n    }\n    .initialise(&mut s.current);\n\n    let mut to_subtract: HashSet<String> = HashSet::from_iter(\n        removed_content\n            .directories\n            .drain()\n            .collect::<Vec<String>>()\n            .into_iter()\n            .map(|x| format!(\"{x}/\"))\n            .collect::<Vec<String>>(),\n    );\n    to_subtract = to_subtract\n        .union(&HashSet::from_iter(removed_content.files.drain()))\n        .map(|x| x.to_string())\n        .collect::<HashSet<String>>();\n\n    // set operations\n    // right join\n    // result - removed_content\n\n    let _ = fs::write(\n        format!(\"./{RELIC_PATH_TRACKED}\"),\n        result\n            .difference(&to_subtract)\n            .map(|x| x[2..].to_string())\n            .collect::<Vec<String>>()\n            .join(\"\\n\"),\n    );\n}\n\npub fn commit(state: &mut State, args: &ArgMatches) {\n    // push into pending stage\n    // update upstream\n\n    // everything after the first line will be generated by Change::serialise_change\n    r#\"= {commit id} {unix timestamp of commit} {message} {description} {author}\n+ D \"lorem/ipsum/dolor\"\n+ F \"lorem/ipsum/dolor/earth.txt\" \"earth.txt\"\n- D \"lorem/sit\"\n=\n| \"lorem/ipsum/dolor/earth.txt\"\n+ 3 asdfsdf\n+ 5 sfsdf\n- 7\n| \"lorem/ipsum/saturn/txt\"\n+ 4 lsdfljs\"#;\n    let message = args.get_one::<String>(\"message\").unwrap().clone();\n    let description = args\n        .get_one::<String>(\"description\")\n        .map_or(\"\".to_string(), String::clone);\n\n    let commit = Commit {\n        id: None,\n        message,\n        description,\n        change: state.get_changes(),\n        timestamp: utils::get_time(),\n        author: \"no_one\".to_string(),\n    };\n\n    state.pending_add(commit);\n    // update upstream\n    (*state).update_upstream(&mut state.track_set.clone());\n}\n\npub fn push(_: &mut State, _: &ArgMatches) {}\n\npub fn pull(_: &mut State, _: &ArgMatches) {}\n\npub fn fetch(_: &mut State, _: &ArgMatches) {}\n\npub fn cherry(_: &mut State, _: &ArgMatches) {}\n\npub fn rollback(_: &mut State, _: &ArgMatches) {}\n\npub fn pending(state: &mut State, args: &ArgMatches) {\n    let pending = state.pending_get();\n\n    if let Some(commit_number) = args\n        .get_one::<String>(\"COMMIT\")\n        .map_or(None, |x| x.parse::<i32>().map_or(None, |x| Some(x)))\n    {\n        // display selected\n        if (commit_number < 0) || (commit_number >= pending.len() as i32) {\n            println!(\n                \"Invalid selection. Please select commit numbers in the range of (0-{})\",\n                pending.len() - 1\n            );\n            return;\n        }\n\n        println!(\"{}\", pending[commit_number as usize].serialise());\n    } else {\n        // display all\n        for (index, c) in pending.iter().enumerate() {\n            println!(\"{index}. {}\", c.header());\n        }\n    }\n}\n"
            }
          },
          {
            "File": {
              "name": "stash.rs",
              "content": "use clap::ArgMatches;\n\nuse crate::state::State;\n\npub fn stash(_: &mut State, _: &ArgMatches) {}\n\npub fn restore(_: &mut State, _: &ArgMatches) {}\n"
            }
          },
          {
            "File": {
              "name": "state.rs",
              "content": "use clap::ArgMatches;\nuse serde::{Deserialize, Serialize};\nuse std::{\n    collections::HashSet,\n    fs,\n    path::{Path, PathBuf},\n};\n\nuse crate::{\n    change::Change,\n    commit::Commit,\n    content::{Content, Directory, File},\n    content_set::{self, ContentSet, IgnoreSet, TrackingSet},\n    error::RelicError,\n    paths::{self, RELIC_PATH_IGNORE, RELIC_PATH_PENDING, RELIC_PATH_TRACKED, RELIC_PATH_UPSTREAM},\n    relic_info::RelicInfo,\n};\n\nconst DEFAULT_INFO: &str = r#\"{\n    \"remote\":\"\",\n    \"branch\":\"main\"\n}\"#;\nconst DEFAULT_UPSTREAM: &str = r#\"{\n    \"path\": \"\",\n    \"name\": \"\",\n    \"content\": []\n}\"#;\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct State {\n    pub info: RelicInfo,\n    pub current: Directory,\n    pub upstream: Directory,\n    pub path: PathBuf,\n    pub track_set: ContentSet,\n    pub ignore_set: ContentSet,\n}\n\nimpl State {\n    pub fn empty() -> State {\n        // needs to store current upstream commit\n        // local commits assigned an id?\n        State {\n            info: RelicInfo::empty(),\n            current: Directory::new(),\n            upstream: Directory::new(),\n            path: PathBuf::from(\"\"),\n            track_set: ContentSet::empty(),\n            ignore_set: ContentSet::empty(),\n        }\n    }\n\n    pub fn create(path: PathBuf) -> Result<State, RelicError> {\n        let info = match RelicInfo::initialise() {\n            Ok(r) => r,\n            Err(e) => return Err(e),\n        };\n\n        let ignore_set =\n            IgnoreSet::create(fs::read_to_string(RELIC_PATH_IGNORE).unwrap_or(\"\".to_string()));\n\n        let current =\n            match State::content_at(&path.to_string_lossy().to_string(), &path, &ignore_set)? {\n                Content::Directory(d) => d,\n                _ => return Err(RelicError::ConfigurationIncorrect),\n            };\n\n        let upstream = match fs::read_to_string(RELIC_PATH_UPSTREAM) {\n            Ok(data) => match Directory::deserialise(data) {\n                Some(d) => d,\n                // TODO : implement something better for this?\n                None => Directory::new(), // None => return Err(RelicError::ConfigurationIncorrect),\n            },\n            Err(_) => return Err(RelicError::FileCantOpen),\n        };\n\n        let mut track_set: ContentSet = match fs::read_to_string(RELIC_PATH_TRACKED) {\n            Ok(data) => TrackingSet::deserialise(data),\n            Err(_) => return Err(RelicError::ConfigurationIncorrect),\n        };\n\n        track_set.directories = HashSet::from_iter(\n            track_set\n                .directories\n                .difference(&ignore_set.directories)\n                .map(|x| {\n                    PathBuf::from(\".\")\n                        .join(PathBuf::from(x))\n                        .to_string_lossy()\n                        .to_string()\n                }),\n        );\n        track_set.files =\n            HashSet::from_iter(track_set.files.difference(&ignore_set.files).map(|x| {\n                PathBuf::from(\".\")\n                    .join(PathBuf::from(x))\n                    .to_string_lossy()\n                    .to_string()\n            }));\n\n        Ok(State {\n            info,\n            current,\n            upstream,\n            path,\n            track_set,\n            ignore_set,\n        })\n    }\n\n    pub fn content_at(\n        file_name: &String,\n        root_path: &PathBuf,\n        ignore_set: &ContentSet,\n    ) -> Result<Content, RelicError> {\n        // get all files at path\n        let paths = match fs::read_dir(root_path) {\n            // let paths = match fs::read_dir(format!(\"./{}\", root_path.clone())) {\n            Ok(r) => r,\n            Err(e) => {\n                println!(\"state.rs (content_at) get all dirs : {root_path:?} : {e:?}\");\n                return Err(RelicError::FileCantOpen);\n            }\n        };\n\n        let mut directory_contents = vec![];\n\n        // iterate through them all\n        for path in paths {\n            match path {\n                Ok(p) => {\n                    let file_type = p.file_type().unwrap();\n                    let file_name = p.file_name().into_string().unwrap();\n                    let file_path = p.path();\n\n                    // if file_name.starts_with(\".\") {\n                    //     continue;\n                    // }\n\n                    if file_type.is_dir() {\n                        if ignore_set.directories.contains(&file_name) {\n                            continue;\n                        }\n\n                        match State::content_at(&file_name, &file_path, ignore_set) {\n                            Ok(c) => {\n                                directory_contents.push(c);\n                            }\n                            Err(e) => {\n                                println!(\"state.rs (content_at) subtraverse : {e:?}\");\n                            }\n                        }\n                    } else if file_type.is_file() {\n                        if ignore_set.files.contains(&file_name) {\n                            continue;\n                        }\n\n                        match File::create(file_name, file_path) {\n                            Ok(f) => {\n                                directory_contents.push(Content::File(f));\n                            }\n                            _ => {}\n                        }\n                    } else if file_type.is_symlink() {\n                        // TODO : decide what to do here\n                        if ignore_set.files.contains(&file_name) {\n                            continue;\n                        }\n                    }\n                }\n                Err(e) => {\n                    println!(\"state.rs (content_at) read_dir : {e:?}\");\n                }\n            }\n        }\n\n        // println!(\"CREATION : {root_path:?}\");\n        Ok(Content::Directory(Directory {\n            path: root_path.clone(),\n            name: file_name.clone(),\n            content: directory_contents,\n        }))\n    }\n\n    pub fn serialise_state(self: &State) -> String {\n        serde_json::to_string(self).unwrap()\n    }\n\n    pub fn deserialise_state(s: String) -> Option<State> {\n        match serde_json::from_str(&s) {\n            Ok(s) => Some(s),\n            Err(_) => None,\n        }\n    }\n\n    // #region changes\n    pub fn get_changes(&self) -> Change {\n        Change::get_change_all(&self.upstream, &self.current, Path::new(&self.path))\n    }\n    // #endregion\n\n    // #region upstream\n    pub fn update_upstream(&mut self, tracked_content: &ContentSet) {\n        // fully fill tracked_content\n        // eg : \"lorem/\" -> [\"lorem/ipsum\", \"lorem/dolor\", \"lorem/sit\"]\n        // traverse directories and fetch all children\n\n        let tracked_content = tracked_content.clone().initialise(&mut self.current);\n\n        // get changes\n        // filter to only changes in the tracked_content content set\n        let changes = self.get_changes().filter_changes(&tracked_content);\n\n        // apply changes to current\n        self.upstream.apply_changes(changes);\n        let _ = fs::write(RELIC_PATH_UPSTREAM, self.upstream.serialise());\n    }\n    // #endregion\n\n    // #region pending\n    pub fn pending_add(&self, commit: Commit) {\n        // TODO : use numbering for file name\n        // who knows if two commits are created in the same nanosecond\n        let _ = fs::write(\n            format!(\"{RELIC_PATH_PENDING}/{}.diff\", commit.timestamp),\n            commit.serialise(),\n        );\n    }\n\n    pub fn pending_get(&self) -> Vec<Commit> {\n        let directories = if let Ok(d) = fs::read_dir(RELIC_PATH_PENDING) {\n            d\n        } else {\n            return vec![];\n        };\n\n        let mut result = vec![];\n\n        for d in directories {\n            let d = if let Ok(d) = d { d } else { continue };\n            let p = if let Ok(p) = fs::read_to_string(d.path()) {\n                p\n            } else {\n                continue;\n            };\n\n            if let Some(c) = Commit::deserialise(p) {\n                result.push(c);\n            }\n        }\n\n        result.sort_by_key(|c| c.timestamp);\n\n        result\n    }\n    // #endregion\n}\n\npub fn init(_: &mut State, _: &ArgMatches) {\n    // create\n    // .relic\n    //      history/ (empty)\n    //      pending/ (empty)\n    //      root (empty)\n    //      tracked (empty)\n    //      upstream (empty)\n    // .relic_ignore (use default (const in content_set))\n\n    // if origin is set\n    // update root\n    // update upstream\n\n    let _ = fs::create_dir(paths::RELIC_PATH_PARENT);\n    let _ = fs::create_dir(paths::RELIC_PATH_HISTORY);\n    let _ = fs::create_dir(paths::RELIC_PATH_PENDING);\n    let _ = fs::write(paths::RELIC_PATH_INFO, DEFAULT_INFO);\n    let _ = fs::write(paths::RELIC_PATH_ROOT, \"\");\n    let _ = fs::write(paths::RELIC_PATH_TRACKED, \"\");\n    let _ = fs::write(paths::RELIC_PATH_UPSTREAM, DEFAULT_UPSTREAM);\n\n    let _ = fs::write(paths::RELIC_PATH_IGNORE, content_set::DEFAULT_IGNORE);\n\n    println!(\"Empty Relic repository created.\");\n}\n\npub fn clone(_: &mut State, _: &ArgMatches) {}\n\npub fn detach(_: &mut State, _: &ArgMatches) {\n    let _ = fs::remove_dir_all(paths::RELIC_PATH_PARENT);\n    let _ = fs::remove_file(paths::RELIC_PATH_IGNORE);\n\n    println!(\"Relic repository successfully removed.\");\n}\n"
            }
          },
          {
            "File": {
              "name": "utils.rs",
              "content": "use std::time::{Duration, SystemTime, UNIX_EPOCH};\n\nuse chrono::{DateTime, Utc};\n\nuse crate::content::{Content, Directory};\n\npub fn generate_tree(dir: &Directory) -> String {\n    return fetch_contents(&Content::Directory(dir.clone()));\n}\n\nfn fetch_contents(c: &Content) -> String {\n    let mut result = vec![];\n\n    match c {\n        Content::Directory(d) => {\n            let mut r = vec![d.name.clone()];\n            if d.content.len() >= 1 {\n                let length = d.content.len() - 1;\n                for (index, i) in d.content.iter().enumerate() {\n                    for (inner_index, line) in fetch_contents(i).split(\"\\n\").enumerate() {\n                        r.push(format!(\n                            \" {} {line}\",\n                            if index == length {\n                                if inner_index == 0 {\n                                    \"└\"\n                                } else {\n                                    \"\"\n                                }\n                            } else {\n                                if inner_index == 0 {\n                                    \"├\"\n                                } else {\n                                    \"│\"\n                                }\n                            }\n                        ));\n                    }\n                }\n            }\n            result.push(r.join(\"\\n\"));\n        }\n        Content::File(f) => {\n            result.push(f.name.clone());\n            // result.push(format!(\"{} ({})\", f.name, sha256::digest(&f.content)));\n        }\n    }\n\n    result.join(\"\\n\")\n}\n\npub fn get_time() -> u64 {\n    SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .expect(\"time went backwards (???)\")\n        .as_millis() as u64\n}\n\npub fn into_human_readable(t: u64) -> String {\n    // accepts unix time, but only in milliseconds format\n    DateTime::<Utc>::from(UNIX_EPOCH + Duration::from_millis(t as u64))\n        .format(\"%Y-%m-%d %H:%M:%S\")\n        .to_string()\n}\n"
            }
          },
          {
            "File": {
              "name": "content_set.rs",
              "content": "use std::{\n    collections::HashSet,\n    path::PathBuf,\n    sync::{Arc, Mutex},\n};\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::content::{ContentMutRef, Directory};\n\npub const DEFAULT_IGNORE: &str = r#\"-- Added by Relic: Automatically ignore all git content\n.git/\n.gitignore\"#;\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\npub struct ContentSet {\n    pub directories: HashSet<String>,\n    pub files: HashSet<String>,\n}\nimpl ContentSet {\n    pub fn empty() -> ContentSet {\n        ContentSet {\n            directories: HashSet::new(),\n            files: HashSet::new(),\n        }\n    }\n\n    pub fn as_set(&self) -> HashSet<String> {\n        HashSet::new()\n    }\n}\n\npub trait IgnoreSet {\n    fn create(content: String) -> Self;\n}\nimpl IgnoreSet for ContentSet {\n    fn create(content: String) -> ContentSet {\n        let mut result = ContentSet {\n            directories: HashSet::new(),\n            files: HashSet::new(),\n        };\n\n        // always ignore the .relic directory\n        result.directories.insert(\".relic\".to_string());\n\n        for line in content.split(\"\\n\") {\n            if line.is_empty() {\n                continue;\n            }\n\n            // skip comments\n            if line.starts_with(\"-- \") {\n                continue;\n            }\n\n            // doesnt take into account cases like\n            // some_directory// <- double slashes\n            if line.ends_with(\"/\") {\n                let i = line[0..line.len() - 1].to_string();\n                if i.is_empty() {\n                    continue;\n                }\n\n                result.directories.insert(i);\n            } else {\n                result.files.insert(line.to_string());\n            }\n        }\n\n        result\n    }\n}\n\npub trait TrackingSet {\n    fn deserialise(content: String) -> Self;\n    fn initialise(&self, d: &mut Directory) -> Self;\n}\nimpl TrackingSet for ContentSet {\n    fn deserialise(content: String) -> Self {\n        let mut result = ContentSet::empty();\n\n        for d in content\n            .split(\"\\n\")\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>()\n        {\n            if d.ends_with(\"/\") {\n                // dir\n                result.directories.insert(d[..d.len() - 1].to_string());\n            } else {\n                // file\n                result.files.insert(d);\n            }\n        }\n\n        result\n    }\n\n    fn initialise(&self, d: &mut Directory) -> ContentSet {\n        let tracked_mutex = Arc::new(Mutex::new(self.clone()));\n        d.traverse(\n            PathBuf::from(\".\"),\n            &|path, _, current| {\n                // println!(\"traversing at : {path:?}\");\n\n                let mut tracked_unlock = tracked_mutex.lock().unwrap();\n\n                match current {\n                    ContentMutRef::Directory(d) => {\n                        // if parent in set\n                        // add to content set\n                        if tracked_unlock\n                            .directories\n                            .contains(&d.path.parent().unwrap().to_string_lossy().to_string())\n                        {\n                            tracked_unlock\n                                .directories\n                                .insert(d.path.to_string_lossy().to_string());\n                        }\n                    }\n                    ContentMutRef::File(f) => {\n                        if tracked_unlock\n                            .directories\n                            .contains(&path.to_string_lossy().to_string())\n                        {\n                            tracked_unlock\n                                .files\n                                .insert(path.join(&f.name).to_string_lossy().to_string());\n                        }\n                    }\n                }\n            },\n            &d.clone(),\n        );\n\n        // dont ask me\n        let result = tracked_mutex.lock().unwrap().clone();\n        result\n    }\n}\n"
            }
          },
          {
            "File": {
              "name": "relic.rs",
              "content": "// use crate::state::State;\n\n// #[derive(Debug)]\n// pub struct Relic {\n//     // holds\n//     //      history.changes\n//     //      now.changes\n//     //      root\n//     //      upstream\n//     pub upstream: State,\n// }\n// impl Relic {\n//     pub fn empty() -> Relic {\n//         Relic {\n//             upstream: State::empty(),\n//         }\n//     }\n// }\n"
            }
          },
          {
            "File": {
              "name": "error.rs",
              "content": "use serde::{Deserialize, Serialize};\n\n#[derive(Debug, Serialize, Deserialize)]\npub enum RelicError {\n    FileCantOpen,\n    IgnoredFile,\n    ConfigurationIncorrect,\n    RelicInfo(Box<RelicError>),\n}\n"
            }
          },
          {
            "File": {
              "name": "content.rs",
              "content": "use std::{\n    collections::{HashMap, HashSet},\n    fs,\n    path::PathBuf,\n    sync::{Arc, Mutex},\n};\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::{\n    change::{Change, ContainerModification, Modification},\n    error::RelicError,\n};\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub enum Content {\n    Directory(Directory),\n    File(File),\n}\n\n#[derive(Debug)]\npub enum ContentMutRef<'a> {\n    Directory(&'a mut Directory),\n    File(&'a mut File),\n}\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub struct File {\n    pub name: String,\n    pub content: String,\n}\n\nimpl File {\n    pub fn new() -> File {\n        File {\n            name: \"\".to_string(),\n            content: \"\".to_string(),\n        }\n    }\n\n    pub fn create(name: String, path: PathBuf) -> Result<File, RelicError> {\n        match fs::read_to_string(path) {\n            Ok(content) => Ok(File {\n                name: name,\n                content: content,\n            }),\n            Err(_) => {\n                // println!(\"Error creating file : {e}\");\n                Err(RelicError::FileCantOpen)\n            }\n        }\n    }\n\n    pub fn apply_changes(&mut self, modifications: &Vec<Modification>) {\n        // TODO : investigate whether an additional newline is added to eof\n        // BUG : when the file has only one line, diffs start to break\n        //\n        // content : \"\"\n        // Create(,, 0, \"something\")\n        // result : \"something\\nsomething\"\n        //\n        // content : \"something\\nsomething\"\n        // Delete(,, 0)\n        // result : \"\"\n\n        // CHANGES ARE BEING APPLIED TO THE WRONG FILE\n        // APPLY CHANGES TO UPSTREAM, NOT CURRENT\n\n        // TODO : revise modification order\n\n        // deletions first then creations?\n        //      sorted largest to smallest\n        // creations sorted smallest to largest?\n        let mut lines = self\n            .content\n            .split(\"\\n\")\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>();\n\n        let mut modifications = modifications.clone();\n        modifications.sort_by_key(|m| match m {\n            Modification::Create(_, _, l, _) => *l as i128,\n            Modification::Delete(_, _, l, _) => -(*l as i128),\n        });\n\n        for m in &modifications {\n            match m {\n                Modification::Create(_, _, line, content) => {\n                    // insert at that line\n                    lines.insert(*line, content.clone());\n                }\n                Modification::Delete(_, _, line, _) => {\n                    // delete that line\n                    lines.remove(*line);\n                }\n            }\n        }\n\n        self.content = lines.join(\"\\n\");\n    }\n}\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub struct Directory {\n    pub path: PathBuf,\n    pub name: String,\n    pub content: Vec<Content>,\n}\n\nimpl Directory {\n    pub fn new() -> Directory {\n        Directory {\n            path: PathBuf::from(\"\"),\n            name: \"\".to_string(),\n            content: vec![],\n        }\n    }\n\n    pub fn get_hash(&self) -> String {\n        sha256::digest(serde_json::to_string(&self).unwrap())\n    }\n\n    pub fn deserialise(s: String) -> Option<Directory> {\n        match serde_json::from_str(&s) {\n            Ok(d) => Some(d),\n            _ => None,\n        }\n    }\n\n    pub fn serialise(&self) -> String {\n        serde_json::to_string_pretty(&self).unwrap()\n    }\n\n    pub fn apply_changes(&mut self, changes: Change) {\n        let (c_mod_map, mod_map) = changes.as_map();\n        let c_mod_map = Arc::new(Mutex::new(c_mod_map));\n\n        // two pass\n        // create/delete containers, then create/delete file content\n\n        self.traverse(\n            PathBuf::from(\".\"),\n            &|_, _, current| {\n                if let ContentMutRef::Directory(d) = current {\n                    // somehow denote that the parent does not yet exist,\n                    // possibly recursively create directories where needed\n\n                    // TODO : optimise the match arms\n                    let mut c_mod_map_lock = c_mod_map.lock().unwrap();\n                    if let Some(c_modifications) =\n                        c_mod_map_lock.get(&d.path.to_string_lossy().to_string())\n                    {\n                        let c_clone = c_modifications.clone();\n\n                        // deals with additions\n                        d.content.append(&mut recursive_birth(\n                            &PathBuf::from(d.path.clone()),\n                            &mut c_mod_map_lock,\n                        ));\n\n                        let mut deleted_containers = HashSet::new();\n                        // deals with subtractions\n                        for c_mod in &c_clone {\n                            match c_mod {\n                                ContainerModification::DeleteDirectory(_, n) => {\n                                    deleted_containers.insert(n);\n                                }\n                                ContainerModification::DeleteFile(_, n) => {\n                                    deleted_containers.insert(n);\n                                }\n                                _ => {}\n                            }\n                        }\n\n                        d.content = d\n                            .content\n                            .iter()\n                            .filter(|x| {\n                                !deleted_containers.contains(match x {\n                                    Content::File(f) => &f.name,\n                                    Content::Directory(d) => &d.name,\n                                })\n                            })\n                            .map(|x| x.clone())\n                            .collect::<Vec<Content>>();\n                    }\n                }\n            },\n            &Directory::new(),\n        );\n\n        self.traverse(\n            PathBuf::from(\".\"),\n            &|path, _, current| {\n                if let ContentMutRef::File(f) = current {\n                    if let Some(modifications) = mod_map\n                        .get(&path.to_string_lossy().to_string())\n                        .map_or(None, |x| x.get(&f.name))\n                    {\n                        f.apply_changes(modifications);\n                    }\n                }\n            },\n            &self.clone(),\n        );\n\n        pub fn recursive_birth(\n            parent_directory: &PathBuf,\n            c_mod_map: &mut HashMap<String, HashSet<ContainerModification>>,\n        ) -> Vec<Content> {\n            // pass the new directory's parent directory\n            let mut result = vec![];\n            if let Some(c_modifications) =\n                c_mod_map.get_mut(&parent_directory.to_string_lossy().to_string())\n            {\n                let c_clone = c_modifications.clone();\n                for c in &c_clone {\n                    c_modifications.remove(&c);\n                }\n                for c_mod in c_clone {\n                    match c_mod {\n                        ContainerModification::CreateDirectory(_, n) => {\n                            result.push(Content::Directory(Directory {\n                                path: parent_directory.join(n.clone()),\n                                name: n.clone(),\n                                content: recursive_birth(\n                                    &parent_directory.join(n.clone()),\n                                    c_mod_map,\n                                ),\n                            }));\n                        }\n                        ContainerModification::CreateFile(_, n) => {\n                            result.push(Content::File(File {\n                                name: n.clone(),\n                                content: \"\".to_string(),\n                            }))\n                        }\n                        _ => {}\n                    }\n                }\n            }\n            result\n        }\n    }\n\n    pub fn unapply_changes(&mut self, changes: Change) {\n        // TODO : test if 100% reliable\n        let changes = changes.inverse();\n        self.apply_changes(changes);\n    }\n\n    pub fn traverse<F>(&mut self, root_path: PathBuf, func: &F, parent: &Directory)\n    where\n        // parent path, parent directory, current content\n        F: Fn(&PathBuf, &Directory, ContentMutRef),\n    {\n        func(&root_path, &parent, ContentMutRef::Directory(self));\n\n        let c = self.clone();\n        for content in &mut self.content {\n            match content {\n                Content::Directory(d) => {\n                    d.traverse(root_path.join(d.name.clone()), func, &c);\n                }\n                Content::File(f) => {\n                    func(&root_path, &c, ContentMutRef::File(f));\n                }\n            }\n        }\n    }\n}\n"
            }
          },
          {
            "File": {
              "name": "change.rs",
              "content": "use std::{\n    collections::{HashMap, HashSet},\n    path::{Path, PathBuf},\n};\n\nuse serde::{Deserialize, Serialize};\nuse similar::{ChangeTag, TextDiff};\n\nuse crate::{\n    content::{Content, Directory, File},\n    content_set::ContentSet,\n};\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\npub struct Change {\n    pub container_modifications: Vec<ContainerModification>,\n    pub modifications: Vec<Modification>,\n}\nimpl Change {\n    pub fn get_hash(&self) -> String {\n        sha256::digest(self.serialise_changes())\n    }\n\n    pub fn serialise_changes(&self) -> String {\n        // + D . src\n        // + F .%2Fsrc utils.rs\n        // + F .%2Fsrc branch.rs\n        // =\n        // | .%2Fsrc content.rs\n        // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\"\n        // + 1 \"\"\n\n        let mut result: Vec<String> = vec![];\n\n        for c_m in &self.container_modifications {\n            result.push(match c_m {\n                ContainerModification::CreateDirectory(p, n) => {\n                    format!(\n                        \"+ D {} {}\",\n                        urlencoding::encode(p).to_string(),\n                        urlencoding::encode(n).to_string()\n                    )\n                }\n                ContainerModification::DeleteDirectory(p, n) => {\n                    format!(\n                        \"- D {} {}\",\n                        urlencoding::encode(p).to_string(),\n                        urlencoding::encode(n).to_string()\n                    )\n                }\n                ContainerModification::CreateFile(p, n) => {\n                    format!(\n                        \"+ F {} {}\",\n                        urlencoding::encode(p).to_string(),\n                        urlencoding::encode(n).to_string()\n                    )\n                }\n                ContainerModification::DeleteFile(p, n) => {\n                    format!(\n                        \"- F {} {}\",\n                        urlencoding::encode(p).to_string(),\n                        urlencoding::encode(n).to_string()\n                    )\n                }\n            });\n        }\n\n        result.push(\"=\".to_string());\n\n        let mut map = HashMap::new();\n        for modification in &self.modifications {\n            let path = match modification {\n                Modification::Create(path, name, _, _) => (path.clone(), name.clone()),\n                Modification::Delete(path, name, _, _) => (path.clone(), name.clone()),\n            };\n            map.entry(path).or_insert(vec![]).push(modification.clone());\n        }\n\n        let mut keys = map\n            .iter()\n            .map(|x| x.0.clone())\n            .collect::<Vec<(String, String)>>();\n\n        // map.sort_by_key(|x| x.0.clone());\n        keys.sort();\n\n        for (path, name) in keys {\n            let modifications = map.get(&(path.clone(), name.clone())).unwrap();\n            result.push(format!(\n                \"| {} {}\",\n                urlencoding::encode(&path).to_string(),\n                urlencoding::encode(&name).to_string()\n            ));\n            for m in modifications {\n                result.push(match m {\n                    Modification::Create(_, _, line, content) => format!(\"+ {line} {content:?}\"),\n                    Modification::Delete(_, _, line, content) => format!(\"- {line} {content:?}\"),\n                })\n            }\n        }\n\n        result.join(\"\\n\")\n    }\n\n    pub fn deserialise_changes(s: String) -> Option<Change> {\n        // + D . src\n        // + F .%2Fsrc utils.rs\n        // + F .%2Fsrc branch.rs\n        // =\n        // | .%2Fsrc content.rs\n        // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\"\n        // + 1 \"\"\n\n        let lines = s\n            .split(\"\\n\")\n            .map(|x| x.to_string())\n            .collect::<Vec<String>>();\n\n        let mut result = Change::empty();\n        let mut container_section = true;\n\n        let mut previous_file = None;\n        for l in lines {\n            if container_section && (l == \"=\") {\n                container_section = false;\n                continue;\n            }\n            let content = l.split(\" \").collect::<Vec<&str>>();\n\n            if container_section {\n                let [species, container, parent, name] = *content.as_slice() else {\n                    return None;\n                };\n\n                result\n                    .container_modifications\n                    .push(match (species, container) {\n                        (\"+\", \"D\") => ContainerModification::CreateDirectory(\n                            urlencoding::decode(parent).unwrap().to_string(),\n                            urlencoding::decode(name).unwrap().to_string(),\n                        ),\n                        (\"-\", \"D\") => ContainerModification::DeleteDirectory(\n                            urlencoding::decode(parent).unwrap().to_string(),\n                            urlencoding::decode(name).unwrap().to_string(),\n                        ),\n                        (\"+\", \"F\") => ContainerModification::CreateFile(\n                            urlencoding::decode(parent).unwrap().to_string(),\n                            urlencoding::decode(name).unwrap().to_string(),\n                        ),\n                        (\"-\", \"F\") => ContainerModification::DeleteFile(\n                            urlencoding::decode(parent).unwrap().to_string(),\n                            urlencoding::decode(name).unwrap().to_string(),\n                        ),\n                        _ => {\n                            println!(\"invalid c_mod\");\n                            return None;\n                        }\n                    });\n            } else {\n                if content[0] == \"|\" {\n                    // | .%2Fsrc content.rs\n                    let [_, parent, name] = *content.as_slice() else {\n                        println!(\"invalid file header\");\n                        return None;\n                    };\n\n                    previous_file = Some((parent.to_string(), name.to_string()));\n                } else {\n                    // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\"\n                    if content.len() < 2 {\n                        println!(\"invalid change line\");\n                        return None;\n                    }\n\n                    let species = content[0];\n                    let line = match content[1].parse::<usize>() {\n                        Ok(i) => i,\n                        _ => {\n                            println!(\"invalid line index\");\n                            return None;\n                        }\n                    };\n\n                    match &previous_file {\n                        Some((p, n)) => match species {\n                            \"+\" => {\n                                let s = unescape::unescape(&content[2..].join(\" \")).unwrap();\n\n                                result.modifications.push(Modification::Create(\n                                    urlencoding::decode(p).unwrap().to_string(),\n                                    urlencoding::decode(n).unwrap().to_string(),\n                                    line,\n                                    s[1..s.len() - 1].to_string(),\n                                ));\n                            }\n                            \"-\" => {\n                                let s = unescape::unescape(&content[2..].join(\" \")).unwrap();\n                                result.modifications.push(Modification::Delete(\n                                    urlencoding::decode(p).unwrap().to_string(),\n                                    urlencoding::decode(n).unwrap().to_string(),\n                                    line,\n                                    s[1..s.len() - 1].to_string(),\n                                ))\n                            }\n                            _ => {\n                                return None;\n                            }\n                        },\n                        None => {\n                            return None;\n                        }\n                    }\n                }\n            }\n        }\n\n        Some(result)\n    }\n\n    pub fn empty() -> Change {\n        Change {\n            container_modifications: vec![],\n            modifications: vec![],\n        }\n    }\n\n    pub fn get_change(\n        path: String,\n        upstream_file: &File,\n        current_file: &File,\n    ) -> Vec<Modification> {\n        // https://blog.jcoglan.com/2017/02/15/the-myers-diff-algorithm-part-2/\n        // for our change algorithm, we will be using myers diff algorithm\n        // basically a shortest distance problem, with downwards, rightwards and diagonal directions as movement choices\n        // (note that diagonal movements do not contribute towards the distance)\n\n        // similar does not handle newlines at eof well at all\n        // this is the workaround for it\n        let upstream = format!(\"{}\\n\", upstream_file.content.clone());\n        let current = format!(\"{}\\n\", current_file.content.clone());\n\n        // TODO : compare hashes instead of files\n        if upstream == current {\n            return vec![];\n        }\n\n        let mut result = vec![];\n        let diff = TextDiff::from_lines(&upstream, &current);\n\n        for change in diff.iter_all_changes().filter_map(|c| match c.tag() {\n            ChangeTag::Equal => None,\n            _ => Some(c),\n        }) {\n            result.push(match change.tag() {\n                ChangeTag::Delete => Modification::Delete(\n                    path.clone(),\n                    current_file.name.clone(),\n                    change.old_index().unwrap(),\n                    change.to_string().strip_suffix(\"\\n\").unwrap().to_string(),\n                ),\n                ChangeTag::Insert => Modification::Create(\n                    path.clone(),\n                    current_file.name.clone(),\n                    change.new_index().unwrap(),\n                    change.to_string().strip_suffix(\"\\n\").unwrap().to_string(),\n                ),\n                _ => panic!(),\n            })\n        }\n\n        result\n    }\n\n    pub fn get_change_all(upstream: &Directory, current: &Directory, path: &Path) -> Change {\n        // assume that both current and previous have the same directory names\n        // has to be bfs\n\n        // initialise current state set\n        let mut current_set = HashSet::new();\n        let mut current_map = HashMap::new();\n        for c in &current.content {\n            match c {\n                Content::Directory(d) => {\n                    current_set.insert((d.name.clone(), false));\n                    current_map.insert((d.name.clone(), false), c);\n                }\n                Content::File(f) => {\n                    current_set.insert((f.name.clone(), true));\n                    current_map.insert((f.name.clone(), true), c);\n                }\n            }\n        }\n        //\n\n        // initialise upstream state set\n        let mut upstream_set = HashSet::new();\n        let mut upstream_map = HashMap::new();\n        for c in &upstream.content {\n            match c {\n                Content::Directory(d) => {\n                    upstream_set.insert((d.name.clone(), false));\n                    upstream_map.insert((d.name.clone(), false), c);\n                }\n                Content::File(f) => {\n                    upstream_set.insert((f.name.clone(), true));\n                    upstream_map.insert((f.name.clone(), true), c);\n                }\n            }\n        }\n        //\n\n        // use set differences to determine file and directory creation or deletion\n        let deleted = upstream_set\n            .difference(&current_set)\n            .map(|(n, t)| (n.to_string(), *t))\n            .collect::<Vec<(String, bool)>>();\n        let created = current_set\n            .difference(&upstream_set)\n            .map(|(n, t)| (n.to_string(), *t))\n            .collect::<Vec<(String, bool)>>();\n        //\n\n        // for all deleted files, log them\n        // for all deleted directories, log them and do the same for all children\n        let mut container_modifications = vec![];\n        let mut modifications = vec![];\n        for (dir_name, is_file) in deleted {\n            if is_file {\n                container_modifications.push(ContainerModification::DeleteFile(\n                    path.to_string_lossy().to_string(),\n                    dir_name,\n                ));\n            } else {\n                container_modifications.push(ContainerModification::DeleteDirectory(\n                    path.to_string_lossy().to_string(),\n                    dir_name.clone(),\n                ));\n                // traverse all children, add them to result as well\n                let mut changes = Change::get_change_all(\n                    match upstream_map.get(&(dir_name.clone(), false)).unwrap() {\n                        Content::Directory(deleted_d) => deleted_d,\n                        _ => panic!(),\n                    },\n                    &Directory::new(),\n                    &path.join(dir_name.clone()),\n                );\n                container_modifications.append(&mut changes.container_modifications);\n                modifications.append(&mut changes.modifications);\n            }\n        }\n        //\n\n        // for all created files, log them\n        // for all created directories, log them and do the same for all children\n        for (dir_name, is_file) in created {\n            if is_file {\n                // let p = path.join(dir_name.clone()).to_string_lossy().to_string();\n                container_modifications.push(ContainerModification::CreateFile(\n                    path.to_string_lossy().to_string(),\n                    dir_name.clone(),\n                ));\n                // Modification::Create here\n                modifications.append(&mut Change::get_change(\n                    path.to_string_lossy().to_string(),\n                    &File::new(),\n                    match current_map.get(&(dir_name, true)).unwrap() {\n                        Content::File(f) => f,\n                        _ => panic!(),\n                    },\n                ))\n            } else {\n                // let p = path.join(dir_name.clone());\n                container_modifications.push(ContainerModification::CreateDirectory(\n                    path.to_string_lossy().to_string(),\n                    dir_name.clone(),\n                ));\n\n                let mut changes = Change::get_change_all(\n                    &Directory::new(),\n                    match current_map.get(&(dir_name.clone(), false)).unwrap() {\n                        Content::Directory(d) => d,\n                        _ => panic!(),\n                    },\n                    &path.join(dir_name.clone()),\n                );\n                container_modifications.append(&mut changes.container_modifications);\n                modifications.append(&mut changes.modifications);\n            }\n        }\n\n        for content in &current.content {\n            match content {\n                Content::Directory(directory) => {\n                    // get the matching upstream directory\n                    // if it doesnt exist, that means the content is new and can be ignored\n                    // we ignore it because we have already logged it in the section above\n                    let p = path.join(directory.name.clone());\n                    let upstream_directory =\n                        match upstream_map.get(&(directory.name.clone(), false)) {\n                            Some(u) => match u {\n                                Content::Directory(u_d) => u_d,\n                                _ => panic!(),\n                            },\n                            _ => {\n                                continue;\n                            }\n                        };\n                    //\n\n                    let mut changes = Change::get_change_all(upstream_directory, directory, &p);\n                    container_modifications.append(&mut changes.container_modifications);\n                    modifications.append(&mut changes.modifications);\n                }\n                Content::File(f) => {\n                    let upstream_file = match upstream_map.get(&(f.name.clone(), true)) {\n                        Some(c) => match c {\n                            Content::File(f) => f,\n                            _ => panic!(),\n                        },\n                        None => {\n                            continue;\n                        }\n                    };\n\n                    modifications.append(&mut Change::get_change(\n                        path.to_string_lossy().to_string(),\n                        &upstream_file,\n                        &f,\n                    ));\n                }\n            }\n        }\n\n        Change {\n            container_modifications,\n            modifications,\n        }\n    }\n\n    pub fn as_map(\n        &self,\n    ) -> (\n        HashMap<String, HashSet<ContainerModification>>,\n        HashMap<String, HashMap<String, Vec<Modification>>>,\n    ) {\n        // c_mod_map: map<parent_directory, Vec<changes>>\n        // mod_map: map<parent_directory, map<file_name, Vec<changes>>>\n\n        let mut c_mod_map = HashMap::new();\n        for container_modification in &self.container_modifications {\n            let path = match container_modification {\n                ContainerModification::CreateDirectory(path, _)\n                | ContainerModification::DeleteDirectory(path, _)\n                | ContainerModification::CreateFile(path, _)\n                | ContainerModification::DeleteFile(path, _) => path.clone(),\n            };\n\n            c_mod_map\n                .entry(path)\n                .or_insert(HashSet::new())\n                .insert(container_modification.clone());\n        }\n\n        let mut mod_map = HashMap::new();\n        for modification in &self.modifications {\n            let (parent_directory, file_name) = match modification {\n                Modification::Create(path, name, _, _) => (path.clone(), name.clone()),\n                Modification::Delete(path, name, _, _) => (path.clone(), name.clone()),\n            };\n            mod_map\n                .entry(parent_directory)\n                .or_insert(HashMap::new())\n                .entry(file_name)\n                .or_insert(vec![])\n                .push(modification.clone());\n        }\n\n        (c_mod_map, mod_map)\n    }\n\n    pub fn filter_changes(&self, filter: &ContentSet) -> Change {\n        Change {\n            container_modifications: self\n                .container_modifications\n                .clone()\n                .into_iter()\n                .filter(|c_mod| match c_mod {\n                    ContainerModification::CreateFile(p, n)\n                    | ContainerModification::DeleteFile(p, n) => filter\n                        .files\n                        .contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),\n                    ContainerModification::CreateDirectory(p, n)\n                    | ContainerModification::DeleteDirectory(p, n) => filter\n                        .directories\n                        .contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),\n                })\n                .collect(),\n            modifications: self\n                .modifications\n                .clone()\n                .into_iter()\n                .filter(|m| {\n                    filter.files.contains(&match m {\n                        Modification::Create(p, n, _, _) | Modification::Delete(p, n, _, _) => {\n                            PathBuf::from(p).join(n).to_string_lossy().to_string()\n                        }\n                    })\n                })\n                .collect(),\n        }\n    }\n\n    pub fn inverse(&self) -> Change {\n        // returns inverse of the change\n        // all additions are deletions and vice versa\n\n        // the order does not follow the optimised/intuitive format\n        // additions will appear before deletions if inversed\n        // but relic will always apply changes in the correct order regardless\n\n        Change {\n            container_modifications: self\n                .container_modifications\n                .iter()\n                .map(|c| match c {\n                    ContainerModification::CreateFile(p, n) => {\n                        ContainerModification::DeleteFile(p.to_string(), n.to_string())\n                    }\n                    ContainerModification::CreateDirectory(p, n) => {\n                        ContainerModification::DeleteDirectory(p.to_string(), n.to_string())\n                    }\n                    ContainerModification::DeleteFile(p, n) => {\n                        ContainerModification::CreateFile(p.to_string(), n.to_string())\n                    }\n                    ContainerModification::DeleteDirectory(p, n) => {\n                        ContainerModification::CreateDirectory(p.to_string(), n.to_string())\n                    }\n                })\n                .collect::<Vec<ContainerModification>>(),\n            modifications: self\n                .modifications\n                .iter()\n                .map(|m| match m {\n                    Modification::Create(p, f, l, t) => {\n                        Modification::Delete(p.to_string(), f.to_string(), *l, t.to_string())\n                    }\n                    Modification::Delete(p, f, l, t) => {\n                        Modification::Create(p.to_string(), f.to_string(), *l, t.to_string())\n                    }\n                })\n                .collect::<Vec<Modification>>(),\n        }\n    }\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq, PartialOrd, Ord)]\npub enum Modification {\n    // creation/deletion of lines in files\n    Create(\n        String, // parent directory\n        String, // file name\n        usize,  // line\n        String, // text\n    ),\n    Delete(\n        String, // parent directory\n        String, // file name\n        usize,  // line\n        String, // text\n    ),\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq, PartialOrd, Ord)]\npub enum ContainerModification {\n    // denote that parent doesnt exist?\n\n    // creation/deletion of files & folders\n    CreateDirectory(\n        String, // parent directory\n        String, // name\n    ),\n    DeleteDirectory(\n        String, // parent directory\n        String, // name\n    ),\n\n    CreateFile(\n        String, // parent directory\n        String, // name\n    ),\n    DeleteFile(\n        String, // parent directory\n        String, // name\n    ),\n}\n"
            }
          },
          {
            "File": {
              "name": "relic_info.rs",
              "content": "use std::fs;\n\nuse serde::{Deserialize, Serialize};\n\nuse crate::{error::RelicError, paths::RELIC_PATH_INFO};\n\n#[derive(Serialize, Deserialize, Clone, Debug)]\npub struct RelicInfo {\n    pub remote: String,\n    pub branch: String,\n}\nimpl RelicInfo {\n    pub fn empty() -> RelicInfo {\n        RelicInfo {\n            remote: \"\".to_string(),\n            branch: \"\".to_string(),\n        }\n    }\n\n    pub fn initialise() -> Result<RelicInfo, RelicError> {\n        if let Ok(t) = fs::read_to_string(format!(\"./{RELIC_PATH_INFO}\")) {\n            if let Ok(d) = serde_json::from_str::<RelicInfo>(&t) {\n                return Ok(d);\n            }\n            return Err(RelicError::RelicInfo(Box::new(\n                RelicError::ConfigurationIncorrect,\n            )));\n        }\n        Err(RelicError::RelicInfo(Box::new(RelicError::FileCantOpen)))\n    }\n}\n"
            }
          },
          {
            "File": {
              "name": "paths.rs",
              "content": "pub const RELIC_PATH_PARENT: &str = \".relic\";\npub const RELIC_PATH_HISTORY: &str = \".relic/history\";\npub const RELIC_PATH_PENDING: &str = \".relic/pending\";\n\npub const RELIC_PATH_ROOT: &str = \".relic/root\";\npub const RELIC_PATH_INFO: &str = \".relic/info.json\";\npub const RELIC_PATH_TRACKED: &str = \".relic/tracked\";\npub const RELIC_PATH_UPSTREAM: &str = \".relic/upstream\";\n\npub const RELIC_PATH_IGNORE: &str = \".relic_ignore\";\n"
            }
          }
        ]
      }
    },
    {
      "File": {
        "name": "Cargo.toml",
        "content": "[package]\nname = \"relic\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nsha256 = \"1.5.0\"\n\nstrum = \"0.26.3\"\nstrum_macros = \"0.26.3\"\n\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\nurlencoding = \"2.1.3\"\nunescape = \"0.1.0\"\nchrono = \"0.4.41\"\n\ndotenv = \"0.15.0\"\nclap = \"4.5.38\"\n\nsimilar = \"2.7.0\"\n# diff = \"0.1.13\""
      }
    },
    {
      "File": {
        "name": "ipsum",
        "content": ",\\n};\\n\\n#[derive(Debug, Clone)]\\npub struct Commit {\\n    pub id: Option<u32>,\\n    pub message: String,\\n    pub description: String,\\n    pub change: Change,\\n    pub timestamp: u64,\\n\\n    pub author: String,\\n}\\nimpl Commit {\\n    pub fn header(&self) -> String {\\n        // \\\"integrated backwards compatibility\\\" (2025-5-26 16:30) (affected : change.rs, content.rs, ...)\\n\\n        let mut file_names = vec![];\\n        for (_, parent) in self.change.as_map().1 {\\n            for (f, _) in parent {\\n                file_names.push(f);\\n            }\\n        }\\n\\n        format!(\\n            \\\"({}) \\\\\\\"{}\\\\\\\" (affected : {}{})\\\",\\n            utils::into_human_readable(self.timestamp),\\n            self.message,\\n            file_names\\n                .iter()\\n                .take(5)\\n                .map(|x| x.to_string())\\n                .collect::<Vec<String>>()\\n                .join(\\\", \\\"),\\n            if file_names.len() > 5 { \\\", ...\\\" } else { \\\"\\\" }\\n        )\\n    }\\n\\n    pub fn serialise(&self) -> String {\\n        format!(\\n            \\\"= {} {} {:?} {:?} {}\\\\n{}\\\",\\n            self.id\\n                .map_or(\\\"LOCAL\\\".to_string(), |i| format!(\\\"{:06x}\\\", i).clone()),\\n            self.timestamp,\\n            urlencoding::encode(&self.message).to_string(),\\n            urlencoding::encode(&self.description).to_string(),\\n            self.author,\\n            self.change.serialise_changes()\\n        )\\n    }\\n\\n    pub fn deserialise(s: String) -> Option<Commit> {\\n        // = LOCAL 1747682692319414000 \\\"initial%20commit\\\" \\\"\\\" no_one\\n\\n        let lines = s.split(\\\"\\\\n\\\").collect::<Vec<&str>>();\\n        if lines.len() < 2 {\\n            // return None;\\n        }\\n\\n        let metadata = lines[0].split(\\\" \\\").collect::<Vec<&str>>();\\n        if metadata.len() != 6 {\\n            // return None;\\n        }\\n\\n        let [_, status, time, message, description, author] = *metadata.as_slice() else {\\n            return None;\\n        };\\n\\n        Some(Commit {\\n            id: status.parse::<u32>().map_or(None, |t| Some(t)),\\n            message: urlencoding::decode(&message[1..message.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            description: urlencoding::decode(&description[1..description.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            change: Change::deserialise_changes(lines[1..].join(\\\"\\\\n\\\")).unwrap_or(Change::empty()),\\n            timestamp: time.parse::<u64>().unwrap_or(0),\\n            author: author.to_string(),\\n        })\\n    }\\n}\\n\\npub fn add(_: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let mut result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n    for p in f {\\n        // TODO : path.join for this? or concatenating / works?\\n        result.insert(format!(\\n            \\\"{}{}\\\",\\n            p.to_string_lossy().to_string(),\\n            if !p.to_string_lossy().to_string().ends_with(\\\"/\\\") && p.is_dir() {\\n                \\\"/\\\"\\n            } else {\\n                \\\"\\\"\\n            }\\n        ));\\n    }\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result.drain().collect::<Vec<String>>().join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn remove(s: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n\\n    // initialise removed_content\\n    let mut removed_content = ContentSet {\\n        files: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| !x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n        directories: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n    }\\n    .initialise(&mut s.current);\\n\\n    let mut to_subtract: HashSet<String> = HashSet::from_iter(\\n        removed_content\\n            .directories\\n            .drain()\\n            .collect::<Vec<String>>()\\n            .into_iter()\\n            .map(|x| format!(\\\"{x}/\\\"))\\n            .collect::<Vec<String>>(),\\n    );\\n    to_subtract = to_subtract\\n        .union(&HashSet::from_iter(removed_content.files.drain()))\\n        .map(|x| x.to_string())\\n        .collect::<HashSet<String>>();\\n\\n    // set operations\\n    // right join\\n    // result - removed_content\\n\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result\\n            .difference(&to_subtract)\\n            .map(|x| x[2..].to_string())\\n            .collect::<Vec<String>>()\\n            .join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn commit(state: &mut State, args: &ArgMatches) {\\n    // push into pending stage\\n    // update upstream\\n\\n    // everything after the first line will be generated by Change::serialise_change\\n    r#\\\"= {commit id} {unix timestamp of commit} {message} {description} {author}\\n+ D \\\"lorem/ipsum/dolor\\\"\\n+ F \\\"lorem/ipsum/dolor/earth.txt\\\" \\\"earth.txt\\\"\\n- D \\\"lorem/sit\\\"\\n=\\n| \\\"lorem/ipsum/dolor/earth.txt\\\"\\n+ 3 asdfsdf\\n+ 5 sfsdf\\n- 7\\n| \\\"lorem/ipsum/saturn/txt\\\"\\n+ 4 lsdfljs\\\"#;\\n    let message = args.get_one::<String>(\\\"message\\\").unwrap().clone();\\n    let description = args\\n        .get_one::<String>(\\\"description\\\")\\n        .map_or(\\\"\\\".to_string(), String::clone);\\n\\n    let commit = Commit {\\n        id: None,\\n        message,\\n        description,\\n        change: state.get_changes(),\\n        timestamp: utils::get_time(),\\n        author: \\\"no_one\\\".to_string(),\\n    };\\n\\n    state.pending_add(commit);\\n    // update upstream\\n    (*state).update_upstream(&mut state.track_set.clone());\\n}\\n\\npub fn push(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pull(_: &mut State, _: &ArgMatches) {}\\n\\npub fn fetch(_: &mut State, _: &ArgMatches) {}\\n\\npub fn cherry(_: &mut State, _: &ArgMatches) {}\\n\\npub fn rollback(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pending(state: &mut State, args: &ArgMatches) {\\n    let pending = state.pending_get();\\n\\n    if let Some(commit_number) = args\\n        .get_one::<String>(\\\"COMMIT\\\")\\n        .map_or(None, |x| x.parse::<i32>().map_or(None, |x| Some(x)))\\n    {\\n        // display selected\\n        if (commit_number < 0) || (commit_number >= pending.len() as i32) {\\n            println!(\\n                \\\"Invalid selection. Please select commit numbers in the range of (0-{})\\\",\\n                pending.len() - 1\\n            );\\n            return;\\n        }\\n\\n        let copy = state.current.clone();\\n        let changes = pending[commit_number as usize].clone();\\n        println!(\\\"before : {}\\\", copy.get_hash());\\n\\n        let mut inversed = copy.clone();\\n        inversed.unapply_changes(changes.change.clone());\\n        println!(\\\"inverse : {}\\\", inversed.get_hash());\\n\\n        let mut after = inversed.clone();\\n        after.apply_changes(changes.change.clone());\\n        println!(\\\"after : {}\\\", after.get_hash());\\n\\n        let mut a = after\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n        let mut b = copy\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n\\n        a.sort();\\n        b.sort();\\n\\n        // println!(\\\"{}\\\", utils::generate_tree(&copy));\\n        // println!(\\\"{}\\\", utils::generate_tree(&after));\\n        // println!(\\\"{}\\\", utils::generate_tree(&inversed));\\n\\n        for i in 0..a.len() {\\n            let c = a[i].clone();\\n            let d = b[i].clone();\\n            if c != d {\\n                println!(\\\"{c}\\\\n{d}\\\\n\\\\n\\\\n\\\\n\\\\n\\\");\\n            }\\n        }\\n    } else {\\n        // display all\\n        for (index, c) in pending.iter().enumerate() {\\n            println!(\\\"{index}. {}\\\", c.header());\\n        }\\n    }\\n}\\n\"\n,\\n};\\n\\n#[derive(Debug, Clone)]\\npub struct Commit {\\n    pub id: Option<u32>,\\n    pub message: String,\\n    pub description: String,\\n    pub change: Change,\\n    pub timestamp: u64,\\n\\n    pub author: String,\\n}\\nimpl Commit {\\n    pub fn header(&self) -> String {\\n        // \\\"integrated backwards compatibility\\\" (2025-5-26 16:30) (affected : change.rs, content.rs, ...)\\n\\n        let mut file_names = vec![];\\n        for (_, parent) in self.change.as_map().1 {\\n            for (f, _) in parent {\\n                file_names.push(f);\\n            }\\n        }\\n\\n        format!(\\n            \\\"({}) \\\\\\\"{}\\\\\\\" (affected : {}{})\\\",\\n            utils::into_human_readable(self.timestamp),\\n            self.message,\\n            file_names\\n                .iter()\\n                .take(5)\\n                .map(|x| x.to_string())\\n                .collect::<Vec<String>>()\\n                .join(\\\", \\\"),\\n            if file_names.len() > 5 { \\\", ...\\\" } else { \\\"\\\" }\\n        )\\n    }\\n\\n    pub fn serialise(&self) -> String {\\n        format!(\\n            \\\"= {} {} {:?} {:?} {}\\\\n{}\\\",\\n            self.id\\n                .map_or(\\\"LOCAL\\\".to_string(), |i| format!(\\\"{:06x}\\\", i).clone()),\\n            self.timestamp,\\n            urlencoding::encode(&self.message).to_string(),\\n            urlencoding::encode(&self.description).to_string(),\\n            self.author,\\n            self.change.serialise_changes()\\n        )\\n    }\\n\\n    pub fn deserialise(s: String) -> Option<Commit> {\\n        // = LOCAL 1747682692319414000 \\\"initial%20commit\\\" \\\"\\\" no_one\\n\\n        let lines = s.split(\\\"\\\\n\\\").collect::<Vec<&str>>();\\n        if lines.len() < 2 {\\n            // return None;\\n        }\\n\\n        let metadata = lines[0].split(\\\" \\\").collect::<Vec<&str>>();\\n        if metadata.len() != 6 {\\n            // return None;\\n        }\\n\\n        let [_, status, time, message, description, author] = *metadata.as_slice() else {\\n            return None;\\n        };\\n\\n        Some(Commit {\\n            id: status.parse::<u32>().map_or(None, |t| Some(t)),\\n            message: urlencoding::decode(&message[1..message.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            description: urlencoding::decode(&description[1..description.len() - 1].to_string())\\n                .unwrap()\\n                .to_string(),\\n            change: Change::deserialise_changes(lines[1..].join(\\\"\\\\n\\\")).unwrap_or(Change::empty()),\\n            timestamp: time.parse::<u64>().unwrap_or(0),\\n            author: author.to_string(),\\n        })\\n    }\\n}\\n\\npub fn add(_: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let mut result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n    for p in f {\\n        // TODO : path.join for this? or concatenating / works?\\n        result.insert(format!(\\n            \\\"{}{}\\\",\\n            p.to_string_lossy().to_string(),\\n            if !p.to_string_lossy().to_string().ends_with(\\\"/\\\") && p.is_dir() {\\n                \\\"/\\\"\\n            } else {\\n                \\\"\\\"\\n            }\\n        ));\\n    }\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result.drain().collect::<Vec<String>>().join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn remove(s: &mut State, args: &ArgMatches) {\\n    let f = args\\n        .get_many::<PathBuf>(\\\"FILE\\\")\\n        .unwrap()\\n        .map(|x| x.clone())\\n        .collect::<Vec<PathBuf>>();\\n\\n    let result: HashSet<String> = HashSet::from_iter(\\n        fs::read_to_string(\\\"./.relic/tracked\\\")\\n            .unwrap()\\n            .split(\\\"\\\\n\\\")\\n            .filter(|x| !x.is_empty())\\n            .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string())\\n            .collect::<Vec<String>>(),\\n    );\\n\\n    // initialise removed_content\\n    let mut removed_content = ContentSet {\\n        files: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| !x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n        directories: HashSet::from_iter(\\n            f.iter()\\n                .filter(|x| x.is_dir())\\n                .map(|x| PathBuf::from(\\\".\\\").join(x).to_string_lossy().to_string()),\\n        ),\\n    }\\n    .initialise(&mut s.current);\\n\\n    let mut to_subtract: HashSet<String> = HashSet::from_iter(\\n        removed_content\\n            .directories\\n            .drain()\\n            .collect::<Vec<String>>()\\n            .into_iter()\\n            .map(|x| format!(\\\"{x}/\\\"))\\n            .collect::<Vec<String>>(),\\n    );\\n    to_subtract = to_subtract\\n        .union(&HashSet::from_iter(removed_content.files.drain()))\\n        .map(|x| x.to_string())\\n        .collect::<HashSet<String>>();\\n\\n    // set operations\\n    // right join\\n    // result - removed_content\\n\\n    let _ = fs::write(\\n        \\\"./.relic/tracked\\\",\\n        result\\n            .difference(&to_subtract)\\n            .map(|x| x[2..].to_string())\\n            .collect::<Vec<String>>()\\n            .join(\\\"\\\\n\\\"),\\n    );\\n}\\n\\npub fn commit(state: &mut State, args: &ArgMatches) {\\n    // push into pending stage\\n    // update upstream\\n\\n    // everything after the first line will be generated by Change::serialise_change\\n    r#\\\"= {commit id} {unix timestamp of commit} {message} {description} {author}\\n+ D \\\"lorem/ipsum/dolor\\\"\\n+ F \\\"lorem/ipsum/dolor/earth.txt\\\" \\\"earth.txt\\\"\\n- D \\\"lorem/sit\\\"\\n=\\n| \\\"lorem/ipsum/dolor/earth.txt\\\"\\n+ 3 asdfsdf\\n+ 5 sfsdf\\n- 7\\n| \\\"lorem/ipsum/saturn/txt\\\"\\n+ 4 lsdfljs\\\"#;\\n    let message = args.get_one::<String>(\\\"message\\\").unwrap().clone();\\n    let description = args\\n        .get_one::<String>(\\\"description\\\")\\n        .map_or(\\\"\\\".to_string(), String::clone);\\n\\n    let commit = Commit {\\n        id: None,\\n        message,\\n        description,\\n        change: state.get_changes(),\\n        timestamp: utils::get_time(),\\n        author: \\\"no_one\\\".to_string(),\\n    };\\n\\n    state.pending_add(commit);\\n    // update upstream\\n    (*state).update_upstream(&mut state.track_set.clone());\\n}\\n\\npub fn push(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pull(_: &mut State, _: &ArgMatches) {}\\n\\npub fn fetch(_: &mut State, _: &ArgMatches) {}\\n\\npub fn cherry(_: &mut State, _: &ArgMatches) {}\\n\\npub fn rollback(_: &mut State, _: &ArgMatches) {}\\n\\npub fn pending(state: &mut State, args: &ArgMatches) {\\n    let pending = state.pending_get();\\n\\n    if let Some(commit_number) = args\\n        .get_one::<String>(\\\"COMMIT\\\")\\n        .map_or(None, |x| x.parse::<i32>().map_or(None, |x| Some(x)))\\n    {\\n        // display selected\\n        if (commit_number < 0) || (commit_number >= pending.len() as i32) {\\n            println!(\\n                \\\"Invalid selection. Please select commit numbers in the range of (0-{})\\\",\\n                pending.len() - 1\\n            );\\n            return;\\n        }\\n\\n        let copy = state.current.clone();\\n        let changes = pending[commit_number as usize].clone();\\n        println!(\\\"before : {}\\\", copy.get_hash());\\n\\n        let mut after = copy.clone();\\n        after.apply_changes(changes.change.clone());\\n        println!(\\\"after : {}\\\", after.get_hash());\\n\\n        let mut inversed = after.clone();\\n        inversed.unapply_changes(changes.change.clone());\\n        println!(\\\"inverse : {}\\\", inversed.get_hash());\\n\\n        let mut a = inversed\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n        let mut b = copy\\n            .serialise()\\n            .split(\\\"\\\\n\\\")\\n            .map(|x| x.to_string())\\n            .collect::<Vec<String>>();\\n\\n        a.sort();\\n        b.sort();\\n\\n        // println!(\\\"{}\\\", utils::generate_tree(&copy));\\n        // println!(\\\"{}\\\", utils::generate_tree(&after));\\n        // println!(\\\"{}\\\", utils::generate_tree(&inversed));\\n\\n        for i in 0..a.len() {\\n            let c = a[i].clone();\\n            let d = b[i].clone();\\n            if c != d {\\n                println!(\\\"{c}\\\\n{d}\\\\n\\\\n\\\\n\\\\n\\\\n\\\");\\n            }\\n        }\\n        // display all\\n        for (index, c) in pending.iter().enumerate() {\\n            println!(\\\"{index}. {}\\\", c.header());\\n        }\\n    }\\n}\\n\"\n"
      }
    },
    {
      "Directory": {
        "path": "./lorem",
        "name": "lorem",
        "content": [
          {
            "File": {
              "name": "earth",
              "content": "can you understand me?"
            }
          },
          {
            "File": {
              "name": "mars",
              "content": "sldfjsljdkf"
            }
          },
          {
            "Directory": {
              "path": "./lorem/ipsum",
              "name": "ipsum",
              "content": [
                {
                  "File": {
                    "name": "saturn",
                    "content": ""
                  }
                },
                {
                  "File": {
                    "name": "temp",
                    "content": "alsfdk"
                  }
                },
                {
                  "Directory": {
                    "path": "./lorem/ipsum/dolor",
                    "name": "dolor",
                    "content": [
                      {
                        "File": {
                          "name": "pluto",
                          "content": ""
                        }
                      }
                    ]
                  }
                }
              ]
            }
          },
          {
            "File": {
              "name": "pluto",
              "content": ""
            }
          }
        ]
      }
    },
    {
      "File": {
        "name": "Cargo.lock",
        "content": "# This file is automatically @generated by Cargo.\n# It is not intended for manual editing.\nversion = 4\n\n[[package]]\nname = \"addr2line\"\nversion = \"0.24.2\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"dfbe277e56a376000877090da837660b4427aad530e3028d44e0bffe4f89a1c1\"\ndependencies = [\n \"gimli\",\n]\n\n[[package]]\nname = \"adler2\"\nversion = \"2.0.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"512761e0bb2578dd7380c6baaa0f4ce03e84f95e960231d1dec8bf4d7d6e2627\"\n\n[[package]]\nname = \"android-tzdata\"\nversion = \"0.1.1\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"e999941b234f3131b00bc13c22d06e8c5ff726d1b6318ac7eb276997bbb4fef0\"\n\n[[package]]\nname = \"android_system_properties\"\nversion = \"0.1.5\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"819e7219dbd41043ac279b19830f2efc897156490d7fd6ea916720117ee66311\"\ndependencies = [\n \"libc\",\n]\n\n[[package]]\nname = \"anstream\"\nversion = \"0.6.18\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"8acc5369981196006228e28809f761875c0327210a891e941f4c683b3a99529b\"\ndependencies = [\n \"anstyle\",\n \"anstyle-parse\",\n \"anstyle-query\",\n \"anstyle-wincon\",\n \"colorchoice\",\n \"is_terminal_polyfill\",\n \"utf8parse\",\n]\n\n[[package]]\nname = \"anstyle\"\nversion = \"1.0.10\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"55cc3b69f167a1ef2e161439aa98aed94e6028e5f9a59be9a6ffb47aef1651f9\"\n\n[[package]]\nname = \"anstyle-parse\"\nversion = \"0.2.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"3b2d16507662817a6a20a9ea92df6652ee4f94f914589377d69f3b21bc5798a9\"\ndependencies = [\n \"utf8parse\",\n]\n\n[[package]]\nname = \"anstyle-query\"\nversion = \"1.1.2\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"79947af37f4177cfead1110013d678905c37501914fba0efea834c3fe9a8d60c\"\ndependencies = [\n \"windows-sys\",\n]\n\n[[package]]\nname = \"anstyle-wincon\"\nversion = \"3.0.7\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"ca3534e77181a9cc07539ad51f2141fe32f6c3ffd4df76db8ad92346b003ae4e\"\ndependencies = [\n \"anstyle\",\n \"once_cell\",\n \"windows-sys\",\n]\n\n[[package]]\nname = \"async-trait\"\nversion = \"0.1.88\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"e539d3fca749fcee5236ab05e93a52867dd549cc157c8cb7f99595f3cedffdb5\"\ndependencies = [\n \"proc-macro2\",\n \"quote\",\n \"syn\",\n]\n\n[[package]]\nname = \"autocfg\"\nversion = \"1.4.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"ace50bade8e6234aa140d9a2f552bbee1db4d353f69b8217bc503490fc1a9f26\"\n\n[[package]]\nname = \"backtrace\"\nversion = \"0.3.74\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"8d82cb332cdfaed17ae235a638438ac4d4839913cc2af585c3c6746e8f8bee1a\"\ndependencies = [\n \"addr2line\",\n \"cfg-if\",\n \"libc\",\n \"miniz_oxide\",\n \"object\",\n \"rustc-demangle\",\n \"windows-targets\",\n]\n\n[[package]]\nname = \"block-buffer\"\nversion = \"0.10.4\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"3078c7629b62d3f0439517fa394996acacc5cbc91c5a20d8c658e77abd503a71\"\ndependencies = [\n \"generic-array\",\n]\n\n[[package]]\nname = \"bumpalo\"\nversion = \"3.17.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1628fb46dfa0b37568d12e5edd512553eccf6a22a78e8bde00bb4aed84d5bdbf\"\n\n[[package]]\nname = \"bytes\"\nversion = \"1.10.1\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"d71b6127be86fdcfddb610f7182ac57211d4b18a3e9c82eb2d17662f2227ad6a\"\n\n[[package]]\nname = \"cc\"\nversion = \"1.2.24\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"16595d3be041c03b09d08d0858631facccee9221e579704070e6e9e4915d3bc7\"\ndependencies = [\n \"shlex\",\n]\n\n[[package]]\nname = \"cfg-if\"\nversion = \"1.0.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd\"\n\n[[package]]\nname = \"chrono\"\nversion = \"0.4.41\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"c469d952047f47f91b68d1cba3f10d63c11d73e4636f24f08daf0278abf01c4d\"\ndependencies = [\n \"android-tzdata\",\n \"iana-time-zone\",\n \"js-sys\",\n \"num-traits\",\n \"wasm-bindgen\",\n \"windows-link\",\n]\n\n[[package]]\nname = \"clap\"\nversion = \"4.5.38\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"ed93b9805f8ba930df42c2590f05453d5ec36cbb85d018868a5b24d31f6ac000\"\ndependencies = [\n \"clap_builder\",\n]\n\n[[package]]\nname = \"clap_builder\"\nversion = \"4.5.38\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"379026ff283facf611b0ea629334361c4211d1b12ee01024eec1591133b04120\"\ndependencies = [\n \"anstream\",\n \"anstyle\",\n \"clap_lex\",\n \"strsim\",\n]\n\n[[package]]\nname = \"clap_lex\"\nversion = \"0.7.4\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"f46ad14479a25103f283c0f10005961cf086d8dc42205bb44c46ac563475dca6\"\n\n[[package]]\nname = \"colorchoice\"\nversion = \"1.0.3\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"5b63caa9aa9397e2d9480a9b13673856c78d8ac123288526c37d7839f2a86990\"\n\n[[package]]\nname = \"core-foundation-sys\"\nversion = \"0.8.7\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"773648b94d0e5d620f64f280777445740e61fe701025087ec8b57f45c791888b\"\n\n[[package]]\nname = \"cpufeatures\"\nversion = \"0.2.17\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"59ed5838eebb26a2bb2e58f6d5b5316989ae9d08bab10e0e6d103e656d1b0280\"\ndependencies = [\n \"libc\",\n]\n\n[[package]]\nname = \"crypto-common\"\nversion = \"0.1.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1bfb12502f3fc46cca1bb51ac28df9d618d813cdc3d2f25b9fe775a34af26bb3\"\ndependencies = [\n \"generic-array\",\n \"typenum\",\n]\n\n[[package]]\nname = \"digest\"\nversion = \"0.10.7\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"9ed9a281f7bc9b7576e61468ba615a66a5c8cfdff42420a70aa82701a3b1e292\"\ndependencies = [\n \"block-buffer\",\n \"crypto-common\",\n]\n\n[[package]]\nname = \"dotenv\"\nversion = \"0.15.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"77c90badedccf4105eca100756a0b1289e191f6fcbdadd3cee1d2f614f97da8f\"\n\n[[package]]\nname = \"generic-array\"\nversion = \"0.14.7\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"85649ca51fd72272d7821adaf274ad91c288277713d9c18820d8499a7ff69e9a\"\ndependencies = [\n \"typenum\",\n \"version_check\",\n]\n\n[[package]]\nname = \"gimli\"\nversion = \"0.31.1\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"07e28edb80900c19c28f1072f2e8aeca7fa06b23cd4169cefe1af5aa3260783f\"\n\n[[package]]\nname = \"heck\"\nversion = \"0.5.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"2304e00983f87ffb38b55b444b5e3b60a884b5d30c0fca7d82fe33449bbe55ea\"\n\n[[package]]\nname = \"hex\"\nversion = \"0.4.3\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"7f24254aa9a54b5c858eaee2f5bccdb46aaf0e486a595ed5fd8f86ba55232a70\"\n\n[[package]]\nname = \"iana-time-zone\"\nversion = \"0.1.63\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"b0c919e5debc312ad217002b8048a17b7d83f80703865bbfcfebb0458b0b27d8\"\ndependencies = [\n \"android_system_properties\",\n \"core-foundation-sys\",\n \"iana-time-zone-haiku\",\n \"js-sys\",\n \"log\",\n \"wasm-bindgen\",\n \"windows-core\",\n]\n\n[[package]]\nname = \"iana-time-zone-haiku\"\nversion = \"0.1.2\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"f31827a206f56af32e590ba56d5d2d085f558508192593743f16b2306495269f\"\ndependencies = [\n \"cc\",\n]\n\n[[package]]\nname = \"is_terminal_polyfill\"\nversion = \"1.70.1\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"7943c866cc5cd64cbc25b2e01621d07fa8eb2a1a23160ee81ce38704e97b8ecf\"\n\n[[package]]\nname = \"itoa\"\nversion = \"1.0.15\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"4a5f13b858c8d314ee3e8f639011f7ccefe71f97f96e50151fb991f267928e2c\"\n\n[[package]]\nname = \"js-sys\"\nversion = \"0.3.77\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1cfaf33c695fc6e08064efbc1f72ec937429614f25eef83af942d0e227c3a28f\"\ndependencies = [\n \"once_cell\",\n \"wasm-bindgen\",\n]\n\n[[package]]\nname = \"libc\"\nversion = \"0.2.172\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"d750af042f7ef4f724306de029d18836c26c1765a54a6a3f094cbd23a7267ffa\"\n\n[[package]]\nname = \"log\"\nversion = \"0.4.27\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"13dc2df351e3202783a1fe0d44375f7295ffb4049267b0f3018346dc122a1d94\"\n\n[[package]]\nname = \"memchr\"\nversion = \"2.7.4\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"78ca9ab1a0babb1e7d5695e3530886289c18cf2f87ec19a575a0abdce112e3a3\"\n\n[[package]]\nname = \"miniz_oxide\"\nversion = \"0.8.8\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"3be647b768db090acb35d5ec5db2b0e1f1de11133ca123b9eacf5137868f892a\"\ndependencies = [\n \"adler2\",\n]\n\n[[package]]\nname = \"num-traits\"\nversion = \"0.2.19\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"071dfc062690e90b734c0b2273ce72ad0ffa95f0c74596bc250dcfd960262841\"\ndependencies = [\n \"autocfg\",\n]\n\n[[package]]\nname = \"object\"\nversion = \"0.36.7\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"62948e14d923ea95ea2c7c86c71013138b66525b86bdc08d2dcc262bdb497b87\"\ndependencies = [\n \"memchr\",\n]\n\n[[package]]\nname = \"once_cell\"\nversion = \"1.21.3\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"42f5e15c9953c5e4ccceeb2e7382a716482c34515315f7b03532b8b4e8393d2d\"\n\n[[package]]\nname = \"pin-project-lite\"\nversion = \"0.2.16\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"3b3cff922bd51709b605d9ead9aa71031d81447142d828eb4a6eba76fe619f9b\"\n\n[[package]]\nname = \"proc-macro2\"\nversion = \"1.0.95\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"02b3e5e68a3a1a02aad3ec490a98007cbc13c37cbe84a3cd7b8e406d76e7f778\"\ndependencies = [\n \"unicode-ident\",\n]\n\n[[package]]\nname = \"quote\"\nversion = \"1.0.40\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1885c039570dc00dcb4ff087a89e185fd56bae234ddc7f056a945bf36467248d\"\ndependencies = [\n \"proc-macro2\",\n]\n\n[[package]]\nname = \"relic\"\nversion = \"0.1.0\"\ndependencies = [\n \"chrono\",\n \"clap\",\n \"dotenv\",\n \"serde\",\n \"serde_json\",\n \"sha256\",\n \"similar\",\n \"strum\",\n \"strum_macros\",\n \"unescape\",\n \"urlencoding\",\n]\n\n[[package]]\nname = \"rustc-demangle\"\nversion = \"0.1.24\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"719b953e2095829ee67db738b3bfa9fa368c94900df327b3f07fe6e794d2fe1f\"\n\n[[package]]\nname = \"rustversion\"\nversion = \"1.0.20\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"eded382c5f5f786b989652c49544c4877d9f015cc22e145a5ea8ea66c2921cd2\"\n\n[[package]]\nname = \"ryu\"\nversion = \"1.0.20\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"28d3b2b1366ec20994f1fd18c3c594f05c5dd4bc44d8bb0c1c632c8d6829481f\"\n\n[[package]]\nname = \"serde\"\nversion = \"1.0.219\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"5f0e2c6ed6606019b4e29e69dbaba95b11854410e5347d525002456dbbb786b6\"\ndependencies = [\n \"serde_derive\",\n]\n\n[[package]]\nname = \"serde_derive\"\nversion = \"1.0.219\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"5b0276cf7f2c73365f7157c8123c21cd9a50fbbd844757af28ca1f5925fc2a00\"\ndependencies = [\n \"proc-macro2\",\n \"quote\",\n \"syn\",\n]\n\n[[package]]\nname = \"serde_json\"\nversion = \"1.0.140\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"20068b6e96dc6c9bd23e01df8827e6c7e1f2fddd43c21810382803c136b99373\"\ndependencies = [\n \"itoa\",\n \"memchr\",\n \"ryu\",\n \"serde\",\n]\n\n[[package]]\nname = \"sha2\"\nversion = \"0.10.8\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"793db75ad2bcafc3ffa7c68b215fee268f537982cd901d132f89c6343f3a3dc8\"\ndependencies = [\n \"cfg-if\",\n \"cpufeatures\",\n \"digest\",\n]\n\n[[package]]\nname = \"sha256\"\nversion = \"1.6.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"f880fc8562bdeb709793f00eb42a2ad0e672c4f883bbe59122b926eca935c8f6\"\ndependencies = [\n \"async-trait\",\n \"bytes\",\n \"hex\",\n \"sha2\",\n \"tokio\",\n]\n\n[[package]]\nname = \"shlex\"\nversion = \"1.3.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"0fda2ff0d084019ba4d7c6f371c95d8fd75ce3524c3cb8fb653a3023f6323e64\"\n\n[[package]]\nname = \"similar\"\nversion = \"2.7.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"bbbb5d9659141646ae647b42fe094daf6c6192d1620870b449d9557f748b2daa\"\n\n[[package]]\nname = \"strsim\"\nversion = \"0.11.1\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"7da8b5736845d9f2fcb837ea5d9e2628564b3b043a70948a3f0b778838c5fb4f\"\n\n[[package]]\nname = \"strum\"\nversion = \"0.26.3\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"8fec0f0aef304996cf250b31b5a10dee7980c85da9d759361292b8bca5a18f06\"\n\n[[package]]\nname = \"strum_macros\"\nversion = \"0.26.4\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"4c6bee85a5a24955dc440386795aa378cd9cf82acd5f764469152d2270e581be\"\ndependencies = [\n \"heck\",\n \"proc-macro2\",\n \"quote\",\n \"rustversion\",\n \"syn\",\n]\n\n[[package]]\nname = \"syn\"\nversion = \"2.0.100\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"b09a44accad81e1ba1cd74a32461ba89dee89095ba17b32f5d03683b1b1fc2a0\"\ndependencies = [\n \"proc-macro2\",\n \"quote\",\n \"unicode-ident\",\n]\n\n[[package]]\nname = \"tokio\"\nversion = \"1.44.2\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"e6b88822cbe49de4185e3a4cbf8321dd487cf5fe0c5c65695fef6346371e9c48\"\ndependencies = [\n \"backtrace\",\n \"bytes\",\n \"pin-project-lite\",\n]\n\n[[package]]\nname = \"typenum\"\nversion = \"1.18.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1dccffe3ce07af9386bfd29e80c0ab1a8205a2fc34e4bcd40364df902cfa8f3f\"\n\n[[package]]\nname = \"unescape\"\nversion = \"0.1.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"ccb97dac3243214f8d8507998906ca3e2e0b900bf9bf4870477f125b82e68f6e\"\n\n[[package]]\nname = \"unicode-ident\"\nversion = \"1.0.18\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"5a5f39404a5da50712a4c1eecf25e90dd62b613502b7e925fd4e4d19b5c96512\"\n\n[[package]]\nname = \"urlencoding\"\nversion = \"2.1.3\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"daf8dba3b7eb870caf1ddeed7bc9d2a049f3cfdfae7cb521b087cc33ae4c49da\"\n\n[[package]]\nname = \"utf8parse\"\nversion = \"0.2.2\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"06abde3611657adf66d383f00b093d7faecc7fa57071cce2578660c9f1010821\"\n\n[[package]]\nname = \"version_check\"\nversion = \"0.9.5\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"0b928f33d975fc6ad9f86c8f283853ad26bdd5b10b7f1542aa2fa15e2289105a\"\n\n[[package]]\nname = \"wasm-bindgen\"\nversion = \"0.2.100\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1edc8929d7499fc4e8f0be2262a241556cfc54a0bea223790e71446f2aab1ef5\"\ndependencies = [\n \"cfg-if\",\n \"once_cell\",\n \"rustversion\",\n \"wasm-bindgen-macro\",\n]\n\n[[package]]\nname = \"wasm-bindgen-backend\"\nversion = \"0.2.100\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"2f0a0651a5c2bc21487bde11ee802ccaf4c51935d0d3d42a6101f98161700bc6\"\ndependencies = [\n \"bumpalo\",\n \"log\",\n \"proc-macro2\",\n \"quote\",\n \"syn\",\n \"wasm-bindgen-shared\",\n]\n\n[[package]]\nname = \"wasm-bindgen-macro\"\nversion = \"0.2.100\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"7fe63fc6d09ed3792bd0897b314f53de8e16568c2b3f7982f468c0bf9bd0b407\"\ndependencies = [\n \"quote\",\n \"wasm-bindgen-macro-support\",\n]\n\n[[package]]\nname = \"wasm-bindgen-macro-support\"\nversion = \"0.2.100\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"8ae87ea40c9f689fc23f209965b6fb8a99ad69aeeb0231408be24920604395de\"\ndependencies = [\n \"proc-macro2\",\n \"quote\",\n \"syn\",\n \"wasm-bindgen-backend\",\n \"wasm-bindgen-shared\",\n]\n\n[[package]]\nname = \"wasm-bindgen-shared\"\nversion = \"0.2.100\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1a05d73b933a847d6cccdda8f838a22ff101ad9bf93e33684f39c1f5f0eece3d\"\ndependencies = [\n \"unicode-ident\",\n]\n\n[[package]]\nname = \"windows-core\"\nversion = \"0.61.2\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"c0fdd3ddb90610c7638aa2b3a3ab2904fb9e5cdbecc643ddb3647212781c4ae3\"\ndependencies = [\n \"windows-implement\",\n \"windows-interface\",\n \"windows-link\",\n \"windows-result\",\n \"windows-strings\",\n]\n\n[[package]]\nname = \"windows-implement\"\nversion = \"0.60.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"a47fddd13af08290e67f4acabf4b459f647552718f683a7b415d290ac744a836\"\ndependencies = [\n \"proc-macro2\",\n \"quote\",\n \"syn\",\n]\n\n[[package]]\nname = \"windows-interface\"\nversion = \"0.59.1\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"bd9211b69f8dcdfa817bfd14bf1c97c9188afa36f4750130fcdf3f400eca9fa8\"\ndependencies = [\n \"proc-macro2\",\n \"quote\",\n \"syn\",\n]\n\n[[package]]\nname = \"windows-link\"\nversion = \"0.1.1\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"76840935b766e1b0a05c0066835fb9ec80071d4c09a16f6bd5f7e655e3c14c38\"\n\n[[package]]\nname = \"windows-result\"\nversion = \"0.3.4\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"56f42bd332cc6c8eac5af113fc0c1fd6a8fd2aa08a0119358686e5160d0586c6\"\ndependencies = [\n \"windows-link\",\n]\n\n[[package]]\nname = \"windows-strings\"\nversion = \"0.4.2\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"56e6c93f3a0c3b36176cb1327a4958a0353d5d166c2a35cb268ace15e91d3b57\"\ndependencies = [\n \"windows-link\",\n]\n\n[[package]]\nname = \"windows-sys\"\nversion = \"0.59.0\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"1e38bc4d79ed67fd075bcc251a1c39b32a1776bbe92e5bef1f0bf1f8c531853b\"\ndependencies = [\n \"windows-targets\",\n]\n\n[[package]]\nname = \"windows-targets\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"9b724f72796e036ab90c1021d4780d4d3d648aca59e491e6b98e725b84e99973\"\ndependencies = [\n \"windows_aarch64_gnullvm\",\n \"windows_aarch64_msvc\",\n \"windows_i686_gnu\",\n \"windows_i686_gnullvm\",\n \"windows_i686_msvc\",\n \"windows_x86_64_gnu\",\n \"windows_x86_64_gnullvm\",\n \"windows_x86_64_msvc\",\n]\n\n[[package]]\nname = \"windows_aarch64_gnullvm\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"32a4622180e7a0ec044bb555404c800bc9fd9ec262ec147edd5989ccd0c02cd3\"\n\n[[package]]\nname = \"windows_aarch64_msvc\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"09ec2a7bb152e2252b53fa7803150007879548bc709c039df7627cabbd05d469\"\n\n[[package]]\nname = \"windows_i686_gnu\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"8e9b5ad5ab802e97eb8e295ac6720e509ee4c243f69d781394014ebfe8bbfa0b\"\n\n[[package]]\nname = \"windows_i686_gnullvm\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"0eee52d38c090b3caa76c563b86c3a4bd71ef1a819287c19d586d7334ae8ed66\"\n\n[[package]]\nname = \"windows_i686_msvc\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"240948bc05c5e7c6dabba28bf89d89ffce3e303022809e73deaefe4f6ec56c66\"\n\n[[package]]\nname = \"windows_x86_64_gnu\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"147a5c80aabfbf0c7d901cb5895d1de30ef2907eb21fbbab29ca94c5b08b1a78\"\n\n[[package]]\nname = \"windows_x86_64_gnullvm\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"24d5b23dc417412679681396f2b49f3de8c1473deb516bd34410872eff51ed0d\"\n\n[[package]]\nname = \"windows_x86_64_msvc\"\nversion = \"0.52.6\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\nchecksum = \"589f6da84c646204747d1270a2a5661ea66ed1cced2631d546fdfb155959f9ec\"\n"
      }
    },
    {
      "File": {
        "name": ".relic_ignore",
        "content": "-- Added by Relic: Automatically ignore all git content\n.git/\n.gitignore\n\ntarget/"
      }
    }
  ]
}