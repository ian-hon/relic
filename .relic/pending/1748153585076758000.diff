= LOCAL 1748153585076758000 "idk" "" no_one
=
| . Cargo.lock
- 2
+ 2 "version = 4"
+ 296 " \"unescape\","
+ 434 "name = \"unescape\""
+ 435 "version = \"0.1.0\""
+ 436 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 437 "checksum = \"ccb97dac3243214f8d8507998906ca3e2e0b900bf9bf4870477f125b82e68f6e\""
+ 438 ""
+ 439 "[[package]]"
| . Cargo.toml
+ 14 "unescape = \"0.1.0\""
| .%2Fsrc branch.rs
- 4
+ 4 "pub fn branch(_: &mut State, _: &ArgMatches) {}"
- 6
| .%2Fsrc change.rs
- 0
+ 0 "use std::{"
+ 1 "    collections::{HashMap, HashSet},"
+ 2 "    path::{Path, PathBuf},"
+ 3 "};"
- 5
+ 8 "use crate::{"
+ 9 "    content::{Content, Directory, File},"
+ 10 "    content_set::ContentSet,"
+ 11 "};"
- 10
+ 16 "    pub modifications: Vec<Modification>,"
+ 19 "    pub fn get_hash(&self) -> String {"
+ 20 "        sha256::digest(self.serialise_changes())"
+ 21 "    }"
+ 22 ""
- 14
- 15
- 16
- 17
- 18
- 19
- 20
- 21
- 22
- 23
- 24
+ 24 "        // + D . src"
+ 25 "        // + F .%2Fsrc utils.rs"
+ 26 "        // + F .%2Fsrc branch.rs"
+ 27 "        // ="
+ 28 "        // | .%2Fsrc content.rs"
+ 29 "        // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\""
+ 30 "        // + 1 \"\""
+ 31 ""
- 28
- 29
- 30
- 31
- 32
- 33
- 34
- 35
- 36
- 37
- 38
- 39
- 40
- 41
+ 35 "            result.push(match c_m {"
+ 36 "                ContainerModification::CreateDirectory(p, n) => {"
+ 37 "                    format!("
+ 38 "                        \"+ D {} {}\","
+ 39 "                        urlencoding::encode(p).to_string(),"
+ 40 "                        urlencoding::encode(n).to_string()"
+ 41 "                    )"
- 43
+ 43 "                ContainerModification::DeleteDirectory(p, n) => {"
+ 44 "                    format!("
+ 45 "                        \"- D {} {}\","
+ 46 "                        urlencoding::encode(p).to_string(),"
+ 47 "                        urlencoding::encode(n).to_string()"
+ 48 "                    )"
+ 49 "                }"
+ 50 "                ContainerModification::CreateFile(p, n) => {"
+ 51 "                    format!("
+ 52 "                        \"+ F {} {}\","
+ 53 "                        urlencoding::encode(p).to_string(),"
+ 54 "                        urlencoding::encode(n).to_string()"
+ 55 "                    )"
+ 56 "                }"
+ 57 "                ContainerModification::DeleteFile(p, n) => {"
+ 58 "                    format!("
+ 59 "                        \"- F {} {}\","
+ 60 "                        urlencoding::encode(p).to_string(),"
+ 61 "                        urlencoding::encode(n).to_string()"
+ 62 "                    )"
+ 63 "                }"
+ 64 "            });"
- 52
+ 73 "                Modification::Delete(path, name, _) => (path.clone(), name.clone()),"
- 57
- 58
+ 78 "        let mut keys = map"
+ 79 "            .iter()"
+ 80 "            .map(|x| x.0.clone())"
+ 81 "            .collect::<Vec<(String, String)>>();"
+ 82 ""
+ 83 "        // map.sort_by_key(|x| x.0.clone());"
+ 84 "        keys.sort();"
+ 85 ""
+ 86 "        for (path, name) in keys {"
+ 87 "            let modifications = map.get(&(path.clone(), name.clone())).unwrap();"
+ 88 "            result.push(format!("
+ 89 "                \"| {} {}\","
+ 90 "                urlencoding::encode(&path).to_string(),"
+ 91 "                urlencoding::encode(&name).to_string()"
+ 92 "            ));"
- 60
- 61
- 62
- 63
- 64
- 65
+ 94 "                result.push(match m {"
+ 95 "                    Modification::Create(_, _, line, content) => format!(\"+ {line} {content:?}\"),"
+ 96 "                    Modification::Delete(_, _, line) => format!(\"- {line}\"),"
+ 97 "                })"
- 72
+ 104 "    pub fn deserialise_changes(s: String) -> Option<Change> {"
+ 105 "        // + D . src"
+ 106 "        // + F .%2Fsrc utils.rs"
+ 107 "        // + F .%2Fsrc branch.rs"
+ 108 "        // ="
+ 109 "        // | .%2Fsrc content.rs"
+ 110 "        // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\""
+ 111 "        // + 1 \"\""
+ 112 ""
+ 113 "        let lines = s"
+ 114 "            .split(\"\\n\")"
+ 115 "            .map(|x| x.to_string())"
+ 116 "            .collect::<Vec<String>>();"
+ 117 ""
+ 118 "        let mut result = Change::empty();"
+ 119 "        let mut container_section = true;"
+ 120 ""
+ 121 "        let mut previous_file = None;"
+ 122 "        for l in lines {"
+ 123 "            if container_section && (l == \"=\") {"
+ 124 "                container_section = false;"
+ 125 "                continue;"
+ 126 "            }"
+ 127 "            let content = l.split(\" \").collect::<Vec<&str>>();"
+ 128 ""
+ 129 "            if container_section {"
+ 130 "                let [species, container, parent, name] = *content.as_slice() else {"
+ 131 "                    return None;"
+ 132 "                };"
+ 133 ""
+ 134 "                result"
+ 135 "                    .container_modifications"
+ 136 "                    .push(match (species, container) {"
+ 137 "                        (\"+\", \"D\") => ContainerModification::CreateDirectory("
+ 138 "                            urlencoding::decode(parent).unwrap().to_string(),"
+ 139 "                            urlencoding::decode(name).unwrap().to_string(),"
+ 140 "                        ),"
+ 141 "                        (\"-\", \"D\") => ContainerModification::DeleteDirectory("
+ 142 "                            urlencoding::decode(parent).unwrap().to_string(),"
+ 143 "                            urlencoding::decode(name).unwrap().to_string(),"
+ 144 "                        ),"
+ 145 "                        (\"+\", \"F\") => ContainerModification::CreateFile("
+ 146 "                            urlencoding::decode(parent).unwrap().to_string(),"
+ 147 "                            urlencoding::decode(name).unwrap().to_string(),"
+ 148 "                        ),"
+ 149 "                        (\"-\", \"F\") => ContainerModification::DeleteFile("
+ 150 "                            urlencoding::decode(parent).unwrap().to_string(),"
+ 151 "                            urlencoding::decode(name).unwrap().to_string(),"
+ 152 "                        ),"
+ 153 "                        _ => {"
+ 154 "                            println!(\"invalid c_mod\");"
+ 155 "                            return None;"
+ 156 "                        }"
+ 157 "                    });"
+ 158 "            } else {"
+ 159 "                if content[0] == \"|\" {"
+ 160 "                    // | .%2Fsrc content.rs"
+ 161 "                    let [_, parent, name] = *content.as_slice() else {"
+ 162 "                        println!(\"invalid file header\");"
+ 163 "                        return None;"
+ 164 "                    };"
+ 165 ""
+ 166 "                    previous_file = Some((parent.to_string(), name.to_string()));"
+ 167 "                } else {"
+ 168 "                    // + 0 \"use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};\""
+ 169 "                    if content.len() < 2 {"
+ 170 "                        println!(\"invalid change line\");"
+ 171 "                        return None;"
+ 172 "                    }"
+ 173 ""
+ 174 "                    let species = content[0];"
+ 175 "                    let line = match content[1].parse::<usize>() {"
+ 176 "                        Ok(i) => i,"
+ 177 "                        _ => {"
+ 178 "                            println!(\"invalid line index\");"
+ 179 "                            return None;"
+ 180 "                        }"
+ 181 "                    };"
+ 182 ""
+ 183 "                    if let Some((p, _)) = &previous_file {"
+ 184 "                        if (p == \"+\") && (content.len() < 3) {"
+ 185 "                            return None;"
+ 186 "                        }"
+ 187 "                    }"
+ 188 ""
+ 189 "                    match &previous_file {"
+ 190 "                        Some((p, n)) => match species {"
+ 191 "                            \"+\" => {"
+ 192 "                                let s = unescape::unescape(&content[2..].join(\" \")).unwrap();"
+ 193 ""
+ 194 "                                result.modifications.push(Modification::Create("
+ 195 "                                    urlencoding::decode(p).unwrap().to_string(),"
+ 196 "                                    urlencoding::decode(n).unwrap().to_string(),"
+ 197 "                                    line,"
+ 198 "                                    s[1..s.len() - 1].to_string(),"
+ 199 "                                ));"
+ 200 "                            }"
+ 201 "                            \"-\" => result.modifications.push(Modification::Delete("
+ 202 "                                urlencoding::decode(p).unwrap().to_string(),"
+ 203 "                                urlencoding::decode(n).unwrap().to_string(),"
+ 204 "                                line,"
+ 205 "                            )),"
+ 206 "                            _ => {"
+ 207 "                                return None;"
+ 208 "                            }"
+ 209 "                        },"
+ 210 "                        None => {"
+ 211 "                            return None;"
+ 212 "                        }"
+ 213 "                    }"
+ 214 "                }"
+ 215 "            }"
+ 216 "        }"
+ 217 ""
+ 218 "        Some(result)"
+ 219 "    }"
+ 220 ""
+ 221 "    pub fn empty() -> Change {"
+ 222 "        Change {"
+ 223 "            container_modifications: vec![],"
+ 224 "            modifications: vec![],"
+ 225 "        }"
+ 226 "    }"
+ 227 ""
+ 228 "    pub fn get_change("
+ 229 "        path: String,"
+ 230 "        upstream_file: &File,"
+ 231 "        current_file: &File,"
+ 232 "    ) -> Vec<Modification> {"
- 91
- 92
- 93
- 94
- 95
- 96
- 97
- 98
- 99
- 100
- 101
- 102
- 103
- 104
- 105
- 106
- 107
- 108
- 109
- 110
- 111
- 112
- 113
+ 251 "        for change in diff.iter_all_changes().filter_map(|c| match c.tag() {"
+ 252 "            ChangeTag::Equal => None,"
+ 253 "            _ => Some(c),"
+ 254 "        }) {"
+ 255 "            result.push(match change.tag() {"
+ 256 "                ChangeTag::Delete => Modification::Delete("
+ 257 "                    path.clone(),"
+ 258 "                    current_file.name.clone(),"
+ 259 "                    change.old_index().unwrap(),"
+ 260 "                ),"
+ 261 "                ChangeTag::Insert => Modification::Create("
+ 262 "                    path.clone(),"
+ 263 "                    current_file.name.clone(),"
+ 264 "                    change.new_index().unwrap(),"
+ 265 "                    change.to_string().strip_suffix(\"\\n\").unwrap().to_string(),"
+ 266 "                ),"
+ 267 "                _ => panic!(),"
+ 268 "            })"
- 131
+ 286 "                }"
- 148
+ 303 "                }"
- 158
- 159
+ 313 "        let deleted = upstream_set"
+ 314 "            .difference(&current_set)"
+ 315 "            .map(|(n, t)| (n.to_string(), *t))"
+ 316 "            .collect::<Vec<(String, bool)>>();"
+ 317 "        let created = current_set"
+ 318 "            .difference(&upstream_set)"
+ 319 "            .map(|(n, t)| (n.to_string(), *t))"
+ 320 "            .collect::<Vec<(String, bool)>>();"
- 168
+ 329 "                container_modifications.push(ContainerModification::DeleteFile("
+ 330 "                    path.to_string_lossy().to_string(),"
+ 331 "                    dir_name,"
+ 332 "                ));"
- 170
+ 334 "                container_modifications.push(ContainerModification::DeleteDirectory("
+ 335 "                    path.to_string_lossy().to_string(),"
+ 336 "                    dir_name.clone(),"
+ 337 "                ));"
- 174
- 175
+ 341 "                        Content::Directory(deleted_d) => deleted_d,"
+ 342 "                        _ => panic!(),"
- 178
+ 345 "                    &path.join(dir_name.clone()),"
- 191
+ 358 "                container_modifications.push(ContainerModification::CreateFile("
+ 359 "                    path.to_string_lossy().to_string(),"
+ 360 "                    dir_name.clone(),"
+ 361 "                ));"
- 193
- 194
- 195
- 196
- 197
- 198
- 199
- 200
- 201
- 202
+ 363 "                modifications.append(&mut Change::get_change("
+ 364 "                    path.to_string_lossy().to_string(),"
+ 365 "                    &File::new(),"
+ 366 "                    match current_map.get(&(dir_name, true)).unwrap() {"
+ 367 "                        Content::File(f) => f,"
+ 368 "                        _ => panic!(),"
+ 369 "                    },"
+ 370 "                ))"
- 205
+ 373 "                container_modifications.push(ContainerModification::CreateDirectory("
+ 374 "                    path.to_string_lossy().to_string(),"
+ 375 "                    dir_name.clone(),"
+ 376 "                ));"
- 211
+ 382 "                        _ => panic!(),"
- 213
+ 384 "                    &path.join(dir_name.clone()),"
- 227
- 228
- 229
- 230
- 231
+ 398 "                    let upstream_directory ="
+ 399 "                        match upstream_map.get(&(directory.name.clone(), false)) {"
+ 400 "                            Some(u) => match u {"
+ 401 "                                Content::Directory(u_d) => u_d,"
+ 402 "                                _ => panic!(),"
+ 403 "                            },"
+ 404 "                            _ => {"
+ 405 "                                continue;"
- 233
- 234
- 235
+ 407 "                        };"
- 238
- 239
- 240
- 241
- 242
+ 410 "                    let mut changes = Change::get_change_all(upstream_directory, directory, &p);"
- 245
+ 413 "                }"
- 247
- 248
+ 415 "                    let upstream_file = match upstream_map.get(&(f.name.clone(), true)) {"
- 251
+ 418 "                            _ => panic!(),"
- 253
+ 420 "                        None => {"
+ 421 "                            continue;"
+ 422 "                        }"
- 256
- 257
- 258
- 259
- 260
- 261
- 262
+ 425 "                    modifications.append(&mut Change::get_change("
+ 426 "                        path.to_string_lossy().to_string(),"
+ 427 "                        &upstream_file,"
+ 428 "                        &f,"
+ 429 "                    ));"
- 269
+ 436 "            modifications,"
- 273
+ 440 "    pub fn as_map("
+ 441 "        &self,"
+ 442 "    ) -> ("
+ 443 "        HashMap<String, HashSet<ContainerModification>>,"
+ 444 "        HashMap<String, HashMap<String, Vec<Modification>>>,"
+ 445 "    ) {"
- 280
- 281
- 282
- 283
+ 452 "                ContainerModification::CreateDirectory(path, _)"
+ 453 "                | ContainerModification::DeleteDirectory(path, _)"
+ 454 "                | ContainerModification::CreateFile(path, _)"
+ 455 "                | ContainerModification::DeleteFile(path, _) => path.clone(),"
- 286
+ 458 "            c_mod_map"
+ 459 "                .entry(path)"
+ 460 "                .or_insert(HashSet::new())"
+ 461 "                .insert(container_modification.clone());"
- 293
+ 468 "                Modification::Delete(path, name, _) => (path.clone(), name.clone()),"
- 298
- 309
+ 483 "            container_modifications: self"
+ 484 "                .container_modifications"
- 312
- 313
- 314
- 315
- 316
- 317
+ 487 "                .filter(|c_mod| match c_mod {"
+ 488 "                    ContainerModification::CreateFile(p, n)"
+ 489 "                    | ContainerModification::DeleteFile(p, n) => filter"
+ 490 "                        .files"
+ 491 "                        .contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),"
+ 492 "                    ContainerModification::CreateDirectory(p, n)"
+ 493 "                    | ContainerModification::DeleteDirectory(p, n) => filter"
+ 494 "                        .directories"
+ 495 "                        .contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),"
+ 496 "                })"
- 319
+ 498 "            modifications: self"
+ 499 "                .modifications"
- 322
- 323
- 324
- 325
+ 502 "                .filter(|m| {"
+ 503 "                    filter.files.contains(&match m {"
+ 504 "                        Modification::Create(p, n, _, _) | Modification::Delete(p, n, _) => {"
+ 505 "                            PathBuf::from(p).join(n).to_string_lossy().to_string()"
- 327
- 328
- 329
+ 507 "                    })"
+ 508 "                })"
+ 509 "                .collect(),"
- 334
+ 514 "#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq, PartialOrd, Ord)]"
- 340
- 341
+ 520 "        usize,  // line"
+ 521 "        String, // text"
- 346
- 347
+ 526 "        usize,  // line"
+ 527 "    ),"
- 350
+ 530 "#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq, PartialOrd, Ord)]"
- 353
+ 533 ""
- 357
+ 537 "        String, // name"
- 361
+ 541 "        String, // name"
- 366
+ 546 "        String, // name"
- 370
- 371
+ 550 "        String, // name"
+ 551 "    ),"
+ 553 ""
| .%2Fsrc commit.rs
- 4
+ 4 "use crate::{"
+ 5 "    change::Change,"
+ 6 "    content_set::{ContentSet, TrackingSet},"
+ 7 "    state::State,"
+ 8 "    utils,"
+ 9 "};"
+ 11 "#[derive(Debug)]"
- 13
+ 19 "    pub author: String,"
- 17
- 18
+ 23 "        format!("
+ 24 "            \"= {} {} {:?} {:?} {}\\n{}\","
+ 25 "            self.id"
+ 26 "                .map_or(\"LOCAL\".to_string(), |i| format!(\"{:06x}\", i).clone()),"
+ 34 ""
+ 35 "    pub fn deserialise(s: String) -> Option<Commit> {"
+ 36 "        // = LOCAL 1747682692319414000 \"initial%20commit\" \"\" no_one"
+ 37 ""
+ 38 "        let lines = s.split(\"\\n\").collect::<Vec<&str>>();"
+ 39 "        if lines.len() < 2 {"
+ 40 "            // return None;"
+ 41 "        }"
+ 42 ""
+ 43 "        let metadata = lines[0].split(\" \").collect::<Vec<&str>>();"
+ 44 "        if metadata.len() != 6 {"
+ 45 "            // return None;"
+ 46 "        }"
+ 47 ""
+ 48 "        let [_, status, time, message, description, author] = *metadata.as_slice() else {"
+ 49 "            return None;"
+ 50 "        };"
+ 51 ""
+ 52 "        Some(Commit {"
+ 53 "            id: status.parse::<u32>().map_or(None, |t| Some(t)),"
+ 54 "            message: urlencoding::decode(&message[1..message.len() - 1].to_string())"
+ 55 "                .unwrap()"
+ 56 "                .to_string(),"
+ 57 "            description: urlencoding::decode(&description[1..description.len() - 1].to_string())"
+ 58 "                .unwrap()"
+ 59 "                .to_string(),"
+ 60 "            change: Change::deserialise_changes(lines[1..].join(\"\\n\")).unwrap_or(Change::empty()),"
+ 61 "            timestamp: time.parse::<u128>().unwrap_or(0),"
+ 62 "            author: author.to_string(),"
+ 63 "        })"
+ 64 "    }"
- 27
- 30
+ 68 "    let f = args"
+ 69 "        .get_many::<PathBuf>(\"FILE\")"
+ 70 "        .unwrap()"
+ 71 "        .map(|x| x.clone())"
+ 72 "        .collect::<Vec<PathBuf>>();"
- 34
- 35
- 36
- 37
- 38
+ 76 "            .unwrap()"
+ 77 "            .split(\"\\n\")"
+ 78 "            .filter(|x| !x.is_empty())"
+ 79 "            .map(|x| x.to_string())"
+ 80 "            .collect::<Vec<String>>(),"
- 42
+ 84 "        result.insert(format!("
+ 85 "            \"{}{}\","
+ 86 "            p.to_string_lossy().to_string(),"
+ 87 "            if !p.to_string_lossy().to_string().ends_with(\"/\") && p.is_dir() {"
+ 88 "                \"/\""
+ 89 "            } else {"
+ 90 "                \"\""
+ 91 "            }"
+ 92 "        ));"
- 44
- 45
- 46
- 47
+ 94 "    let _ = fs::write("
+ 95 "        \"./.relic/tracked\","
+ 96 "        result.drain().collect::<Vec<String>>().join(\"\\n\"),"
- 51
- 52
+ 100 "pub fn remove(s: &mut State, args: &ArgMatches) {"
+ 101 "    let f = args"
+ 102 "        .get_many::<PathBuf>(\"FILE\")"
+ 103 "        .unwrap()"
+ 104 "        .map(|x| x.clone())"
+ 105 "        .collect::<Vec<PathBuf>>();"
- 54
+ 107 "    let result: HashSet<String> = HashSet::from_iter("
- 56
- 57
- 58
- 59
- 60
+ 109 "            .unwrap()"
+ 110 "            .split(\"\\n\")"
+ 111 "            .filter(|x| !x.is_empty())"
+ 112 "            .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string())"
+ 113 "            .collect::<Vec<String>>(),"
- 62
- 63
- 64
+ 115 ""
+ 116 "    // initialise removed_content"
+ 117 "    let mut removed_content = ContentSet {"
+ 118 "        files: HashSet::from_iter("
+ 119 "            f.iter()"
+ 120 "                .filter(|x| !x.is_dir())"
+ 121 "                .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string()),"
+ 122 "        ),"
+ 123 "        directories: HashSet::from_iter("
+ 124 "            f.iter()"
+ 125 "                .filter(|x| x.is_dir())"
+ 126 "                .map(|x| PathBuf::from(\".\").join(x).to_string_lossy().to_string()),"
+ 127 "        ),"
- 66
- 67
- 68
- 69
+ 129 "    .initialise(&mut s.current);"
+ 130 ""
+ 131 "    let mut to_subtract: HashSet<String> = HashSet::from_iter("
+ 132 "        removed_content"
+ 133 "            .directories"
+ 134 "            .drain()"
+ 135 "            .collect::<Vec<String>>()"
+ 136 "            .into_iter()"
+ 137 "            .map(|x| format!(\"{x}/\"))"
+ 138 "            .collect::<Vec<String>>(),"
+ 140 "    to_subtract = to_subtract"
+ 141 "        .union(&HashSet::from_iter(removed_content.files.drain()))"
+ 142 "        .map(|x| x.to_string())"
+ 143 "        .collect::<HashSet<String>>();"
+ 144 ""
+ 145 "    // set operations"
+ 146 "    // right join"
+ 147 "    // result - removed_content"
+ 148 ""
+ 149 "    let _ = fs::write("
+ 150 "        \"./.relic/tracked\","
+ 151 "        result"
+ 152 "            .difference(&to_subtract)"
+ 153 "            .map(|x| x[2..].to_string())"
+ 154 "            .collect::<Vec<String>>()"
+ 155 "            .join(\"\\n\"),"
+ 156 "    );"
- 78
+ 164 "    r#\"= {commit id} {unix timestamp of commit} {message} {description} {author}"
- 90
+ 176 "    let description = args"
+ 177 "        .get_one::<String>(\"description\")"
+ 178 "        .map_or(\"\".to_string(), String::clone);"
- 98
+ 186 "        author: \"no_one\".to_string(),"
- 106
- 107
- 108
- 109
- 110
+ 194 "pub fn push(_: &mut State, _: &ArgMatches) {}"
- 112
+ 196 "pub fn pull(_: &mut State, _: &ArgMatches) {}"
- 114
+ 198 "pub fn fetch(_: &mut State, _: &ArgMatches) {}"
- 116
+ 200 "pub fn cherry(_: &mut State, _: &ArgMatches) {}"
- 118
- 119
- 120
+ 202 "pub fn rollback(_: &mut State, _: &ArgMatches) {}"
- 122
- 123
+ 204 "pub fn pending(_: &mut State, args: &ArgMatches) {"
+ 205 "    if let Some(commit_number) = args"
+ 206 "        .get_one::<String>(\"COMMIT\")"
+ 207 "        .map_or(None, |x| x.parse::<i32>().map_or(None, |x| Some(x)))"
+ 208 "    {"
+ 209 "        println!(\"selected commit : {commit_number}\");"
+ 210 "    } else {"
+ 211 "        println!(\"none selected\");"
+ 212 "    }"
| .%2Fsrc content.rs
- 0
+ 0 "use std::{"
+ 1 "    collections::{HashMap, HashSet},"
+ 2 "    fs,"
+ 3 "    path::PathBuf,"
+ 4 "    sync::{Arc, Mutex},"
+ 5 "};"
- 4
+ 9 "use crate::{"
+ 10 "    change::{Change, ContainerModification, Modification},"
+ 11 "    error::RelicError,"
+ 12 "};"
- 28
+ 36 "            content: \"\".to_string(),"
- 34
- 35
- 36
- 37
- 38
- 39
+ 42 "            Ok(content) => Ok(File {"
+ 43 "                name: name,"
+ 44 "                content: content,"
+ 45 "            }),"
- 63
+ 69 ""
- 67
+ 73 "        let mut lines = self"
+ 74 "            .content"
+ 75 "            .split(\"\\n\")"
+ 76 "            .map(|x| x.to_string())"
+ 77 "            .collect::<Vec<String>>();"
- 72
+ 82 "            Modification::Delete(_, _, l) => -(*l as i128),"
- 80
+ 90 "                }"
- 96
+ 106 "    pub content: Vec<Content>,"
- 104
+ 114 "            content: vec![],"
- 111
+ 121 "            _ => None,"
- 129
- 130
- 131
+ 139 "                if let ContentMutRef::Directory(d) = current {"
+ 140 "                    // somehow denote that the parent does not yet exist,"
+ 141 "                    // possibly recursively create directories where needed"
- 133
- 134
- 135
- 136
+ 143 "                    // TODO : optimise the match arms"
+ 144 "                    let mut c_mod_map_lock = c_mod_map.lock().unwrap();"
+ 145 "                    if let Some(c_modifications) ="
+ 146 "                        c_mod_map_lock.get(&d.path.to_string_lossy().to_string())"
+ 147 "                    {"
+ 148 "                        let c_clone = c_modifications.clone();"
- 138
- 139
+ 150 "                        // deals with additions"
+ 151 "                        d.content.append(&mut recursive_birth("
+ 152 "                            &PathBuf::from(d.path.clone()),"
+ 153 "                            &mut c_mod_map_lock,"
+ 154 "                        ));"
- 141
- 142
- 143
- 144
- 145
- 146
+ 156 "                        let mut deleted_containers = HashSet::new();"
+ 157 "                        // deals with subtractions"
+ 158 "                        for c_mod in &c_clone {"
+ 159 "                            match c_mod {"
+ 160 "                                ContainerModification::DeleteDirectory(_, n) => {"
+ 161 "                                    deleted_containers.insert(n);"
+ 162 "                                }"
+ 163 "                                ContainerModification::DeleteFile(_, n) => {"
+ 164 "                                    deleted_containers.insert(n);"
+ 165 "                                }"
+ 166 "                                _ => {}"
- 148
- 149
- 150
- 151
- 153
- 155
- 156
- 157
- 158
- 159
+ 170 "                        d.content = d"
+ 171 "                            .content"
+ 172 "                            .iter()"
+ 173 "                            .filter(|x| {"
+ 174 "                                !deleted_containers.contains(match x {"
- 161
+ 176 "                                    Content::Directory(d) => &d.name,"
- 163
- 164
- 165
+ 178 "                            })"
+ 179 "                            .map(|x| x.clone())"
+ 180 "                            .collect::<Vec<Content>>();"
+ 181 "                    }"
- 167
- 168
+ 183 "            },"
+ 184 "            &Directory::new(),"
+ 185 "        );"
- 173
- 174
- 175
- 176
- 177
+ 190 "                if let ContentMutRef::File(f) = current {"
+ 191 "                    if let Some(modifications) = mod_map"
+ 192 "                        .get(&path.to_string_lossy().to_string())"
+ 193 "                        .map_or(None, |x| x.get(&f.name))"
+ 194 "                    {"
+ 195 "                        f.apply_changes(modifications);"
+ 196 "                    }"
- 179
- 180
+ 198 "            },"
+ 199 "            &self.clone(),"
+ 200 "        );"
- 182
+ 202 "        pub fn recursive_birth("
+ 203 "            parent_directory: &PathBuf,"
+ 204 "            c_mod_map: &mut HashMap<String, HashSet<ContainerModification>>,"
+ 205 "        ) -> Vec<Content> {"
- 185
+ 208 "            if let Some(c_modifications) ="
+ 209 "                c_mod_map.get_mut(&parent_directory.to_string_lossy().to_string())"
+ 210 "            {"
- 192
+ 217 "                        ContainerModification::CreateDirectory(_, n) => {"
- 198
- 199
+ 223 "                                    c_mod_map,"
+ 224 "                                ),"
- 201
- 202
+ 226 "                        }"
+ 227 "                        ContainerModification::CreateFile(_, n) => {"
- 205
+ 230 "                                content: \"\".to_string(),"
- 207
+ 232 "                        }"
- 218
- 219
+ 243 "        // parent path, parent directory, current content"
+ 244 "        F: Fn(&PathBuf, &Directory, ContentMutRef),"
- 228
+ 253 "                }"
| .%2Fsrc content_set.rs
- 0
+ 0 "use std::{"
+ 1 "    collections::HashSet,"
+ 2 "    path::PathBuf,"
+ 3 "    sync::{Arc, Mutex},"
+ 4 "};"
- 4
+ 8 "use crate::content::{ContentMutRef, Directory};"
- 9
+ 13 "    pub files: HashSet<String>,"
- 15
+ 19 "            files: HashSet::new(),"
- 20
- 21
- 33
+ 35 "            files: HashSet::new(),"
- 44
+ 46 "            // doesnt take into account cases like"
- 70
+ 72 "        for d in content"
+ 73 "            .split(\"\\n\")"
+ 74 "            .map(|x| x.to_string())"
+ 75 "            .collect::<Vec<String>>()"
+ 76 "        {"
- 85
- 86
+ 91 "        d.traverse("
+ 92 "            PathBuf::from(\".\"),"
+ 93 "            &|path, _, current| {"
+ 94 "                // println!(\"traversing at : {path:?}\");"
- 88
+ 96 "                let mut tracked_unlock = tracked_mutex.lock().unwrap();"
- 90
- 91
- 92
- 93
- 94
- 95
+ 98 "                match current {"
+ 99 "                    ContentMutRef::Directory(d) => {"
+ 100 "                        // if parent in set"
+ 101 "                        // add to content set"
+ 102 "                        if tracked_unlock"
+ 103 "                            .directories"
+ 104 "                            .contains(&d.path.parent().unwrap().to_string_lossy().to_string())"
+ 105 "                        {"
+ 106 "                            tracked_unlock"
+ 107 "                                .directories"
+ 108 "                                .insert(d.path.to_string_lossy().to_string());"
+ 109 "                        }"
- 97
- 98
- 99
- 100
+ 111 "                    ContentMutRef::File(f) => {"
+ 112 "                        if tracked_unlock"
+ 113 "                            .directories"
+ 114 "                            .contains(&path.to_string_lossy().to_string())"
+ 115 "                        {"
+ 116 "                            tracked_unlock"
+ 117 "                                .files"
+ 118 "                                .insert(path.join(&f.name).to_string_lossy().to_string());"
+ 119 "                        }"
- 103
- 104
+ 122 "            },"
+ 123 "            &d.clone(),"
+ 124 "        );"
+ 131 ""
| .%2Fsrc error.rs
- 6
+ 6 "    ConfigurationIncorrect,"
+ 8 ""
| .%2Fsrc main.rs
+ 0 "use std::collections::HashMap;"
- 1
- 2
+ 2 "use std::path::PathBuf;"
+ 4 "mod content_set;"
- 5
- 9
- 10
+ 10 "mod commit;"
+ 11 "mod relic;"
+ 14 "mod change;"
- 15
- 18
- 19
- 20
- 21
- 22
- 23
+ 18 "use commit::{pending, remove};"
+ 19 "use content_set::TrackingSet;"
- 26
- 28
+ 23 "use crate::commit::{add, cherry, commit, fetch, pull, push, rollback};"
+ 24 "use crate::stash::{restore, stash};"
- 49
- 50
- 51
+ 45 "pub fn init(_: &mut State, _: &ArgMatches) {}"
- 54
- 55
- 56
- 57
- 58
- 59
- 60
- 61
- 62
- 63
- 64
- 65
- 66
- 67
- 68
- 69
- 70
- 71
- 72
- 73
- 74
- 75
- 76
- 77
- 78
- 79
- 80
- 81
- 82
- 83
- 84
- 85
- 86
- 87
- 88
- 89
- 90
- 91
- 92
- 93
- 94
- 95
- 96
- 97
- 98
- 99
- 100
- 101
- 102
- 103
- 104
- 105
- 106
- 107
- 108
- 109
- 110
- 111
- 112
- 113
- 114
- 115
- 116
- 117
- 118
- 119
- 120
- 121
- 122
- 123
- 124
- 125
+ 48 "    let mut command_handler = Command::new(\"relic\")"
+ 49 "        .about("
+ 50 "            r#\"This is the Relic Version Control System."
- 127
- 128
- 129
- 130
- 131
- 139
+ 59 "pushing and pulling, are implemented.\"#,"
+ 60 "        )"
- 141
- 142
- 143
- 144
- 145
+ 62 "        .arg_required_else_help(true);"
- 147
+ 64 "    type CommandType = fn(&mut State, &ArgMatches);"
+ 65 "    let mut commands: HashMap<String, CommandType> = HashMap::new();"
+ 66 "    for (f, c) in HashMap::<CommandType, clap::Command>::from_iter::<"
+ 67 "        Vec<(CommandType, clap::Command)>,"
+ 68 "    >(vec!["
+ 69 "        ("
+ 70 "            init,"
+ 71 "            Command::new(\"init\").about(\"Initialises a Relic repository in the current directory.\"),"
+ 72 "        ),"
+ 73 "        ("
+ 74 "            add,"
- 153
- 154
- 155
- 156
- 157
+ 80 "                        .required(true)"
+ 81 "                        .value_parser(value_parser!(PathBuf)),"
+ 82 "                ),"
+ 83 "        ),"
+ 84 "        ("
+ 85 "            remove,"
- 163
- 164
- 165
- 166
- 167
+ 91 "                        .required(true)"
+ 92 "                        .value_parser(value_parser!(PathBuf)),"
+ 93 "                ),"
+ 94 "        ),"
+ 95 "        ("
+ 96 "            commit,"
- 172
- 173
- 174
- 175
- 176
- 177
- 178
- 179
- 180
- 181
- 182
- 183
- 184
- 185
- 186
- 187
- 188
- 189
- 190
+ 101 "                .arg(arg!(-d --description <DESCRIPTION> \"Commit description\")),"
+ 102 "        ),"
+ 103 "        ("
+ 104 "            push,"
+ 105 "            Command::new(\"push\").about(\"Pushes local changes to remote.\"),"
+ 106 "        ),"
+ 107 "        ("
+ 108 "            pull,"
+ 109 "            Command::new(\"pull\").about(\"Pull changes from remote to local.\"),"
+ 110 "        ),"
+ 111 "        ("
+ 112 "            fetch,"
+ 113 "            Command::new(\"fetch\").about(\"Check remote for new changes.\"),"
+ 114 "        ),"
+ 115 "        (branch, Command::new(\"branch\").about(\"\")),"
+ 116 "        ("
+ 117 "            stash,"
- 198
- 199
- 200
- 201
- 202
- 203
- 204
- 205
- 206
- 207
- 208
- 209
- 210
- 211
- 212
- 213
- 214
- 215
- 216
- 217
- 218
- 219
- 220
- 221
+ 125 "                .about(\"\"),"
+ 126 "        ),"
+ 127 "        ("
+ 128 "            restore,"
+ 129 "            Command::new(\"restore\"), // unimplemented"
+ 130 "        ),"
+ 131 "        ("
+ 132 "            rollback,"
+ 133 "            Command::new(\"rollback\").about(\"Discard all current changes. Rolls back to most recent commit (or pending commit).\"),"
+ 134 "        ),"
+ 135 "        ("
+ 136 "            cherry,"
+ 137 "            Command::new(\"cherry\").about(\"Go to specific commit.\"),"
+ 138 "        ),"
+ 139 "        ("
+ 140 "            |s, _| {"
+ 141 "                println!(\"{}\", generate_tree(&s.current));"
+ 142 "            },"
+ 143 "            Command::new(\"tree\").about(\"Generate content tree of current directory.\"),"
+ 144 "        ),"
+ 145 "        ("
+ 146 "            |s, _| {"
+ 147 "                println!("
+ 148 "                    \"{}\","
+ 149 "                    s.get_changes()"
+ 150 "                        .filter_changes(&s.track_set.initialise(&mut s.current))"
+ 151 "                        .serialise_changes()"
+ 152 "                );"
+ 153 "            },"
+ 154 "            Command::new(\"staging\").about(\"View all staging changes.\"),"
+ 155 "        ),"
+ 156 "        ("
+ 157 "            pending,"
+ 158 "            Command::new(\"pending\").about(\"View all pending commits.\")"
+ 159 "                .arg(arg!([COMMIT]... \"Commit number.\"))"
+ 160 "        ),"
+ 161 "        ("
+ 162 "            |s, _| {"
+ 163 "                s.upstream.apply_changes(s.get_changes());"
+ 164 "            },"
+ 165 "            Command::new(\"test\").about(\"test\"),"
+ 166 "        ),"
+ 167 "        ("
+ 168 "            |_, _| {"
+ 169 "                println!(\".................................................................................................\\n.................................................................................................\\n.................................................................................................\\n.....-----:......:-:.......:--........:-:.......:------::......:----:....:-:....:---::...:::.....\\n..:-+#%%%%+=:...:+#=:......=#+:......-*#+:......=%%%%%%#*=:..:=*%%%%*-:.-+#=..-+#%%%#+-.:=#*-....\\n.:-%%#+=+#%%+:..-*%+:.....:=%*:.....:+%@#-.....:+%%++++#%%*-.=#%#+=#@#-.-#%=::+%%+=+%%+::+%#-....\\n.-#%=:...:=%%=..-*%+:.....:=%*:.....=#%#%*:....:+%*:...:=%%=-+#+:..-%%=.-*%=:-*#=..:=%#-:+%#-....\\n:+@*:.....:+%#-.-#%+-.....:+%*:....:+%*=#%-....:+%*-....-#%+:::....-%%=:-#%=:.::...:=%#-:+%#-....\\n-#@=:.....:=%%-.-#%+-------+%*:....-##=:+%+:...:+%*:...:=%%=:.....-+%*-.-*%=:.....:=#%+:.=%#-....\\n-#@=......:=%%=.-#@%%######%@*:...:+%+:.-##-:..:+%#====+#%*-.....-*%*-..-*%=.....:=#%+-.:=%#-....\\n-#@=:......=%%=.-#@#+======*@*:..:=##=::-+@*-..:+@%##%%@#=:.....-#%*-:..-*%=....:+%#=:..:=%#-....\\n-*@=:.....:=%%-.:#@+-.....:+%*:..:+@%*++*#@%=..:+%#=--=@#=:....:=%#-....-*#=....-#%+:....=%*-....\\n:+@*-.....-*%#:.:#@+:.....:=%*:..=#%######%@*-.:+%*:..:*%*-:...:-+=:....:==-....:++-.....-==:....\\n.-#%+-:.:-+%%=..:#%+-.....:=%*:.-*%*::::..=#%=::+%*-...-#%+-.....::......:::.....::.......::.....\\n.:-%%%*++#%%=:..-*%+:......+%+-:=%#=:.....-+@*-:+%*-....=%%=:..:=#+-...:-+*=:...:*#=:....=*+-....\\n...:=*#%%%@#=...:+*=:......=#=::+#+-.:.::.:-**-:=*=:.::::=#*-:..=*+-....:+*=....:**=.....=*+-....\\n....:::::-+%%+:..::........::-::---:::::::::-=-:::::--===+++==-::::......::......::.......::.....\\n..........:-=-.............:----==--:::::----===-:-=++*####++++=-:::----:::::::..................\\n..:........................:---===-----------==+=--=***+==+***++=--=+++++=--===-.................\\n.....::::::................:-====-------------===-:-------=+*****+++===++*+***+=:................\\n...:-==++++=--..::---:.....:-=======--======-:-=-......:..::-==++==-:::---====-::................\\n...:=+**#*+++=--==+++=-....-=--============-::-=-.......::::::-::::::::::.::::......:::..........\\n...::--==+++++++++***+-::.:------====+++===-----:......-===++====---====-:........:-===---::::...\\n......::=+**######**+-::...:--========*#+=---::...:::::=+++*####****####*=-:::.:.:=+#***+++===-:.\\n......::-==+++++==-:::...:...:--===---=*+-::.:......::-=********+++++****+++====---=++*+****+++==\\n..........::::::::::::....:..:.::-==---+*=::...::.:::::-=+*####+=---+###****#**++++=-----=+***+++\\n............::--======-------===-------+#+-:::::::::.::::-----=-:::--++*#######*+++++=-:::-=+*###\\n..........:.-=+++******++++=+***+=-----=*#-------:::::::-----------=+++********++****+=:::::--=++\\n....:.:...::-+***##########*+###+=-----=+#+=====----------=======++*################*+--::.:.::::\\n..::::::..::-+*****#+=======-==---=======++====----=--=======+*###****##*+++++++++===-------:::..\\n:-=====--:::-=+**###+---------------==++++====---------=======+*#####*++=-::-::::::::-=++++=+==--\\n-++*#*++==--==++====---:::--::::::--==========--------======---=++##++=--:::::::::::-=+*****##**+\\n:-=+++++*+=+++**=--::::::::--------======--------------=====--=+****+++==--:::::::--=+**+**######\\n.::-=++++++**#**=--::::::----========------------------------=+####*++++++++=-::-=++***###******+\\n.::-=+**+*##*+=--:::::::--:--========-----=======-----:--------==+**+*+++***+=--+#*******########\\n.:::-=======--:::::::::::-----=========++#*******+=--:::::::::::----==++****+++=+#*****++===+++++\\n.:.:::::::::::::::::::::::----======++############*+--::::::::::::::---=********+******+=--::::::\\n....:.::::---=====---::::------====+*#############**+=--::::::::::::::--=*#************=--::::::.\\n.:::---==++++++**++++=--::--------=+#######*+++##******=======--::::::::-=+*#########*+=======--:\\n:--=+++**************++---::::-----+*######*===+*#***#*+++****++-:::::::::--===++++==*******+++++\\n=++*****######********+--:::::::---=*#####*+=--=+**###+*#******+-::::::::.:::::::::-=+#########**\\n+******###************+--:::::::::--=+***+=-------=++==*#####*+=-:::..:..::::..:::::--=+*#######*\\n******##*==++********+=--:::::::::::---==--::::::------===++++=-:::::...:..:.::..:::-==*+********\\n#######*==+*********+--:::::::.::::::::..:::::--=+**+=---::::::::...::........:::--=+###*********\\n##**+==--=+*****###+=--::::...::.:..:.::..:::-++*****#*=--:::::....:...:..:.:::-=++**############\\n=--------=+########*+=--::::::..:.:.:..:::::-=**#**####**+=-::::::::--:..::.::-=*#*******#*++++++\\n::::::::--+#####******+=-:::.:.............::-==+#####*****+-::::-==++=-::.:::-=*####***+=-------\\n.:.:.::::--+**********#*+-:::............::.:::--==++**#****=--=++*****+-:::.::--=++*#*==--::::::\\n.......:::-=+****#*####*+-::::..............::::::--=+******=--+*#*#****=-:::.::::--==---::::....\\n......::::--=+*######*+==-::.........::.:.....:::::-=+******+===****#***=-:::::.::::::::.........\\n......:.::::--=***+==--:::...............::.....:::-=+**##********##***+=-:::....................\\n....:::.:::::--=---:::::.......................:.::-=+#**####****##***+=--::.:...................\\n................::.::..........................:.::--=*##########***++=-:::......................\");"
+ 170 "            },"
+ 171 "            Command::new(\"qhar\").about(\"??\")"
- 223
- 224
- 225
- 226
- 227
- 228
- 229
- 230
- 231
- 232
- 233
- 234
- 235
- 236
- 237
- 238
- 239
- 240
- 241
- 242
- 243
- 244
- 245
- 246
- 247
- 248
- 249
- 250
- 251
- 252
- 253
- 254
- 255
+ 173 "    ]) {"
+ 174 "        commands.insert(c.get_name().to_string(), f);"
+ 175 "        command_handler = command_handler.subcommand(c);"
+ 176 "    }"
- 264
+ 185 "                }"
- 266
+ 187 "                    unimplemented!(\"Relic Error, command not defined.\");"
- 269
+ 190 "        }"
- 271
+ 192 "            panic!(\"main.rs (main) {e:?} error encountered.\");"
| .%2Fsrc relic.rs
- 0
+ 0 "// use crate::state::State;"
- 2
- 3
- 4
- 5
- 6
- 7
- 8
- 9
- 10
- 11
- 12
- 13
- 14
- 15
- 16
- 17
- 18
- 19
+ 2 "// #[derive(Debug)]"
+ 3 "// pub struct Relic {"
+ 4 "//     // holds"
+ 5 "//     //      history.changes"
+ 6 "//     //      now.changes"
+ 7 "//     //      root"
+ 8 "//     //      upstream"
+ 9 "//     pub upstream: State,"
+ 10 "// }"
+ 11 "// impl Relic {"
+ 12 "//     pub fn empty() -> Relic {"
+ 13 "//         Relic {"
+ 14 "//             upstream: State::empty(),"
+ 15 "//         }"
+ 16 "//     }"
+ 17 "// }"
| .%2Fsrc stash.rs
- 4
- 5
- 6
+ 4 "pub fn stash(_: &mut State, _: &ArgMatches) {}"
- 8
+ 6 "pub fn restore(_: &mut State, _: &ArgMatches) {}"
- 10
| .%2Fsrc state.rs
- 0
+ 1 "use std::{"
+ 2 "    collections::HashSet,"
+ 3 "    fs,"
+ 4 "    path::{Path, PathBuf},"
+ 5 "};"
- 3
+ 7 "use crate::{"
+ 8 "    change::Change,"
+ 9 "    commit::Commit,"
+ 10 "    content::{Content, Directory, File},"
+ 11 "    content_set::{ContentSet, IgnoreSet, TrackingSet},"
+ 12 "    error::RelicError,"
+ 13 "};"
- 11
+ 21 "    pub ignore_set: ContentSet,"
- 21
+ 31 "            ignore_set: ContentSet::empty(),"
- 26
+ 36 "        let ignore_set ="
+ 37 "            IgnoreSet::create(fs::read_to_string(\".relic_ignore\").unwrap_or(\"\".to_string()));"
- 28
- 29
- 30
- 31
+ 39 "        let current ="
+ 40 "            match State::content_at(&path.to_string_lossy().to_string(), &path, &ignore_set)? {"
+ 41 "                Content::Directory(d) => d,"
+ 42 "                _ => return Err(RelicError::ConfigurationIncorrect),"
+ 43 "            };"
- 34
- 35
- 36
- 37
- 38
+ 46 "            Ok(data) => match Directory::deserialise(data) {"
+ 47 "                Some(d) => d,"
+ 48 "                None => return Err(RelicError::ConfigurationIncorrect),"
- 40
+ 50 "            Err(_) => return Err(RelicError::FileCantOpen),"
- 45
+ 55 "            Err(_) => return Err(RelicError::ConfigurationIncorrect),"
- 48
- 49
+ 58 "        track_set.directories = HashSet::from_iter("
+ 59 "            track_set"
+ 60 "                .directories"
+ 61 "                .difference(&ignore_set.directories)"
+ 62 "                .map(|x| {"
+ 63 "                    PathBuf::from(\".\")"
+ 64 "                        .join(PathBuf::from(x))"
+ 65 "                        .to_string_lossy()"
+ 66 "                        .to_string()"
+ 67 "                }),"
+ 68 "        );"
+ 69 "        track_set.files ="
+ 70 "            HashSet::from_iter(track_set.files.difference(&ignore_set.files).map(|x| {"
+ 71 "                PathBuf::from(\".\")"
+ 72 "                    .join(PathBuf::from(x))"
+ 73 "                    .to_string_lossy()"
+ 74 "                    .to_string()"
+ 75 "            }));"
- 56
+ 82 "            ignore_set,"
- 60
+ 86 "    pub fn content_at("
+ 87 "        file_name: &String,"
+ 88 "        root_path: &PathBuf,"
+ 89 "        ignore_set: &ContentSet,"
+ 90 "    ) -> Result<Content, RelicError> {"
- 63
+ 93 "            // let paths = match fs::read_dir(format!(\"./{}\", root_path.clone())) {"
- 93
+ 123 "                            }"
- 106
+ 136 "                            }"
- 115
+ 145 "                }"
- 126
+ 156 "            content: directory_contents,"
- 133
+ 163 ""
- 137
+ 167 "            Err(_) => None,"
- 152
- 153
- 154
- 155
- 157
- 158
- 159
- 160
- 161
- 162
- 163
- 164
- 165
- 166
- 167
- 168
- 169
- 170
- 171
- 172
- 173
- 174
- 181
- 182
- 185
- 186
- 187
- 194
+ 197 "        let _ = fs::write("
+ 198 "            format!(\".relic/pending/{}.diff\", commit.timestamp),"
+ 199 "            commit.serialise(),"
+ 200 "        );"
| .%2Fsrc utils.rs
- 2
- 3
- 4
- 5
- 6
- 7
- 8
- 9
- 10
- 11
- 12
+ 2 "use crate::content::{Content, Directory};"
- 28
+ 18 "                        r.push(format!("
+ 19 "                            \" {} {line}\","
+ 20 "                            if index == length {"
+ 21 "                                if inner_index == 0 {"
+ 22 "                                    \"└\""
+ 23 "                                } else {"
+ 24 "                                    \"\""
+ 25 "                                }"
+ 26 "                            } else {"
+ 27 "                                if inner_index == 0 {"
+ 28 "                                    \"├\""
+ 29 "                                } else {"
+ 30 "                                    \"│\""
+ 31 "                                }"
+ 32 "                            }"
+ 33 "                        ));"
- 33
+ 38 "        }"