= LOCAL 1747660365597294000 "test" "" no_one
+ D . lorem
+ D .%2Florem ipsum
+ F .%2Florem%2Fipsum saturn
+ D .%2Florem%2Fipsum dolor
+ F .%2Florem%2Fipsum%2Fdolor pluto
+ F .%2Florem%2Fipsum temp
+ F .%2Florem mars
+ F .%2Florem earth
+ F .%2Florem pluto
+ F . Cargo.toml
+ F . Cargo.lock
+ D . src
+ F .%2Fsrc commit.rs
+ F .%2Fsrc content_set.rs
+ F .%2Fsrc utils.rs
+ F .%2Fsrc change.rs
+ F .%2Fsrc content.rs
+ F .%2Fsrc branch.rs
+ F .%2Fsrc main.rs
+ F .%2Fsrc state.rs
+ F .%2Fsrc stash.rs
+ F .%2Fsrc relic.rs
+ F .%2Fsrc error.rs
=
| .%2Florem earth
+ 0 "lorem"
+ 1 "ipsum"
+ 2 "do"
+ 3 "sit"
+ 4 "huh"
+ 5 "amet"
+ 6 "asldjflsjfjsdlk"
+ 7 "klasjdflskdf"
| .%2Fsrc change.rs
+ 0 "use std::{collections::{HashMap, HashSet}, path::{Path, PathBuf}};"
+ 1 ""
+ 2 "use serde::{Deserialize, Serialize};"
+ 3 "use similar::{ChangeTag, TextDiff};"
+ 4 ""
+ 5 "use crate::{content::{Content, Directory, File}, content_set::ContentSet};"
+ 6 ""
+ 7 "#[derive(Debug, Serialize, Deserialize, Clone)]"
+ 8 "pub struct Change {"
+ 9 "    pub container_modifications: Vec<ContainerModification>,"
+ 10 "    pub modifications: Vec<Modification>"
+ 11 "}"
+ 12 "impl Change {"
+ 13 "    pub fn serialise_changes(&self) -> String {"
+ 14 "// + D \"lorem/ipsum/dolor\""
+ 15 "// + F \"lorem/ipsum/dolor/earth.txt\" \"earth.txt\""
+ 16 "// - D \"lorem/sit\""
+ 17 "// ="
+ 18 "// | \"lorem/ipsum/dolor/earth.txt\""
+ 19 "// + 3 asdfsdf"
+ 20 "// + 5 sfsdf"
+ 21 "// - 7"
+ 22 "// | \"lorem/ipsum/saturn/txt\""
+ 23 "// + 4 lsdfljs"
+ 24 "        "
+ 25 "        let mut result: Vec<String> = vec![];"
+ 26 ""
+ 27 "        for c_m in &self.container_modifications {"
+ 28 "            result.push("
+ 29 "                match c_m {"
+ 30 "                    ContainerModification::CreateDirectory(p, n) => {"
+ 31 "                        format!(\"+ D {} {}\", urlencoding::encode(p).to_string(), urlencoding::encode(n).to_string())"
+ 32 "                    },"
+ 33 "                    ContainerModification::DeleteDirectory(p, n) => {"
+ 34 "                        format!(\"- D {} {}\", urlencoding::encode(p).to_string(), urlencoding::encode(n).to_string())"
+ 35 "                    },"
+ 36 "                    ContainerModification::CreateFile(p, n) => {"
+ 37 "                        format!(\"+ F {} {}\", urlencoding::encode(p).to_string(), urlencoding::encode(n).to_string())"
+ 38 "                    },"
+ 39 "                    ContainerModification::DeleteFile(p, n) => {"
+ 40 "                        format!(\"- F {} {}\", urlencoding::encode(p).to_string(), urlencoding::encode(n).to_string())"
+ 41 "                    }"
+ 42 "                }"
+ 43 "            );"
+ 44 "        }"
+ 45 ""
+ 46 "        result.push(\"=\".to_string());"
+ 47 ""
+ 48 "        let mut map = HashMap::new();"
+ 49 "        for modification in &self.modifications {"
+ 50 "            let path = match modification {"
+ 51 "                Modification::Create(path, name, _, _) => (path.clone(), name.clone()),"
+ 52 "                Modification::Delete(path, name, _) => (path.clone(), name.clone())"
+ 53 "            };"
+ 54 "            map.entry(path).or_insert(vec![]).push(modification.clone());"
+ 55 "        }"
+ 56 ""
+ 57 "        for ((path, name), modifications) in map {"
+ 58 "            result.push(format!(\"| {} {}\", urlencoding::encode(&path).to_string(), urlencoding::encode(&name).to_string()));"
+ 59 "            for m in modifications {"
+ 60 "                result.push("
+ 61 "                    match m {"
+ 62 "                        Modification::Create(_, _, line, content) => format!(\"+ {line} {content:?}\"),"
+ 63 "                        Modification::Delete(_, _, line) => format!(\"- {line}\")"
+ 64 "                    }"
+ 65 "                )"
+ 66 "            }"
+ 67 "        }"
+ 68 ""
+ 69 "        result.join(\"\\n\")"
+ 70 "    }"
+ 71 ""
+ 72 "    pub fn get_change(path: String, upstream_file: &File, current_file: &File) -> Vec<Modification> {"
+ 73 "        // https://blog.jcoglan.com/2017/02/15/the-myers-diff-algorithm-part-2/"
+ 74 "        // for our change algorithm, we will be using myers diff algorithm"
+ 75 "        // basically a shortest distance problem, with downwards, rightwards and diagonal directions as movement choices"
+ 76 "        // (note that diagonal movements do not contribute towards the distance)"
+ 77 ""
+ 78 "        let upstream = upstream_file.content.clone();"
+ 79 "        let current = current_file.content.clone();"
+ 80 ""
+ 81 "        // TODO : compare hashes instead of files"
+ 82 "        if upstream == current {"
+ 83 "            return vec![];"
+ 84 "        }"
+ 85 ""
+ 86 "        let mut result = vec![];"
+ 87 "        let diff = TextDiff::from_lines(&upstream, &current);"
+ 88 ""
+ 89 "        for change in diff"
+ 90 "            .iter_all_changes()"
+ 91 "            .filter_map(|c| match c.tag() {"
+ 92 "                ChangeTag::Equal => None,"
+ 93 "                _ => Some(c)"
+ 94 "            }"
+ 95 "        ) {"
+ 96 "            result.push("
+ 97 "                match change.tag() {"
+ 98 "                    ChangeTag::Delete => Modification::Delete("
+ 99 "                        path.clone(),"
+ 100 "                        current_file.name.clone(),"
+ 101 "                        change.old_index().unwrap()"
+ 102 "                    ),"
+ 103 "                    ChangeTag::Insert => Modification::Create("
+ 104 "                        path.clone(),"
+ 105 "                        current_file.name.clone(),"
+ 106 "                        change.new_index().unwrap(),"
+ 107 "                        change.to_string().strip_suffix(\"\\n\").unwrap().to_string()"
+ 108 "                    ),"
+ 109 "                    _ => panic!()"
+ 110 "                }"
+ 111 "            )"
+ 112 "        }"
+ 113 ""
+ 114 "        result"
+ 115 "    }"
+ 116 ""
+ 117 "    pub fn get_change_all(upstream: &Directory, current: &Directory, path: &Path) -> Change {"
+ 118 "        // assume that both current and previous have the same directory names"
+ 119 "        // has to be bfs"
+ 120 ""
+ 121 "        // initialise current state set"
+ 122 "        let mut current_set = HashSet::new();"
+ 123 "        let mut current_map = HashMap::new();"
+ 124 "        for c in &current.content {"
+ 125 "            match c {"
+ 126 "                Content::Directory(d) => {"
+ 127 "                    current_set.insert((d.name.clone(), false));"
+ 128 "                    current_map.insert((d.name.clone(), false), c);"
+ 129 "                },"
+ 130 "                Content::File(f) => {"
+ 131 "                    current_set.insert((f.name.clone(), true));"
+ 132 "                    current_map.insert((f.name.clone(), true), c);"
+ 133 "                }"
+ 134 "            }"
+ 135 "        }"
+ 136 "        //"
+ 137 ""
+ 138 "        // initialise upstream state set"
+ 139 "        let mut upstream_set = HashSet::new();"
+ 140 "        let mut upstream_map = HashMap::new();"
+ 141 "        for c in &upstream.content {"
+ 142 "            match c {"
+ 143 "                Content::Directory(d) => {"
+ 144 "                    upstream_set.insert((d.name.clone(), false));"
+ 145 "                    upstream_map.insert((d.name.clone(), false), c);"
+ 146 "                },"
+ 147 "                Content::File(f) => {"
+ 148 "                    upstream_set.insert((f.name.clone(), true));"
+ 149 "                    upstream_map.insert((f.name.clone(), true), c);"
+ 150 "                }"
+ 151 "            }"
+ 152 "        }"
+ 153 "        //"
+ 154 ""
+ 155 "        // use set differences to determine file and directory creation or deletion"
+ 156 "        let deleted = upstream_set.difference(&current_set).map(|(n, t)| (n.to_string(), *t)).collect::<Vec<(String, bool)>>();"
+ 157 "        let created = current_set.difference(&upstream_set).map(|(n, t)| (n.to_string(), *t)).collect::<Vec<(String, bool)>>();"
+ 158 "        //"
+ 159 ""
+ 160 "        // for all deleted files, log them"
+ 161 "        // for all deleted directories, log them and do the same for all children"
+ 162 "        let mut container_modifications = vec![];"
+ 163 "        let mut modifications = vec![];"
+ 164 "        for (dir_name, is_file) in deleted {"
+ 165 "            if is_file {"
+ 166 "                container_modifications.push(ContainerModification::DeleteFile(path.to_string_lossy().to_string(), dir_name));"
+ 167 "            } else {"
+ 168 "                container_modifications.push(ContainerModification::DeleteDirectory(path.to_string_lossy().to_string(), dir_name.clone()));"
+ 169 "                // traverse all children, add them to result as well"
+ 170 "                let mut changes = Change::get_change_all("
+ 171 "                    match upstream_map.get(&(dir_name.clone(), false)).unwrap() {"
+ 172 "                        Content::Directory(deleted_d) => { deleted_d },"
+ 173 "                        _ => panic!()"
+ 174 "                    },"
+ 175 "                    &Directory::new(),"
+ 176 "                    &path.join(dir_name.clone())"
+ 177 "                );"
+ 178 "                container_modifications.append(&mut changes.container_modifications);"
+ 179 "                modifications.append(&mut changes.modifications);"
+ 180 "            }"
+ 181 "        }"
+ 182 "        //"
+ 183 ""
+ 184 "        // for all created files, log them"
+ 185 "        // for all created directories, log them and do the same for all children"
+ 186 "        for (dir_name, is_file) in created {"
+ 187 "            if is_file {"
+ 188 "                // let p = path.join(dir_name.clone()).to_string_lossy().to_string();"
+ 189 "                container_modifications.push(ContainerModification::CreateFile(path.to_string_lossy().to_string(), dir_name.clone()));"
+ 190 "                // Modification::Create here"
+ 191 "                modifications.append("
+ 192 "                    &mut Change::get_change("
+ 193 "                        path.to_string_lossy().to_string(),"
+ 194 "                        &File::new(),"
+ 195 "                        match current_map.get(&(dir_name, true)).unwrap() {"
+ 196 "                            Content::File(f) => { f },"
+ 197 "                            _ => panic!()"
+ 198 "                        }"
+ 199 "                    )"
+ 200 "                )"
+ 201 "            } else {"
+ 202 "                // let p = path.join(dir_name.clone());"
+ 203 "                container_modifications.push(ContainerModification::CreateDirectory(path.to_string_lossy().to_string(), dir_name.clone()));"
+ 204 ""
+ 205 "                let mut changes = Change::get_change_all("
+ 206 "                    &Directory::new(),"
+ 207 "                    match current_map.get(&(dir_name.clone(), false)).unwrap() {"
+ 208 "                        Content::Directory(d) => d,"
+ 209 "                        _ => panic!()"
+ 210 "                    },"
+ 211 "                    &path.join(dir_name.clone())"
+ 212 "                );"
+ 213 "                container_modifications.append(&mut changes.container_modifications);"
+ 214 "                modifications.append(&mut changes.modifications);"
+ 215 "            }"
+ 216 "        }"
+ 217 ""
+ 218 "        for content in &current.content {"
+ 219 "            match content {"
+ 220 "                Content::Directory(directory) => {"
+ 221 "                    // get the matching upstream directory"
+ 222 "                    // if it doesnt exist, that means the content is new and can be ignored"
+ 223 "                    // we ignore it because we have already logged it in the section above"
+ 224 "                    let p = path.join(directory.name.clone());"
+ 225 "                    let upstream_directory = match upstream_map.get(&(directory.name.clone(), false)) {"
+ 226 "                        Some(u) => {"
+ 227 "                            match u {"
+ 228 "                                Content::Directory(u_d) => { u_d },"
+ 229 "                                _ => panic!()"
+ 230 "                            }"
+ 231 "                        },"
+ 232 "                        _ => { continue; }"
+ 233 "                    };"
+ 234 "                    //"
+ 235 ""
+ 236 "                    let mut changes = Change::get_change_all("
+ 237 "                        upstream_directory,"
+ 238 "                        directory,"
+ 239 "                        &p"
+ 240 "                    );"
+ 241 "                    container_modifications.append(&mut changes.container_modifications);"
+ 242 "                    modifications.append(&mut changes.modifications);"
+ 243 "                },"
+ 244 "                Content::File(f) => {"
+ 245 "                    let upstream_file = match upstream_map.get(&(f.name.clone(), true)) "
+ 246 "                    {"
+ 247 "                        Some(c) => match c {"
+ 248 "                            Content::File(f) => f,"
+ 249 "                            _ => panic!()"
+ 250 "                        },"
+ 251 "                        None => { continue; }"
+ 252 "                    };"
+ 253 ""
+ 254 "                    modifications.append("
+ 255 "                        &mut Change::get_change("
+ 256 "                            path.to_string_lossy().to_string(),"
+ 257 "                            &upstream_file,"
+ 258 "                            &f"
+ 259 "                        )"
+ 260 "                    );"
+ 261 "                }"
+ 262 "            }"
+ 263 "        }"
+ 264 ""
+ 265 "        Change {"
+ 266 "            container_modifications,"
+ 267 "            modifications"
+ 268 "        }"
+ 269 "    }"
+ 270 ""
+ 271 "    pub fn as_map(&self) -> (HashMap<String, Vec<ContainerModification>>, HashMap<String, HashMap<String, Vec<Modification>>>) {"
+ 272 "        // c_mod_map: map<parent_directory, Vec<changes>>"
+ 273 "        // mod_map: map<parent_directory, map<file_name, Vec<changes>>>"
+ 274 ""
+ 275 "        let mut c_mod_map = HashMap::new();"
+ 276 "        for container_modification in &self.container_modifications {"
+ 277 "            let path = match container_modification {"
+ 278 "                ContainerModification::CreateDirectory(path, _) => path.clone(),"
+ 279 "                ContainerModification::DeleteDirectory(path, _) => path.clone(),"
+ 280 "                ContainerModification::CreateFile(path, _) => path.clone(),"
+ 281 "                ContainerModification::DeleteFile(path, _) => path.clone()"
+ 282 "            };"
+ 283 ""
+ 284 "            c_mod_map.entry(path).or_insert(vec![]).push(container_modification.clone());"
+ 285 "        }"
+ 286 ""
+ 287 "        let mut mod_map = HashMap::new();"
+ 288 "        for modification in &self.modifications {"
+ 289 "            let (parent_directory, file_name) = match modification {"
+ 290 "                Modification::Create(path, name, _, _) => (path.clone(), name.clone()),"
+ 291 "                Modification::Delete(path, name, _) => (path.clone(), name.clone())"
+ 292 "            };"
+ 293 "            mod_map"
+ 294 "                .entry(parent_directory)"
+ 295 "                .or_insert(HashMap::new())"
+ 296 ""
+ 297 "                .entry(file_name)"
+ 298 "                .or_insert(vec![])"
+ 299 "                .push(modification.clone());"
+ 300 "        }"
+ 301 ""
+ 302 "        (c_mod_map, mod_map)"
+ 303 "    }"
+ 304 ""
+ 305 "    pub fn filter_changes(&self, filter: &ContentSet) -> Change {"
+ 306 "        Change {"
+ 307 "            container_modifications: self.container_modifications"
+ 308 "                .clone()"
+ 309 "                .into_iter()"
+ 310 "                .filter(|c_mod|"
+ 311 "                    match c_mod {"
+ 312 "                        ContainerModification::CreateFile(p, n) | ContainerModification::DeleteFile(p, n) => filter.files.contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),"
+ 313 "                        ContainerModification::CreateDirectory(p, n) | ContainerModification::DeleteDirectory(p, n) => filter.directories.contains(&PathBuf::from(p).join(n).to_string_lossy().to_string()),"
+ 314 "                    }"
+ 315 "                )"
+ 316 "                .collect(),"
+ 317 "            modifications: self.modifications"
+ 318 "                .clone()"
+ 319 "                .into_iter()"
+ 320 "                .filter(|m|"
+ 321 "                    filter.files.contains(&"
+ 322 "                        match m {"
+ 323 "                            Modification::Create(p, n, _, _) | Modification::Delete(p, n, _) => PathBuf::from(p).join(n).to_string_lossy().to_string(),"
+ 324 "                        }"
+ 325 "                    )"
+ 326 "                )"
+ 327 "                .collect()"
+ 328 "        }"
+ 329 "    }"
+ 330 "}"
+ 331 ""
+ 332 "#[derive(Debug, Clone, Serialize, Deserialize)]"
+ 333 "pub enum Modification {"
+ 334 "    // creation/deletion of lines in files"
+ 335 "    Create("
+ 336 "        String, // parent directory"
+ 337 "        String, // file name"
+ 338 "        usize, // line"
+ 339 "        String // text"
+ 340 "    ),"
+ 341 "    Delete("
+ 342 "        String, // parent directory"
+ 343 "        String, // file name"
+ 344 "        usize // line"
+ 345 "    )"
+ 346 "}"
+ 347 ""
+ 348 "#[derive(Debug, Clone, Serialize, Deserialize)]"
+ 349 "pub enum ContainerModification {"
+ 350 "    // denote that parent doesnt exist?"
+ 351 "    "
+ 352 "    // creation/deletion of files & folders"
+ 353 "    CreateDirectory("
+ 354 "        String, // parent directory"
+ 355 "        String // name"
+ 356 "    ),"
+ 357 "    DeleteDirectory("
+ 358 "        String, // parent directory"
+ 359 "        String // name"
+ 360 "    ),"
+ 361 ""
+ 362 "    CreateFile("
+ 363 "        String, // parent directory"
+ 364 "        String // name"
+ 365 "    ),"
+ 366 "    DeleteFile("
+ 367 "        String, // parent directory"
+ 368 "        String // name"
+ 369 "    )"
+ 370 "}"
| . Cargo.toml
+ 0 "[package]"
+ 1 "name = \"relic\""
+ 2 "version = \"0.1.0\""
+ 3 "edition = \"2021\""
+ 4 ""
+ 5 "[dependencies]"
+ 6 "sha256 = \"1.5.0\""
+ 7 ""
+ 8 "strum = \"0.26.3\""
+ 9 "strum_macros = \"0.26.3\""
+ 10 ""
+ 11 "serde = { version = \"1.0\", features = [\"derive\"] }"
+ 12 "serde_json = \"1.0\""
+ 13 "urlencoding = \"2.1.3\""
+ 14 ""
+ 15 "dotenv = \"0.15.0\""
+ 16 "clap = \"4.5.38\""
+ 17 ""
+ 18 "similar = \"2.7.0\""
| .%2Fsrc branch.rs
+ 0 "use clap::ArgMatches;"
+ 1 ""
+ 2 "use crate::state::State;"
+ 3 ""
+ 4 "pub fn branch(state: &mut State, args: &ArgMatches) {"
+ 5 ""
+ 6 "}"
| .%2Fsrc error.rs
+ 0 "use serde::{Deserialize, Serialize};"
+ 1 ""
+ 2 "#[derive(Debug, Serialize, Deserialize)]"
+ 3 "pub enum RelicError {"
+ 4 "    FileCantOpen,"
+ 5 "    IgnoredFile,"
+ 6 "    ConfigurationIncorrect"
+ 7 "}"
| .%2Fsrc state.rs
+ 0 "use std::{collections::HashSet, fs, path::{Path, PathBuf}, sync::{Arc, Mutex}};"
+ 1 "use serde::{Deserialize, Serialize};"
+ 2 ""
+ 3 "use crate::{change::{Change, ContainerModification, Modification}, commit::Commit, content::{Content, Directory, File}, content_set::{ContentSet, IgnoreSet, TrackingSet}, error::RelicError};"
+ 4 ""
+ 5 "#[derive(Debug, Serialize, Deserialize)]"
+ 6 "pub struct State {"
+ 7 "    pub current: Directory,"
+ 8 "    pub upstream: Directory,"
+ 9 "    pub path: PathBuf,"
+ 10 "    pub track_set: ContentSet,"
+ 11 "    pub ignore_set: ContentSet"
+ 12 "}"
+ 13 ""
+ 14 "impl State {"
+ 15 "    pub fn empty() -> State {"
+ 16 "        State {"
+ 17 "            current: Directory::new(),"
+ 18 "            upstream: Directory::new(),"
+ 19 "            path: PathBuf::from(\"\"),"
+ 20 "            track_set: ContentSet::empty(),"
+ 21 "            ignore_set: ContentSet::empty()"
+ 22 "        }"
+ 23 "    }"
+ 24 ""
+ 25 "    pub fn create(path: PathBuf) -> Result<State, RelicError> {"
+ 26 "        let ignore_set = IgnoreSet::create(fs::read_to_string(\".relic_ignore\").unwrap_or(\"\".to_string()));"
+ 27 ""
+ 28 "        let current = match State::content_at(&path.to_string_lossy().to_string(), &path, &ignore_set)? {"
+ 29 "            Content::Directory(d) => d,"
+ 30 "            _ => return Err(RelicError::ConfigurationIncorrect)"
+ 31 "        };"
+ 32 ""
+ 33 "        let upstream = match fs::read_to_string(\".relic/upstream\") {"
+ 34 "            Ok(data) => {"
+ 35 "                match Directory::deserialise(data) {"
+ 36 "                    Some(d) => d,"
+ 37 "                    None => return Err(RelicError::ConfigurationIncorrect)"
+ 38 "                }"
+ 39 "            },"
+ 40 "            Err(_) => return Err(RelicError::FileCantOpen)"
+ 41 "        };"
+ 42 ""
+ 43 "        let mut track_set: ContentSet = match fs::read_to_string(\".relic/tracked\") {"
+ 44 "            Ok(data) => TrackingSet::deserialise(data),"
+ 45 "            Err(_) => return Err(RelicError::ConfigurationIncorrect)"
+ 46 "        };"
+ 47 ""
+ 48 "        track_set.directories = HashSet::from_iter(track_set.directories.difference(&ignore_set.directories).map(|x| PathBuf::from(\".\").join(PathBuf::from(x)).to_string_lossy().to_string()));"
+ 49 "        track_set.files = HashSet::from_iter(track_set.files.difference(&ignore_set.files).map(|x| PathBuf::from(\".\").join(PathBuf::from(x)).to_string_lossy().to_string()));"
+ 50 ""
+ 51 "        Ok(State {"
+ 52 "            current,"
+ 53 "            upstream,"
+ 54 "            path,"
+ 55 "            track_set,"
+ 56 "            ignore_set"
+ 57 "        })"
+ 58 "    }"
+ 59 ""
+ 60 "    pub fn content_at(file_name: &String, root_path: &PathBuf, ignore_set: &ContentSet) -> Result<Content, RelicError> {"
+ 61 "        // get all files at path"
+ 62 "        let paths = match fs::read_dir(root_path) {"
+ 63 "        // let paths = match fs::read_dir(format!(\"./{}\", root_path.clone())) {"
+ 64 "            Ok(r) => r,"
+ 65 "            Err(e) => {"
+ 66 "                println!(\"state.rs (content_at) get all dirs : {root_path:?} : {e:?}\");"
+ 67 "                return Err(RelicError::FileCantOpen);"
+ 68 "            }"
+ 69 "        };"
+ 70 ""
+ 71 "        let mut directory_contents = vec![];"
+ 72 ""
+ 73 "        // iterate through them all"
+ 74 "        for path in paths {"
+ 75 "            match path {"
+ 76 "                Ok(p) => {"
+ 77 "                    let file_type = p.file_type().unwrap();"
+ 78 "                    let file_name = p.file_name().into_string().unwrap();"
+ 79 "                    let file_path = p.path();"
+ 80 ""
+ 81 "                    if file_name.starts_with(\".\") {"
+ 82 "                        continue;"
+ 83 "                    }"
+ 84 ""
+ 85 "                    if file_type.is_dir() {"
+ 86 "                        if ignore_set.directories.contains(&file_name) {"
+ 87 "                            continue;"
+ 88 "                        }"
+ 89 ""
+ 90 "                        match State::content_at(&file_name, &file_path, ignore_set) {"
+ 91 "                            Ok(c) => {"
+ 92 "                                directory_contents.push(c);"
+ 93 "                            },"
+ 94 "                            Err(e) => {"
+ 95 "                                println!(\"state.rs (content_at) subtraverse : {e:?}\");"
+ 96 "                            }"
+ 97 "                        }"
+ 98 "                    } else if file_type.is_file() {"
+ 99 "                        if ignore_set.files.contains(&file_name) {"
+ 100 "                            continue;"
+ 101 "                        }"
+ 102 ""
+ 103 "                        match File::create(file_name, file_path) {"
+ 104 "                            Ok(f) => {"
+ 105 "                                directory_contents.push(Content::File(f));"
+ 106 "                            },"
+ 107 "                            _ => {}"
+ 108 "                        }"
+ 109 "                    } else if file_type.is_symlink() {"
+ 110 "                        // TODO : decide what to do here"
+ 111 "                        if ignore_set.files.contains(&file_name) {"
+ 112 "                            continue;"
+ 113 "                        }"
+ 114 "                    }"
+ 115 "                },"
+ 116 "                Err(e) => {"
+ 117 "                    println!(\"state.rs (content_at) read_dir : {e:?}\");"
+ 118 "                }"
+ 119 "            }"
+ 120 "        }"
+ 121 ""
+ 122 "        // println!(\"CREATION : {root_path:?}\");"
+ 123 "        Ok(Content::Directory(Directory {"
+ 124 "            path: root_path.clone(),"
+ 125 "            name: file_name.clone(),"
+ 126 "            content: directory_contents"
+ 127 "        }))"
+ 128 "    }"
+ 129 ""
+ 130 "    pub fn serialise_state(self: &State) -> String {"
+ 131 "        serde_json::to_string(self).unwrap()"
+ 132 "    }"
+ 133 "    "
+ 134 "    pub fn deserialise_state(s: String) -> Option<State> {"
+ 135 "        match serde_json::from_str(&s) {"
+ 136 "            Ok(s) => Some(s),"
+ 137 "            Err(_) => None"
+ 138 "        }"
+ 139 "    }"
+ 140 ""
+ 141 "    // #region changes"
+ 142 "    pub fn get_changes(&self) -> Change {"
+ 143 "        Change::get_change_all(&self.upstream, &self.current, Path::new(&self.path))"
+ 144 "    }"
+ 145 "    // #endregion"
+ 146 ""
+ 147 "    // #region upstream"
+ 148 "    pub fn update_upstream(&mut self, tracked_content: &ContentSet) {"
+ 149 "        // fully fill tracked_content"
+ 150 "        // eg : \"lorem/\" -> [\"lorem/ipsum\", \"lorem/dolor\", \"lorem/sit\"]"
+ 151 "        // traverse directories and fetch all children"
+ 152 ""
+ 153 "        // let tracked_mutex = Arc::new(Mutex::new(tracked_content.clone()));"
+ 154 "        // self.current.traverse(PathBuf::from(\".\"), &|path, _, current| {"
+ 155 "        //     let mut tracked_unlock = tracked_mutex.lock().unwrap();"
+ 156 ""
+ 157 "        //     match current {"
+ 158 "        //         Content::Directory(d) => {"
+ 159 "        //             // if parent in set"
+ 160 "        //             // add to content set"
+ 161 "        //             if tracked_unlock.directories.contains(&d.path.parent().unwrap().to_string_lossy().to_string()) {"
+ 162 "        //                 tracked_unlock.directories.insert(d.path.to_string_lossy().to_string());"
+ 163 "        //             }"
+ 164 "        //         },"
+ 165 "        //         Content::File(f) => {"
+ 166 "        //             if tracked_unlock.directories.contains(&path.to_string_lossy().to_string()) {"
+ 167 "        //                 tracked_unlock.files.insert(path.join(&f.name).to_string_lossy().to_string());"
+ 168 "        //             }"
+ 169 "        //         }"
+ 170 "        //     }"
+ 171 "        // });"
+ 172 ""
+ 173 "        // let tracked_content = tracked_mutex.lock().unwrap().clone();"
+ 174 ""
+ 175 "        let tracked_content = tracked_content.clone().initialise(&mut self.current);"
+ 176 ""
+ 177 "        // get changes"
+ 178 "        // filter to only changes in the tracked_content content set"
+ 179 "        let changes = self.get_changes().filter_changes(&tracked_content);"
+ 180 ""
+ 181 "        // println!(\"{}\", changes.serialise_changes());"
+ 182 ""
+ 183 "        // apply changes to current"
+ 184 "        self.upstream.apply_changes(changes);"
+ 185 "        // replace upstream with current"
+ 186 "        // self.upstream = self.current.clone(); // expensive?"
+ 187 ""
+ 188 "        let _ = fs::write(\".relic/upstream\", self.upstream.serialise());"
+ 189 "    }"
+ 190 "    // #endregion"
+ 191 ""
+ 192 "    // #region pending"
+ 193 "    pub fn pending_add(&self, commit: Commit) {"
+ 194 "        let _ = fs::write(format!(\".relic/pending/{}.diff\", commit.timestamp), commit.serialise());"
+ 195 "    }"
+ 196 "    // #endregion"
+ 197 "}"
| .%2Florem mars
+ 0 "sldfjsljdkf"
| .%2Fsrc utils.rs
+ 0 "use std::time::{SystemTime, UNIX_EPOCH};"
+ 1 ""
+ 2 "use crate::{content::{Content, Directory}, state::State};"
+ 3 ""
+ 4 "pub fn get_value(args: &Vec<String>, key: &str) -> Option<String> {"
+ 5 "    for (index, i) in args.iter().enumerate() {"
+ 6 "        if i.starts_with(\"-\") && (i[1..] == key[..]) {"
+ 7 ""
+ 8 "        }"
+ 9 "    }"
+ 10 ""
+ 11 "    None"
+ 12 "}"
+ 13 ""
+ 14 "pub fn generate_tree(dir: &Directory) -> String {"
+ 15 "    return fetch_contents(&Content::Directory(dir.clone()));"
+ 16 "}"
+ 17 ""
+ 18 "fn fetch_contents(c: &Content) -> String {"
+ 19 "    let mut result = vec![];"
+ 20 ""
+ 21 "    match c {"
+ 22 "        Content::Directory(d) => {"
+ 23 "            let mut r = vec![d.name.clone()];"
+ 24 "            if d.content.len() >= 1 {"
+ 25 "                let length = d.content.len() - 1;"
+ 26 "                for (index, i) in d.content.iter().enumerate() {"
+ 27 "                    for (inner_index, line) in fetch_contents(i).split(\"\\n\").enumerate() {"
+ 28 "                        r.push(format!(\" {} {line}\", if index == length { if inner_index == 0 { \"└\" } else { \"\" } } else { if inner_index == 0 { \"├\" } else { \"│\" } }));"
+ 29 "                    }"
+ 30 "                }"
+ 31 "            }"
+ 32 "            result.push(r.join(\"\\n\"));"
+ 33 "        },"
+ 34 "        Content::File(f) => {"
+ 35 "            // result.push(f.name.clone());"
+ 36 "            result.push(format!(\"{} ({})\", f.name, sha256::digest(&f.content)));"
+ 37 "        }"
+ 38 "    }"
+ 39 ""
+ 40 "    result.join(\"\\n\")"
+ 41 "}"
+ 42 ""
+ 43 "pub fn get_time() -> u128 {"
+ 44 "    SystemTime::now()"
+ 45 "        .duration_since(UNIX_EPOCH)"
+ 46 "        .expect(\"time went backwards (???)\")"
+ 47 "        .as_nanos() as u128"
+ 48 "}"
| .%2Fsrc stash.rs
+ 0 "use clap::ArgMatches;"
+ 1 ""
+ 2 "use crate::state::State;"
+ 3 ""
+ 4 "pub fn stash(state: &mut State, args: &ArgMatches) {"
+ 5 ""
+ 6 "}"
+ 7 ""
+ 8 "pub fn restore(state: &mut State, args: &ArgMatches) {"
+ 9 ""
+ 10 "}"
| .%2Florem%2Fipsum temp
+ 0 "alsfdk"
| .%2Fsrc content_set.rs
+ 0 "use std::{collections::HashSet, path::PathBuf, sync::{Arc, Mutex}};"
+ 1 ""
+ 2 "use serde::{Deserialize, Serialize};"
+ 3 ""
+ 4 "use crate::content::{Content, Directory};"
+ 5 ""
+ 6 "#[derive(Serialize, Deserialize, Debug, Clone)]"
+ 7 "pub struct ContentSet {"
+ 8 "    pub directories: HashSet<String>,"
+ 9 "    pub files: HashSet<String>"
+ 10 "}"
+ 11 "impl ContentSet {"
+ 12 "    pub fn empty() -> ContentSet {"
+ 13 "        ContentSet {"
+ 14 "            directories: HashSet::new(),"
+ 15 "            files: HashSet::new()"
+ 16 "        }"
+ 17 "    }"
+ 18 ""
+ 19 "    pub fn as_set(&self) -> HashSet<String> {"
+ 20 ""
+ 21 ""
+ 22 "        HashSet::new()"
+ 23 "    }"
+ 24 "}"
+ 25 ""
+ 26 "pub trait IgnoreSet {"
+ 27 "    fn create(content: String) -> Self;"
+ 28 "}"
+ 29 "impl IgnoreSet for ContentSet {"
+ 30 "    fn create(content: String) -> ContentSet {"
+ 31 "        let mut result = ContentSet {"
+ 32 "            directories: HashSet::new(),"
+ 33 "            files: HashSet::new()"
+ 34 "        };"
+ 35 ""
+ 36 "        // always ignore the .relic directory"
+ 37 "        result.directories.insert(\".relic\".to_string());"
+ 38 ""
+ 39 "        for line in content.split(\"\\n\") {"
+ 40 "            if line.is_empty() {"
+ 41 "                continue;"
+ 42 "            }"
+ 43 ""
+ 44 "            // doesnt take into account cases like "
+ 45 "            // some_directory// <- double slashes"
+ 46 "            if line.ends_with(\"/\") {"
+ 47 "                let i = line[0..line.len() - 1].to_string();"
+ 48 "                if i.is_empty() {"
+ 49 "                    continue;"
+ 50 "                }"
+ 51 ""
+ 52 "                result.directories.insert(i);"
+ 53 "            } else {"
+ 54 "                result.files.insert(line.to_string());"
+ 55 "            }"
+ 56 "        }"
+ 57 ""
+ 58 "        result"
+ 59 "    }"
+ 60 "}"
+ 61 ""
+ 62 "pub trait TrackingSet {"
+ 63 "    fn deserialise(content: String) -> Self;"
+ 64 "    fn initialise(&self, d: &mut Directory) -> Self;"
+ 65 "}"
+ 66 "impl TrackingSet for ContentSet {"
+ 67 "    fn deserialise(content: String) -> Self {"
+ 68 "        let mut result = ContentSet::empty();"
+ 69 ""
+ 70 "        for d in content.split(\"\\n\").map(|x| x.to_string()).collect::<Vec<String>>() {"
+ 71 "            if d.ends_with(\"/\") {"
+ 72 "                // dir"
+ 73 "                result.directories.insert(d[..d.len() - 1].to_string());"
+ 74 "            } else {"
+ 75 "                // file"
+ 76 "                result.files.insert(d);"
+ 77 "            }"
+ 78 "        }"
+ 79 ""
+ 80 "        result"
+ 81 "    }"
+ 82 ""
+ 83 "    fn initialise(&self, d: &mut Directory) -> ContentSet {"
+ 84 "        let tracked_mutex = Arc::new(Mutex::new(self.clone()));"
+ 85 "        d.traverse(PathBuf::from(\".\"), &|path, _, current| {"
+ 86 "            // println!(\"traversing at : {path:?}\");"
+ 87 ""
+ 88 "            let mut tracked_unlock = tracked_mutex.lock().unwrap();"
+ 89 ""
+ 90 "            match current {"
+ 91 "                Content::Directory(d) => {"
+ 92 "                    // if parent in set"
+ 93 "                    // add to content set"
+ 94 "                    if tracked_unlock.directories.contains(&d.path.parent().unwrap().to_string_lossy().to_string()) {"
+ 95 "                        tracked_unlock.directories.insert(d.path.to_string_lossy().to_string());"
+ 96 "                    }"
+ 97 "                },"
+ 98 "                Content::File(f) => {"
+ 99 "                    if tracked_unlock.directories.contains(&path.to_string_lossy().to_string()) {"
+ 100 "                        tracked_unlock.files.insert(path.join(&f.name).to_string_lossy().to_string());"
+ 101 "                    }"
+ 102 "                }"
+ 103 "            }"
+ 104 "        }, &d.clone());"
+ 105 ""
+ 106 "        // dont ask me"
+ 107 "        let result = tracked_mutex.lock().unwrap().clone();"
+ 108 "        result"
+ 109 "    }"
+ 110 "}"
| . Cargo.lock
+ 0 "# This file is automatically @generated by Cargo."
+ 1 "# It is not intended for manual editing."
+ 2 "version = 3"
+ 3 ""
+ 4 "[[package]]"
+ 5 "name = \"addr2line\""
+ 6 "version = \"0.24.2\""
+ 7 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 8 "checksum = \"dfbe277e56a376000877090da837660b4427aad530e3028d44e0bffe4f89a1c1\""
+ 9 "dependencies = ["
+ 10 " \"gimli\","
+ 11 "]"
+ 12 ""
+ 13 "[[package]]"
+ 14 "name = \"adler2\""
+ 15 "version = \"2.0.0\""
+ 16 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 17 "checksum = \"512761e0bb2578dd7380c6baaa0f4ce03e84f95e960231d1dec8bf4d7d6e2627\""
+ 18 ""
+ 19 "[[package]]"
+ 20 "name = \"anstream\""
+ 21 "version = \"0.6.18\""
+ 22 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 23 "checksum = \"8acc5369981196006228e28809f761875c0327210a891e941f4c683b3a99529b\""
+ 24 "dependencies = ["
+ 25 " \"anstyle\","
+ 26 " \"anstyle-parse\","
+ 27 " \"anstyle-query\","
+ 28 " \"anstyle-wincon\","
+ 29 " \"colorchoice\","
+ 30 " \"is_terminal_polyfill\","
+ 31 " \"utf8parse\","
+ 32 "]"
+ 33 ""
+ 34 "[[package]]"
+ 35 "name = \"anstyle\""
+ 36 "version = \"1.0.10\""
+ 37 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 38 "checksum = \"55cc3b69f167a1ef2e161439aa98aed94e6028e5f9a59be9a6ffb47aef1651f9\""
+ 39 ""
+ 40 "[[package]]"
+ 41 "name = \"anstyle-parse\""
+ 42 "version = \"0.2.6\""
+ 43 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 44 "checksum = \"3b2d16507662817a6a20a9ea92df6652ee4f94f914589377d69f3b21bc5798a9\""
+ 45 "dependencies = ["
+ 46 " \"utf8parse\","
+ 47 "]"
+ 48 ""
+ 49 "[[package]]"
+ 50 "name = \"anstyle-query\""
+ 51 "version = \"1.1.2\""
+ 52 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 53 "checksum = \"79947af37f4177cfead1110013d678905c37501914fba0efea834c3fe9a8d60c\""
+ 54 "dependencies = ["
+ 55 " \"windows-sys\","
+ 56 "]"
+ 57 ""
+ 58 "[[package]]"
+ 59 "name = \"anstyle-wincon\""
+ 60 "version = \"3.0.7\""
+ 61 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 62 "checksum = \"ca3534e77181a9cc07539ad51f2141fe32f6c3ffd4df76db8ad92346b003ae4e\""
+ 63 "dependencies = ["
+ 64 " \"anstyle\","
+ 65 " \"once_cell\","
+ 66 " \"windows-sys\","
+ 67 "]"
+ 68 ""
+ 69 "[[package]]"
+ 70 "name = \"async-trait\""
+ 71 "version = \"0.1.88\""
+ 72 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 73 "checksum = \"e539d3fca749fcee5236ab05e93a52867dd549cc157c8cb7f99595f3cedffdb5\""
+ 74 "dependencies = ["
+ 75 " \"proc-macro2\","
+ 76 " \"quote\","
+ 77 " \"syn\","
+ 78 "]"
+ 79 ""
+ 80 "[[package]]"
+ 81 "name = \"backtrace\""
+ 82 "version = \"0.3.74\""
+ 83 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 84 "checksum = \"8d82cb332cdfaed17ae235a638438ac4d4839913cc2af585c3c6746e8f8bee1a\""
+ 85 "dependencies = ["
+ 86 " \"addr2line\","
+ 87 " \"cfg-if\","
+ 88 " \"libc\","
+ 89 " \"miniz_oxide\","
+ 90 " \"object\","
+ 91 " \"rustc-demangle\","
+ 92 " \"windows-targets\","
+ 93 "]"
+ 94 ""
+ 95 "[[package]]"
+ 96 "name = \"block-buffer\""
+ 97 "version = \"0.10.4\""
+ 98 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 99 "checksum = \"3078c7629b62d3f0439517fa394996acacc5cbc91c5a20d8c658e77abd503a71\""
+ 100 "dependencies = ["
+ 101 " \"generic-array\","
+ 102 "]"
+ 103 ""
+ 104 "[[package]]"
+ 105 "name = \"bytes\""
+ 106 "version = \"1.10.1\""
+ 107 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 108 "checksum = \"d71b6127be86fdcfddb610f7182ac57211d4b18a3e9c82eb2d17662f2227ad6a\""
+ 109 ""
+ 110 "[[package]]"
+ 111 "name = \"cfg-if\""
+ 112 "version = \"1.0.0\""
+ 113 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 114 "checksum = \"baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd\""
+ 115 ""
+ 116 "[[package]]"
+ 117 "name = \"clap\""
+ 118 "version = \"4.5.38\""
+ 119 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 120 "checksum = \"ed93b9805f8ba930df42c2590f05453d5ec36cbb85d018868a5b24d31f6ac000\""
+ 121 "dependencies = ["
+ 122 " \"clap_builder\","
+ 123 "]"
+ 124 ""
+ 125 "[[package]]"
+ 126 "name = \"clap_builder\""
+ 127 "version = \"4.5.38\""
+ 128 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 129 "checksum = \"379026ff283facf611b0ea629334361c4211d1b12ee01024eec1591133b04120\""
+ 130 "dependencies = ["
+ 131 " \"anstream\","
+ 132 " \"anstyle\","
+ 133 " \"clap_lex\","
+ 134 " \"strsim\","
+ 135 "]"
+ 136 ""
+ 137 "[[package]]"
+ 138 "name = \"clap_lex\""
+ 139 "version = \"0.7.4\""
+ 140 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 141 "checksum = \"f46ad14479a25103f283c0f10005961cf086d8dc42205bb44c46ac563475dca6\""
+ 142 ""
+ 143 "[[package]]"
+ 144 "name = \"colorchoice\""
+ 145 "version = \"1.0.3\""
+ 146 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 147 "checksum = \"5b63caa9aa9397e2d9480a9b13673856c78d8ac123288526c37d7839f2a86990\""
+ 148 ""
+ 149 "[[package]]"
+ 150 "name = \"cpufeatures\""
+ 151 "version = \"0.2.17\""
+ 152 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 153 "checksum = \"59ed5838eebb26a2bb2e58f6d5b5316989ae9d08bab10e0e6d103e656d1b0280\""
+ 154 "dependencies = ["
+ 155 " \"libc\","
+ 156 "]"
+ 157 ""
+ 158 "[[package]]"
+ 159 "name = \"crypto-common\""
+ 160 "version = \"0.1.6\""
+ 161 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 162 "checksum = \"1bfb12502f3fc46cca1bb51ac28df9d618d813cdc3d2f25b9fe775a34af26bb3\""
+ 163 "dependencies = ["
+ 164 " \"generic-array\","
+ 165 " \"typenum\","
+ 166 "]"
+ 167 ""
+ 168 "[[package]]"
+ 169 "name = \"digest\""
+ 170 "version = \"0.10.7\""
+ 171 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 172 "checksum = \"9ed9a281f7bc9b7576e61468ba615a66a5c8cfdff42420a70aa82701a3b1e292\""
+ 173 "dependencies = ["
+ 174 " \"block-buffer\","
+ 175 " \"crypto-common\","
+ 176 "]"
+ 177 ""
+ 178 "[[package]]"
+ 179 "name = \"dotenv\""
+ 180 "version = \"0.15.0\""
+ 181 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 182 "checksum = \"77c90badedccf4105eca100756a0b1289e191f6fcbdadd3cee1d2f614f97da8f\""
+ 183 ""
+ 184 "[[package]]"
+ 185 "name = \"generic-array\""
+ 186 "version = \"0.14.7\""
+ 187 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 188 "checksum = \"85649ca51fd72272d7821adaf274ad91c288277713d9c18820d8499a7ff69e9a\""
+ 189 "dependencies = ["
+ 190 " \"typenum\","
+ 191 " \"version_check\","
+ 192 "]"
+ 193 ""
+ 194 "[[package]]"
+ 195 "name = \"gimli\""
+ 196 "version = \"0.31.1\""
+ 197 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 198 "checksum = \"07e28edb80900c19c28f1072f2e8aeca7fa06b23cd4169cefe1af5aa3260783f\""
+ 199 ""
+ 200 "[[package]]"
+ 201 "name = \"heck\""
+ 202 "version = \"0.5.0\""
+ 203 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 204 "checksum = \"2304e00983f87ffb38b55b444b5e3b60a884b5d30c0fca7d82fe33449bbe55ea\""
+ 205 ""
+ 206 "[[package]]"
+ 207 "name = \"hex\""
+ 208 "version = \"0.4.3\""
+ 209 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 210 "checksum = \"7f24254aa9a54b5c858eaee2f5bccdb46aaf0e486a595ed5fd8f86ba55232a70\""
+ 211 ""
+ 212 "[[package]]"
+ 213 "name = \"is_terminal_polyfill\""
+ 214 "version = \"1.70.1\""
+ 215 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 216 "checksum = \"7943c866cc5cd64cbc25b2e01621d07fa8eb2a1a23160ee81ce38704e97b8ecf\""
+ 217 ""
+ 218 "[[package]]"
+ 219 "name = \"itoa\""
+ 220 "version = \"1.0.15\""
+ 221 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 222 "checksum = \"4a5f13b858c8d314ee3e8f639011f7ccefe71f97f96e50151fb991f267928e2c\""
+ 223 ""
+ 224 "[[package]]"
+ 225 "name = \"libc\""
+ 226 "version = \"0.2.172\""
+ 227 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 228 "checksum = \"d750af042f7ef4f724306de029d18836c26c1765a54a6a3f094cbd23a7267ffa\""
+ 229 ""
+ 230 "[[package]]"
+ 231 "name = \"memchr\""
+ 232 "version = \"2.7.4\""
+ 233 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 234 "checksum = \"78ca9ab1a0babb1e7d5695e3530886289c18cf2f87ec19a575a0abdce112e3a3\""
+ 235 ""
+ 236 "[[package]]"
+ 237 "name = \"miniz_oxide\""
+ 238 "version = \"0.8.8\""
+ 239 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 240 "checksum = \"3be647b768db090acb35d5ec5db2b0e1f1de11133ca123b9eacf5137868f892a\""
+ 241 "dependencies = ["
+ 242 " \"adler2\","
+ 243 "]"
+ 244 ""
+ 245 "[[package]]"
+ 246 "name = \"object\""
+ 247 "version = \"0.36.7\""
+ 248 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 249 "checksum = \"62948e14d923ea95ea2c7c86c71013138b66525b86bdc08d2dcc262bdb497b87\""
+ 250 "dependencies = ["
+ 251 " \"memchr\","
+ 252 "]"
+ 253 ""
+ 254 "[[package]]"
+ 255 "name = \"once_cell\""
+ 256 "version = \"1.21.3\""
+ 257 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 258 "checksum = \"42f5e15c9953c5e4ccceeb2e7382a716482c34515315f7b03532b8b4e8393d2d\""
+ 259 ""
+ 260 "[[package]]"
+ 261 "name = \"pin-project-lite\""
+ 262 "version = \"0.2.16\""
+ 263 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 264 "checksum = \"3b3cff922bd51709b605d9ead9aa71031d81447142d828eb4a6eba76fe619f9b\""
+ 265 ""
+ 266 "[[package]]"
+ 267 "name = \"proc-macro2\""
+ 268 "version = \"1.0.95\""
+ 269 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 270 "checksum = \"02b3e5e68a3a1a02aad3ec490a98007cbc13c37cbe84a3cd7b8e406d76e7f778\""
+ 271 "dependencies = ["
+ 272 " \"unicode-ident\","
+ 273 "]"
+ 274 ""
+ 275 "[[package]]"
+ 276 "name = \"quote\""
+ 277 "version = \"1.0.40\""
+ 278 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 279 "checksum = \"1885c039570dc00dcb4ff087a89e185fd56bae234ddc7f056a945bf36467248d\""
+ 280 "dependencies = ["
+ 281 " \"proc-macro2\","
+ 282 "]"
+ 283 ""
+ 284 "[[package]]"
+ 285 "name = \"relic\""
+ 286 "version = \"0.1.0\""
+ 287 "dependencies = ["
+ 288 " \"clap\","
+ 289 " \"dotenv\","
+ 290 " \"serde\","
+ 291 " \"serde_json\","
+ 292 " \"sha256\","
+ 293 " \"similar\","
+ 294 " \"strum\","
+ 295 " \"strum_macros\","
+ 296 " \"urlencoding\","
+ 297 "]"
+ 298 ""
+ 299 "[[package]]"
+ 300 "name = \"rustc-demangle\""
+ 301 "version = \"0.1.24\""
+ 302 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 303 "checksum = \"719b953e2095829ee67db738b3bfa9fa368c94900df327b3f07fe6e794d2fe1f\""
+ 304 ""
+ 305 "[[package]]"
+ 306 "name = \"rustversion\""
+ 307 "version = \"1.0.20\""
+ 308 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 309 "checksum = \"eded382c5f5f786b989652c49544c4877d9f015cc22e145a5ea8ea66c2921cd2\""
+ 310 ""
+ 311 "[[package]]"
+ 312 "name = \"ryu\""
+ 313 "version = \"1.0.20\""
+ 314 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 315 "checksum = \"28d3b2b1366ec20994f1fd18c3c594f05c5dd4bc44d8bb0c1c632c8d6829481f\""
+ 316 ""
+ 317 "[[package]]"
+ 318 "name = \"serde\""
+ 319 "version = \"1.0.219\""
+ 320 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 321 "checksum = \"5f0e2c6ed6606019b4e29e69dbaba95b11854410e5347d525002456dbbb786b6\""
+ 322 "dependencies = ["
+ 323 " \"serde_derive\","
+ 324 "]"
+ 325 ""
+ 326 "[[package]]"
+ 327 "name = \"serde_derive\""
+ 328 "version = \"1.0.219\""
+ 329 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 330 "checksum = \"5b0276cf7f2c73365f7157c8123c21cd9a50fbbd844757af28ca1f5925fc2a00\""
+ 331 "dependencies = ["
+ 332 " \"proc-macro2\","
+ 333 " \"quote\","
+ 334 " \"syn\","
+ 335 "]"
+ 336 ""
+ 337 "[[package]]"
+ 338 "name = \"serde_json\""
+ 339 "version = \"1.0.140\""
+ 340 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 341 "checksum = \"20068b6e96dc6c9bd23e01df8827e6c7e1f2fddd43c21810382803c136b99373\""
+ 342 "dependencies = ["
+ 343 " \"itoa\","
+ 344 " \"memchr\","
+ 345 " \"ryu\","
+ 346 " \"serde\","
+ 347 "]"
+ 348 ""
+ 349 "[[package]]"
+ 350 "name = \"sha2\""
+ 351 "version = \"0.10.8\""
+ 352 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 353 "checksum = \"793db75ad2bcafc3ffa7c68b215fee268f537982cd901d132f89c6343f3a3dc8\""
+ 354 "dependencies = ["
+ 355 " \"cfg-if\","
+ 356 " \"cpufeatures\","
+ 357 " \"digest\","
+ 358 "]"
+ 359 ""
+ 360 "[[package]]"
+ 361 "name = \"sha256\""
+ 362 "version = \"1.6.0\""
+ 363 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 364 "checksum = \"f880fc8562bdeb709793f00eb42a2ad0e672c4f883bbe59122b926eca935c8f6\""
+ 365 "dependencies = ["
+ 366 " \"async-trait\","
+ 367 " \"bytes\","
+ 368 " \"hex\","
+ 369 " \"sha2\","
+ 370 " \"tokio\","
+ 371 "]"
+ 372 ""
+ 373 "[[package]]"
+ 374 "name = \"similar\""
+ 375 "version = \"2.7.0\""
+ 376 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 377 "checksum = \"bbbb5d9659141646ae647b42fe094daf6c6192d1620870b449d9557f748b2daa\""
+ 378 ""
+ 379 "[[package]]"
+ 380 "name = \"strsim\""
+ 381 "version = \"0.11.1\""
+ 382 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 383 "checksum = \"7da8b5736845d9f2fcb837ea5d9e2628564b3b043a70948a3f0b778838c5fb4f\""
+ 384 ""
+ 385 "[[package]]"
+ 386 "name = \"strum\""
+ 387 "version = \"0.26.3\""
+ 388 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 389 "checksum = \"8fec0f0aef304996cf250b31b5a10dee7980c85da9d759361292b8bca5a18f06\""
+ 390 ""
+ 391 "[[package]]"
+ 392 "name = \"strum_macros\""
+ 393 "version = \"0.26.4\""
+ 394 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 395 "checksum = \"4c6bee85a5a24955dc440386795aa378cd9cf82acd5f764469152d2270e581be\""
+ 396 "dependencies = ["
+ 397 " \"heck\","
+ 398 " \"proc-macro2\","
+ 399 " \"quote\","
+ 400 " \"rustversion\","
+ 401 " \"syn\","
+ 402 "]"
+ 403 ""
+ 404 "[[package]]"
+ 405 "name = \"syn\""
+ 406 "version = \"2.0.100\""
+ 407 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 408 "checksum = \"b09a44accad81e1ba1cd74a32461ba89dee89095ba17b32f5d03683b1b1fc2a0\""
+ 409 "dependencies = ["
+ 410 " \"proc-macro2\","
+ 411 " \"quote\","
+ 412 " \"unicode-ident\","
+ 413 "]"
+ 414 ""
+ 415 "[[package]]"
+ 416 "name = \"tokio\""
+ 417 "version = \"1.44.2\""
+ 418 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 419 "checksum = \"e6b88822cbe49de4185e3a4cbf8321dd487cf5fe0c5c65695fef6346371e9c48\""
+ 420 "dependencies = ["
+ 421 " \"backtrace\","
+ 422 " \"bytes\","
+ 423 " \"pin-project-lite\","
+ 424 "]"
+ 425 ""
+ 426 "[[package]]"
+ 427 "name = \"typenum\""
+ 428 "version = \"1.18.0\""
+ 429 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 430 "checksum = \"1dccffe3ce07af9386bfd29e80c0ab1a8205a2fc34e4bcd40364df902cfa8f3f\""
+ 431 ""
+ 432 "[[package]]"
+ 433 "name = \"unicode-ident\""
+ 434 "version = \"1.0.18\""
+ 435 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 436 "checksum = \"5a5f39404a5da50712a4c1eecf25e90dd62b613502b7e925fd4e4d19b5c96512\""
+ 437 ""
+ 438 "[[package]]"
+ 439 "name = \"urlencoding\""
+ 440 "version = \"2.1.3\""
+ 441 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 442 "checksum = \"daf8dba3b7eb870caf1ddeed7bc9d2a049f3cfdfae7cb521b087cc33ae4c49da\""
+ 443 ""
+ 444 "[[package]]"
+ 445 "name = \"utf8parse\""
+ 446 "version = \"0.2.2\""
+ 447 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 448 "checksum = \"06abde3611657adf66d383f00b093d7faecc7fa57071cce2578660c9f1010821\""
+ 449 ""
+ 450 "[[package]]"
+ 451 "name = \"version_check\""
+ 452 "version = \"0.9.5\""
+ 453 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 454 "checksum = \"0b928f33d975fc6ad9f86c8f283853ad26bdd5b10b7f1542aa2fa15e2289105a\""
+ 455 ""
+ 456 "[[package]]"
+ 457 "name = \"windows-sys\""
+ 458 "version = \"0.59.0\""
+ 459 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 460 "checksum = \"1e38bc4d79ed67fd075bcc251a1c39b32a1776bbe92e5bef1f0bf1f8c531853b\""
+ 461 "dependencies = ["
+ 462 " \"windows-targets\","
+ 463 "]"
+ 464 ""
+ 465 "[[package]]"
+ 466 "name = \"windows-targets\""
+ 467 "version = \"0.52.6\""
+ 468 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 469 "checksum = \"9b724f72796e036ab90c1021d4780d4d3d648aca59e491e6b98e725b84e99973\""
+ 470 "dependencies = ["
+ 471 " \"windows_aarch64_gnullvm\","
+ 472 " \"windows_aarch64_msvc\","
+ 473 " \"windows_i686_gnu\","
+ 474 " \"windows_i686_gnullvm\","
+ 475 " \"windows_i686_msvc\","
+ 476 " \"windows_x86_64_gnu\","
+ 477 " \"windows_x86_64_gnullvm\","
+ 478 " \"windows_x86_64_msvc\","
+ 479 "]"
+ 480 ""
+ 481 "[[package]]"
+ 482 "name = \"windows_aarch64_gnullvm\""
+ 483 "version = \"0.52.6\""
+ 484 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 485 "checksum = \"32a4622180e7a0ec044bb555404c800bc9fd9ec262ec147edd5989ccd0c02cd3\""
+ 486 ""
+ 487 "[[package]]"
+ 488 "name = \"windows_aarch64_msvc\""
+ 489 "version = \"0.52.6\""
+ 490 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 491 "checksum = \"09ec2a7bb152e2252b53fa7803150007879548bc709c039df7627cabbd05d469\""
+ 492 ""
+ 493 "[[package]]"
+ 494 "name = \"windows_i686_gnu\""
+ 495 "version = \"0.52.6\""
+ 496 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 497 "checksum = \"8e9b5ad5ab802e97eb8e295ac6720e509ee4c243f69d781394014ebfe8bbfa0b\""
+ 498 ""
+ 499 "[[package]]"
+ 500 "name = \"windows_i686_gnullvm\""
+ 501 "version = \"0.52.6\""
+ 502 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 503 "checksum = \"0eee52d38c090b3caa76c563b86c3a4bd71ef1a819287c19d586d7334ae8ed66\""
+ 504 ""
+ 505 "[[package]]"
+ 506 "name = \"windows_i686_msvc\""
+ 507 "version = \"0.52.6\""
+ 508 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 509 "checksum = \"240948bc05c5e7c6dabba28bf89d89ffce3e303022809e73deaefe4f6ec56c66\""
+ 510 ""
+ 511 "[[package]]"
+ 512 "name = \"windows_x86_64_gnu\""
+ 513 "version = \"0.52.6\""
+ 514 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 515 "checksum = \"147a5c80aabfbf0c7d901cb5895d1de30ef2907eb21fbbab29ca94c5b08b1a78\""
+ 516 ""
+ 517 "[[package]]"
+ 518 "name = \"windows_x86_64_gnullvm\""
+ 519 "version = \"0.52.6\""
+ 520 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 521 "checksum = \"24d5b23dc417412679681396f2b49f3de8c1473deb516bd34410872eff51ed0d\""
+ 522 ""
+ 523 "[[package]]"
+ 524 "name = \"windows_x86_64_msvc\""
+ 525 "version = \"0.52.6\""
+ 526 "source = \"registry+https://github.com/rust-lang/crates.io-index\""
+ 527 "checksum = \"589f6da84c646204747d1270a2a5661ea66ed1cced2631d546fdfb155959f9ec\""
| .%2Fsrc commit.rs
+ 0 "use std::{collections::HashSet, fs, path::PathBuf};"
+ 1 ""
+ 2 "use clap::ArgMatches;"
+ 3 ""
+ 4 "use crate::{change::Change, state::State, utils};"
+ 5 ""
+ 6 "pub struct Commit {"
+ 7 "    pub id: Option<u32>,"
+ 8 "    pub message: String,"
+ 9 "    pub description: String,"
+ 10 "    pub change: Change,"
+ 11 "    pub timestamp: u128,"
+ 12 ""
+ 13 "    pub author: String"
+ 14 "}"
+ 15 "impl Commit {"
+ 16 "    pub fn serialise(&self) -> String {"
+ 17 "        format!(\"= {} {} {:?} {:?} {}\\n{}\","
+ 18 "            self.id.map_or(\"LOCAL\".to_string(), |i| format!(\"{:06x}\", i).clone()),"
+ 19 "            self.timestamp,"
+ 20 "            urlencoding::encode(&self.message).to_string(),"
+ 21 "            urlencoding::encode(&self.description).to_string(),"
+ 22 "            self.author,"
+ 23 "            self.change.serialise_changes()"
+ 24 "        )"
+ 25 "    }"
+ 26 "}"
+ 27 ""
+ 28 ""
+ 29 "pub fn add(_: &mut State, args: &ArgMatches) {"
+ 30 "    let f = args.get_many::<PathBuf>(\"FILE\").unwrap().map(|x| x.clone()).collect::<Vec<PathBuf>>();"
+ 31 ""
+ 32 "    let mut result: HashSet<String> = HashSet::from_iter("
+ 33 "        fs::read_to_string(\"./.relic/tracked\")"
+ 34 "        .unwrap()"
+ 35 "        .split(\"\\n\")"
+ 36 "        .filter(|x| !x.is_empty())"
+ 37 "        .map(|x| x.to_string())"
+ 38 "        .collect::<Vec<String>>()"
+ 39 "    );"
+ 40 "    for p in f {"
+ 41 "        // TODO : path.join for this? or concatenating / works?"
+ 42 "        result.insert(format!(\"{}{}\", p.to_string_lossy().to_string(), if !p.to_string_lossy().to_string().ends_with(\"/\") && p.is_dir() { \"/\" } else { \"\" }));"
+ 43 "    }"
+ 44 "    let _ = fs::write(\"./.relic/tracked\", result"
+ 45 "        .drain()"
+ 46 "        .collect::<Vec<String>>()"
+ 47 "        .join(\"\\n\")"
+ 48 "    );"
+ 49 "}"
+ 50 ""
+ 51 "pub fn remove(_: &mut State, args: &ArgMatches) {"
+ 52 "    let f = args.get_many::<PathBuf>(\"FILE\").unwrap().map(|x| x.clone()).collect::<Vec<PathBuf>>();"
+ 53 ""
+ 54 "    let mut result: HashSet<String> = HashSet::from_iter("
+ 55 "        fs::read_to_string(\"./.relic/tracked\")"
+ 56 "        .unwrap()"
+ 57 "        .split(\"\\n\")"
+ 58 "        .filter(|x| !x.is_empty())"
+ 59 "        .map(|x| x.to_string())"
+ 60 "        .collect::<Vec<String>>()"
+ 61 "    );"
+ 62 "    for p in f {"
+ 63 "        // TODO : path.join for this? or concatenating / works?"
+ 64 "        result.remove(&format!(\"{}{}\", p.to_string_lossy().to_string(), if !p.to_string_lossy().to_string().ends_with(\"/\") && p.is_dir() { \"/\" } else { \"\" }));"
+ 65 "    }"
+ 66 "    let _ = fs::write(\"./.relic/tracked\", result"
+ 67 "        .drain()"
+ 68 "        .collect::<Vec<String>>()"
+ 69 "        .join(\"\\n\")"
+ 70 "    );"
+ 71 "}"
+ 72 ""
+ 73 "pub fn commit(state: &mut State, args: &ArgMatches) {"
+ 74 "    // push into pending stage"
+ 75 "    // update upstream"
+ 76 ""
+ 77 "    // everything after the first line will be generated by Change::serialise_change"
+ 78 "r#\"= {commit id} {unix timestamp of commit} {message} {description} {author}"
+ 79 "+ D \"lorem/ipsum/dolor\""
+ 80 "+ F \"lorem/ipsum/dolor/earth.txt\" \"earth.txt\""
+ 81 "- D \"lorem/sit\""
+ 82 "="
+ 83 "| \"lorem/ipsum/dolor/earth.txt\""
+ 84 "+ 3 asdfsdf"
+ 85 "+ 5 sfsdf"
+ 86 "- 7"
+ 87 "| \"lorem/ipsum/saturn/txt\""
+ 88 "+ 4 lsdfljs\"#;"
+ 89 "    let message = args.get_one::<String>(\"message\").unwrap().clone();"
+ 90 "    let description = args.get_one::<String>(\"description\").map_or(\"\".to_string(), String::clone);"
+ 91 ""
+ 92 "    let commit = Commit {"
+ 93 "        id: None,"
+ 94 "        message,"
+ 95 "        description,"
+ 96 "        change: state.get_changes(),"
+ 97 "        timestamp: utils::get_time(),"
+ 98 "        author: \"no_one\".to_string()"
+ 99 "    };"
+ 100 ""
+ 101 "    state.pending_add(commit);"
+ 102 "    // update upstream"
+ 103 "    (*state).update_upstream(&mut state.track_set.clone());"
+ 104 "}"
+ 105 ""
+ 106 "pub fn push(state: &mut State, args: &ArgMatches) {"
+ 107 ""
+ 108 "}"
+ 109 ""
+ 110 "pub fn pull(state: &mut State, args: &ArgMatches) {"
+ 111 ""
+ 112 "}"
+ 113 ""
+ 114 "pub fn fetch(state: &mut State, args: &ArgMatches) {"
+ 115 ""
+ 116 "}"
+ 117 ""
+ 118 "pub fn cherry(state: &mut State, args: &ArgMatches) {"
+ 119 "    "
+ 120 "}"
+ 121 ""
+ 122 "pub fn rollback(state: &mut State, args: &ArgMatches) {"
+ 123 ""
+ 124 "}"
| .%2Fsrc content.rs
+ 0 "use std::{collections::{HashMap, HashSet}, fs, path::{Path, PathBuf}, sync::Arc};"
+ 1 ""
+ 2 "use serde::{Deserialize, Serialize};"
+ 3 ""
+ 4 "use crate::{change::{Change, ContainerModification, Modification}, error::RelicError, utils};"
+ 5 ""
+ 6 "#[derive(Debug, Serialize, Deserialize, Clone)]"
+ 7 "pub enum Content {"
+ 8 "    Directory(Directory),"
+ 9 "    File(File),"
+ 10 "}"
+ 11 ""
+ 12 "#[derive(Debug, Serialize, Deserialize, Clone)]"
+ 13 "pub struct File {"
+ 14 "    pub name: String,"
+ 15 "    pub content: String,"
+ 16 "}"
+ 17 ""
+ 18 "impl File {"
+ 19 "    pub fn new() -> File {"
+ 20 "        File {"
+ 21 "            name: \"\".to_string(),"
+ 22 "            content: \"\".to_string()"
+ 23 "        }"
+ 24 "    }"
+ 25 ""
+ 26 "    pub fn create(name: String, path: PathBuf) -> Result<File, RelicError> {"
+ 27 "        match fs::read_to_string(path) {"
+ 28 "            Ok(content) => {"
+ 29 "                Ok(File {"
+ 30 "                    name: name,"
+ 31 "                    content: content"
+ 32 "                })"
+ 33 "            },"
+ 34 "            Err(_) => {"
+ 35 "                // println!(\"Error creating file : {e}\");"
+ 36 "                Err(RelicError::FileCantOpen)"
+ 37 "            }"
+ 38 "        }"
+ 39 "    }"
+ 40 ""
+ 41 "    pub fn apply_changes(&mut self, modifications: &Vec<Modification>) {"
+ 42 "        // TODO : investigate whether an additional newline is added to eof"
+ 43 "        // BUG : when the file has only one line, diffs start to break"
+ 44 "        //"
+ 45 "        // content : \"\""
+ 46 "        // Create(,, 0, \"something\")"
+ 47 "        // result : \"something\\nsomething\""
+ 48 "        //"
+ 49 "        // content : \"something\\nsomething\""
+ 50 "        // Delete(,, 0)"
+ 51 "        // result : \"\""
+ 52 ""
+ 53 "        // CHANGES ARE BEING APPLIED TO THE WRONG FILE"
+ 54 "        // APPLY CHANGES TO UPSTREAM, NOT CURRENT"
+ 55 ""
+ 56 "        // TODO : revise modification order"
+ 57 "        "
+ 58 "        // deletions first then creations?"
+ 59 "        //      sorted largest to smallest"
+ 60 "        // creations sorted smallest to largest?"
+ 61 "        let mut lines = self.content.split(\"\\n\").map(|x| x.to_string()).collect::<Vec<String>>();"
+ 62 ""
+ 63 "        let mut modifications = modifications.clone();"
+ 64 "        modifications.sort_by_key(|m| match m {"
+ 65 "            Modification::Create(_, _, l, _) => *l as i128,"
+ 66 "            Modification::Delete(_, _, l) => -(*l as i128)"
+ 67 "        });"
+ 68 ""
+ 69 "        for m in modifications {"
+ 70 "            match m {"
+ 71 "                Modification::Create(_, _, line, content) => {"
+ 72 "                    // insert at that line"
+ 73 "                    lines.insert(line, content.clone());"
+ 74 "                },"
+ 75 "                Modification::Delete(_, _, line) => {"
+ 76 "                    // delete that line"
+ 77 "                    lines.remove(line);"
+ 78 "                }"
+ 79 "            }"
+ 80 "        }"
+ 81 ""
+ 82 "        self.content = lines.join(\"\\n\");"
+ 83 "    }"
+ 84 "}"
+ 85 ""
+ 86 "#[derive(Debug, Serialize, Deserialize, Clone)]"
+ 87 "pub struct Directory {"
+ 88 "    pub path: PathBuf,"
+ 89 "    pub name: String,"
+ 90 "    pub content: Vec<Content>"
+ 91 "}"
+ 92 ""
+ 93 "impl Directory {"
+ 94 "    pub fn new() -> Directory {"
+ 95 "        Directory {"
+ 96 "            path: PathBuf::from(\"\"),"
+ 97 "            name: \"\".to_string(),"
+ 98 "            content: vec![]"
+ 99 "        }"
+ 100 "    }"
+ 101 ""
+ 102 "    pub fn deserialise(s: String) -> Option<Directory> {"
+ 103 "        match serde_json::from_str(&s) {"
+ 104 "            Ok(d) => Some(d),"
+ 105 "            _ => None"
+ 106 "        }"
+ 107 "    }"
+ 108 ""
+ 109 "    pub fn serialise(&self) -> String {"
+ 110 "        serde_json::to_string(&self).unwrap()"
+ 111 "    }"
+ 112 ""
+ 113 "    pub fn apply_changes(&mut self, changes: Change) {"
+ 114 "        let (c_mod_map, mod_map) = changes.as_map();"
+ 115 ""
+ 116 "        // println!(\"{c_mod_map:?}\");"
+ 117 ""
+ 118 "        // println!(\"changes to apply:\\n{}\", changes.serialise_changes());"
+ 119 ""
+ 120 "        // println!(\"{}\", serde_json::to_string_pretty(&self).unwrap().to_string());"
+ 121 ""
+ 122 "        println!(\"{}\", utils::generate_tree(&self));"
+ 123 ""
+ 124 "        // two pass"
+ 125 "        // create/delete containers, then create/delete file content"
+ 126 ""
+ 127 "        self.traverse("
+ 128 "            PathBuf::from(\".\"),"
+ 129 "            &|_, _, current| {"
+ 130 "                match current {"
+ 131 "                    Content::Directory(d) => {"
+ 132 "                        // somehow denote that the parent does not yet exist,"
+ 133 "                        // possibly recursively create directories where needed"
+ 134 ""
+ 135 "                        // TODO : optimise the match arms"
+ 136 "                        // println!(\"{}\", d.path.to_string_lossy().to_string());"
+ 137 ""
+ 138 "                        if let Some(c_modifications) = c_mod_map.get(&d.path.to_string_lossy().to_string()) {"
+ 139 "                            // println!(\"BEFORE\\n{}\", utils::generate_tree(&d));"
+ 140 ""
+ 141 "                            // deals with additions"
+ 142 "                            d.content.append(&mut recursive_birth(&PathBuf::from(d.path.clone()), &c_mod_map));"
+ 143 ""
+ 144 "                            // println!(\"POST-CREATION\\n{}\", utils::generate_tree(&d));"
+ 145 ""
+ 146 "                            let mut deleted_containers = HashSet::new();"
+ 147 "                            // deals with subtractions"
+ 148 "                            for c_mod in c_modifications {"
+ 149 "                                match c_mod {"
+ 150 "                                    ContainerModification::DeleteDirectory(_, n) => {"
+ 151 "                                        deleted_containers.insert(n);"
+ 152 "                                    }"
+ 153 "                                    ContainerModification::DeleteFile(_, n) => {"
+ 154 "                                        deleted_containers.insert(n);"
+ 155 "                                    },"
+ 156 "                                    _ => {}"
+ 157 "                                }"
+ 158 "                            }"
+ 159 ""
+ 160 "                            d.content = d.content"
+ 161 "                                .iter()"
+ 162 "                                .filter(|x|"
+ 163 "                                    !deleted_containers"
+ 164 "                                        .contains(match x {"
+ 165 "                                            Content::File(f) => &f.name,"
+ 166 "                                            Content::Directory(d) => &d.name"
+ 167 "                                        })"
+ 168 "                                )"
+ 169 "                                .map(|x| x.clone())"
+ 170 "                                .collect::<Vec<Content>>();"
+ 171 "                        }"
+ 172 "                    },"
+ 173 "                    _ => {}"
+ 174 "                }"
+ 175 ""
+ 176 "            // println!(\"{} -> {} ({path:?})\", parent.name, match current { Content::Directory(d) => d.name.clone(), Content::File(f) => f.name.clone() });"
+ 177 "        }, &self.clone());"
+ 178 ""
+ 179 "        println!(\"{}\", utils::generate_tree(&self));"
+ 180 ""
+ 181 "        self.traverse("
+ 182 "            PathBuf::from(\".\"),"
+ 183 "            &|path, _, current| {"
+ 184 "            match current {"
+ 185 "                Content::File(f) => {"
+ 186 "                    // THIS IS WHAT TO DO NEXT"
+ 187 "                    if let Some(modifications) = mod_map"
+ 188 "                        .get(&path.to_string_lossy().to_string())"
+ 189 "                        .map_or(None, |x| x.get(&f.name)) {"
+ 190 "                        // println!(\"{modifications:?}\");"
+ 191 "                        f.apply_changes(modifications);"
+ 192 "                    }"
+ 193 "                },"
+ 194 "                _ => {}"
+ 195 "            }"
+ 196 ""
+ 197 "            // println!(\"{} -> {} ({path:?})\", parent.name, match current { Content::Directory(d) => d.name.clone(), Content::File(f) => f.name.clone() });"
+ 198 "        }, &self.clone());"
+ 199 ""
+ 200 "        // println!(\"{}\", utils::generate_tree(&self));"
+ 201 ""
+ 202 "        pub fn recursive_birth(parent_directory: &PathBuf, c_mod_map: &HashMap<String, Vec<ContainerModification>>) -> Vec<Content> {"
+ 203 "            // pass the new directory's parent directory"
+ 204 "            let mut result = vec![];"
+ 205 "            match c_mod_map.get(&parent_directory.to_string_lossy().to_string()) {"
+ 206 "                Some(c_modifications) => {"
+ 207 "                    for c_mod in c_modifications {"
+ 208 "                        match c_mod {"
+ 209 "                            ContainerModification::CreateDirectory(p, n) => {"
+ 210 "                                result.push(Content::Directory(Directory {"
+ 211 "                                    path: parent_directory.join(n.clone()),"
+ 212 "                                    name: n.clone(),"
+ 213 "                                    content: recursive_birth("
+ 214 "                                        &parent_directory.join(n.clone()),"
+ 215 "                                        c_mod_map"
+ 216 "                                    )"
+ 217 "                                }));"
+ 218 "                            },"
+ 219 "                            ContainerModification::CreateFile(p, n) => {"
+ 220 "                                result.push(Content::File(File {"
+ 221 "                                    name: n.clone(),"
+ 222 "                                    content: \"\".to_string()"
+ 223 "                                }))"
+ 224 "                            },"
+ 225 "                            _ => {}"
+ 226 "                        }"
+ 227 "                    }"
+ 228 "                },"
+ 229 "                None => {}"
+ 230 "            }"
+ 231 "            result"
+ 232 "        }"
+ 233 "    }"
+ 234 ""
+ 235 "    // pub fn traverse(&mut self, root_path: PathBuf, c_mod_map: &HashMap<String, Vec<ContainerModification>>, mod_map: &HashMap<String, HashMap<String, Vec<Modification>>>, func: fn(&PathBuf, &Directory, &mut Content, &HashMap<String, Vec<ContainerModification>>, &HashMap<String, HashMap<String, Vec<Modification>>>)) {"
+ 236 "    pub fn traverse<F>(&mut self, root_path: PathBuf, func: &F, parent: &Directory)"
+ 237 "    where"
+ 238 "        F: Fn(&PathBuf, &Directory, &mut Content)"
+ 239 "    {"
+ 240 "        func(&root_path, &parent, &mut Content::Directory(self.clone()));"
+ 241 "        let c = self.clone();"
+ 242 "        for content in &mut self.content {"
+ 243 "            match content {"
+ 244 "                Content::Directory(d) => {"
+ 245 "                    d.traverse(root_path.join(d.name.clone()), func, &c);"
+ 246 "                },"
+ 247 "                Content::File(_) => {"
+ 248 "                    func(&root_path, &c, content);"
+ 249 "                }"
+ 250 "            }"
+ 251 "        }"
+ 252 "    }"
+ 253 "}"
| .%2Fsrc main.rs
+ 0 "use std::fs;"
+ 1 "use std::path::{Path, PathBuf};"
+ 2 "use std::{collections::HashMap, env};"
+ 3 ""
+ 4 "mod error;"
+ 5 "mod content_set;"
+ 6 "mod state;"
+ 7 "mod utils;"
+ 8 ""
+ 9 "mod relic;"
+ 10 "mod commit;"
+ 11 "mod branch;"
+ 12 "mod stash;"
+ 13 ""
+ 14 "mod content;"
+ 15 "mod change;"
+ 16 ""
+ 17 "use clap::{arg, value_parser, ArgMatches, Command};"
+ 18 "use commit::remove;"
+ 19 "use content::Content;"
+ 20 "use relic::Relic;"
+ 21 "use change::Change;"
+ 22 "use content_set::{ContentSet, IgnoreSet, TrackingSet};"
+ 23 "use utils::generate_tree;"
+ 24 ""
+ 25 "use crate::commit::{add, commit, push, pull, fetch, cherry, rollback};"
+ 26 "use crate::branch::branch;"
+ 27 "use crate::stash::{stash, restore};"
+ 28 "use crate::state::State;"
+ 29 ""
+ 30 "// add"
+ 31 "// commit {message}"
+ 32 "// push"
+ 33 "// pull"
+ 34 "// fetch"
+ 35 "// branch {name}"
+ 36 "//      will change to that branch"
+ 37 "//      if branch doesnt exist, create"
+ 38 "//      ask to create stash (if changes present)"
+ 39 "// stash {name|optional}"
+ 40 "//      stashes are bound to a branch"
+ 41 "//      optional to have a name"
+ 42 "// restore"
+ 43 "//      select stash to restore"
+ 44 "// rollback"
+ 45 "//      resets to current head"
+ 46 "// cherry {commit hash}"
+ 47 ""
+ 48 "pub fn init(_: &mut State, _: &ArgMatches) {"
+ 49 ""
+ 50 "}"
+ 51 ""
+ 52 "fn main() {"
+ 53 "    // let _ = fs::write("
+ 54 "    //     \".relic/upstream\","
+ 55 "    //     match State::content_at("
+ 56 "    //         &\"\".to_string(),"
+ 57 "    //         &PathBuf::from(\".\"),"
+ 58 "    //         &IgnoreSet::create(\"target/\".to_string())"
+ 59 "    //     ).unwrap() {"
+ 60 "    //         content::Content::Directory(d) => {"
+ 61 "    //             d.serialise()"
+ 62 "    //         },"
+ 63 "    //         _ => panic!()"
+ 64 "    //     }"
+ 65 "    // );"
+ 66 "    // return;"
+ 67 ""
+ 68 "    // let mut f = content::Directory {"
+ 69 "    //     path: PathBuf::from(\".\"),"
+ 70 "    //     name: \"\".to_string(),"
+ 71 "    //     content: vec!["
+ 72 "    //         content::Content::Directory(content::Directory {"
+ 73 "    //             path: PathBuf::from(\".\"),"
+ 74 "    //             name: \"huh\".to_string(),"
+ 75 "    //             content: vec![]"
+ 76 "    //         })"
+ 77 "    //     ]"
+ 78 "    // };"
+ 79 ""
+ 80 "    // println!(\"{}\", utils::generate_tree(&f));"
+ 81 ""
+ 82 "    // f.apply_changes(Change {"
+ 83 "    //     container_modifications: vec!["
+ 84 "    //         change::ContainerModification::CreateDirectory(\".\".to_string(), \"lorem\".to_string())"
+ 85 "    //     ],"
+ 86 "    //     modifications: vec![]"
+ 87 "    // });"
+ 88 ""
+ 89 "    // println!(\"{}\", utils::generate_tree(&f));"
+ 90 ""
+ 91 "    // return;"
+ 92 ""
+ 93 "    // #region commands"
+ 94 "    // TODO : automate this"
+ 95 "    let command_handler = Command::new(\"relic\")"
+ 96 "        .about(r#\"This is the Relic Version Control System."
+ 97 ""
+ 98 "The best way to learn is to stupidly and"
+ 99 "blindly reinvent the wheel."
+ 100 ""
+ 101 "Relic is a simple hobby project, because"
+ 102 "remaking Git sounded fun and interesting."
+ 103 ""
+ 104 "Most common features like committing,"
+ 105 "pushing and pulling, are implemented.\"#)"
+ 106 "        .subcommand_required(true)"
+ 107 "        .arg_required_else_help(true)"
+ 108 "        .subcommand("
+ 109 "            Command::new(\"init\")"
+ 110 "                .about(\"Initialises a Relic repository in the current directory.\")"
+ 111 "        )"
+ 112 ""
+ 113 "        .subcommand("
+ 114 "            Command::new(\"add\")"
+ 115 "                .about(\"Adds a file(s) to staging\")"
+ 116 "                .arg_required_else_help(true)"
+ 117 "                .arg("
+ 118 "                    arg!([FILE]... \"File(s) to add (* for all)\")"
+ 119 "                    .required(true)"
+ 120 "                    .value_parser(value_parser!(PathBuf))"
+ 121 "                )"
+ 122 "        )"
+ 123 "        .subcommand("
+ 124 "            Command::new(\"remove\")"
+ 125 "                .about(\"Removes a file(s) to staging\")"
+ 126 "                .arg_required_else_help(true)"
+ 127 "                .arg("
+ 128 "                    arg!([FILE]... \"File(s) to remove (* for all)\")"
+ 129 "                    .required(true)"
+ 130 "                    .value_parser(value_parser!(PathBuf))"
+ 131 "                )"
+ 132 "        )"
+ 133 "        .subcommand("
+ 134 "            Command::new(\"commit\")"
+ 135 "                .about(\"Commit current changes.\")"
+ 136 "                .arg_required_else_help(true)"
+ 137 "                .arg(arg!(-m --message <MESSAGE> \"Commit message\").required(true))"
+ 138 "                .arg(arg!(-d --description <DESCRIPTION> \"Commit description\"))"
+ 139 "        )"
+ 140 "        .subcommand("
+ 141 "            Command::new(\"push\")"
+ 142 "                .about(\"Pushes local changes to remote.\")"
+ 143 "        )"
+ 144 "        .subcommand("
+ 145 "            Command::new(\"pull\")"
+ 146 "                .about(\"Pull changes from remote to local.\")"
+ 147 "        )"
+ 148 "        .subcommand("
+ 149 "            Command::new(\"fetch\")"
+ 150 "                .about(\"Check remote for new changes.\")"
+ 151 "        )"
+ 152 "        .subcommand("
+ 153 "            Command::new(\"branch\")"
+ 154 "                .about(\"\")"
+ 155 "        )"
+ 156 "        .subcommand("
+ 157 "            Command::new(\"stash\")"
+ 158 "                // pseudo-commits basically"
+ 159 "                // clear stash after a commit"
+ 160 "                // stash create"
+ 161 "                // stash view"
+ 162 "                // stash restore"
+ 163 "                // stash delete"
+ 164 "                .about(\"\")"
+ 165 "        )"
+ 166 "        .subcommand("
+ 167 "            Command::new(\"rollback\")"
+ 168 "                .about(\"Discard all current changes. Rolls back to most recent commit (or pending commit).\")"
+ 169 "        )"
+ 170 "        .subcommand("
+ 171 "            Command::new(\"cherry\")"
+ 172 "                .about(\"Go to specific commit.\")"
+ 173 "        )"
+ 174 "        .subcommand("
+ 175 "            Command::new(\"tree\")"
+ 176 "                .about(\"Generate content tree of current directory.\")"
+ 177 "        )"
+ 178 ""
+ 179 ""
+ 180 "        .subcommand("
+ 181 "            Command::new(\"staging\")"
+ 182 "                .about(\"View all staging changes\")"
+ 183 "        )"
+ 184 ""
+ 185 "        .subcommand("
+ 186 "            Command::new(\"test\")"
+ 187 "                .about(\"test\")"
+ 188 "        )"
+ 189 "    ;"
+ 190 ""
+ 191 "    type CommandType = fn(&mut State, &ArgMatches);"
+ 192 "    let commands: HashMap<String, CommandType> = HashMap::from_iter::<Vec<(String, CommandType)>>(vec!["
+ 193 "        // TODO : pass user credentials into commands too"
+ 194 "        (\"init\".to_string(), init),"
+ 195 ""
+ 196 "        (\"add\".to_string(), add),"
+ 197 "        (\"remove\".to_string(), remove),"
+ 198 "        (\"commit\".to_string(), commit),"
+ 199 "        (\"push\".to_string(), push),"
+ 200 "        (\"pull\".to_string(), pull),"
+ 201 "        (\"fetch\".to_string(), fetch),"
+ 202 ""
+ 203 "        (\"branch\".to_string(), branch),"
+ 204 "        (\"stash\".to_string(), stash),"
+ 205 "        (\"restore\".to_string(), restore),"
+ 206 ""
+ 207 "        (\"rollback\".to_string(), rollback),"
+ 208 "        (\"cherry\".to_string(), cherry),"
+ 209 ""
+ 210 "        (\"tree\".to_string(), |s, _| {"
+ 211 "            println!(\"{}\", generate_tree(&s.current));"
+ 212 "        }),"
+ 213 "        (\"staging\".to_string(), |s, _| {"
+ 214 "            println!(\"{}\", s.get_changes().filter_changes(&s.track_set.initialise(&mut s.current)).serialise_changes());"
+ 215 "        }),"
+ 216 ""
+ 217 "        (\"test\".to_string(), |s, _| {"
+ 218 "            s.upstream.apply_changes(s.get_changes());"
+ 219 "        })"
+ 220 "    ]);"
+ 221 "    // #endregion"
+ 222 ""
+ 223 "    match State::create(PathBuf::from(\".\")) {"
+ 224 "        Ok(mut s) => {"
+ 225 "            let c = command_handler.get_matches();"
+ 226 "            let (command_name, sub_matches) = c.subcommand().unwrap();"
+ 227 "            match commands.get(command_name) {"
+ 228 "                Some(command) => {"
+ 229 "                    command(&mut s, sub_matches);"
+ 230 "                },"
+ 231 "                None => {"
+ 232 "                    println!(\"Relic Error, command not defined.\")"
+ 233 "                }"
+ 234 "            }"
+ 235 "        },"
+ 236 "        Err(e) => {"
+ 237 "            println!(\"main.rs (main) {e:?} error encountered.\");"
+ 238 "        }"
+ 239 "    }"
+ 240 "}"
| .%2Fsrc relic.rs
+ 0 "use std::{fs, path::Path};"
+ 1 ""
+ 2 "use crate::state::State;"
+ 3 ""
+ 4 "#[derive(Debug)]"
+ 5 "pub struct Relic {"
+ 6 "    // holds"
+ 7 "    //      history.changes"
+ 8 "    //      now.changes"
+ 9 "    //      root"
+ 10 "    //      upstream"
+ 11 "    pub upstream: State"
+ 12 "}"
+ 13 "impl Relic {"
+ 14 "    pub fn empty() -> Relic {"
+ 15 "        Relic {"
+ 16 "            upstream: State::empty()"
+ 17 "        }"
+ 18 "    }"
+ 19 "}"